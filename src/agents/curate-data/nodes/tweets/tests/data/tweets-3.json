[
  {
    "id": "1881423039730225555",
    "edit_history_tweet_ids": ["1881423039730225555"],
    "text": "RT @jecdohmann: I‚Äôm very excited to announce that I‚Äôll be joining @perceptroninc  (https://t.co/c85ZxRLuSI?) as a researcher and founding m‚Ä¶",
    "author_id": "2239670346",
    "created_at": "2025-01-20T19:26:22.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881418279945978261" }]
  },
  {
    "id": "1881421862158413989",
    "edit_history_tweet_ids": ["1881421862158413989"],
    "attachments": { "media_keys": ["3_1881421831749423104"] },
    "text": "you can just ask things https://t.co/a7q3QBcg7b https://t.co/okdX3Z3rAt",
    "author_id": "192201556",
    "created_at": "2025-01-20T19:21:41.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881301606727356474" }]
  },
  {
    "id": "1881420752228057435",
    "edit_history_tweet_ids": ["1881420752228057435"],
    "in_reply_to_user_id": "2465283662",
    "text": "Quick start colab: https://t.co/gIJgCzRKgs",
    "author_id": "2465283662",
    "created_at": "2025-01-20T19:17:17.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881405361200234933" }]
  },
  {
    "id": "1881420706694709671",
    "edit_history_tweet_ids": ["1881420706694709671"],
    "in_reply_to_user_id": "1141052916570214400",
    "text": "Paper: https://t.co/z55eucxOMl\n\nModels: https://t.co/aJ5jMHDJLm\n\nRead the paper if you are interested in reasoning models. It is very well written and easy to understand. ü§ó",
    "author_id": "1141052916570214400",
    "created_at": "2025-01-20T19:17:06.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881420703721009192" }]
  },
  {
    "id": "1881420703721009192",
    "edit_history_tweet_ids": ["1881420703721009192"],
    "attachments": { "media_keys": ["3_1881420656350253056"] },
    "note_tweet": {
      "text": "Reinforcement Learning is all you need! @deepseek_ai R1 an open model that rivals @OpenAI o1 and other models on complex reasoning tasks just got released. But how is it trained? üëÄ¬† DeepSeek combines reinforcement learning with multi-stage training to achieve reasoning abilities that rival leading closed-source: Base ‚Üí RL ‚Üí SFT ‚Üí RL ‚Üí SFT ‚Üí RL\n\n0/4 Base ‚Üí RL: Uses GRPO on ended reasoning text-completions with rule-based Reward Models, e.g. Format, Math, Coding. Leading to coherent long reasoning/reflection CoT but with readability issues.\n\n1/4  RL ‚Üí SFT: Collect up to 10k token long CoT using the previous model and few-shot prompting, then supervise fine-tune it. Leading readable thoughts and structured outputs (<think>, <summary>).\n\n2/4  SFT ‚Üí RL: Same pipeline as on 0/4 with GRPO focusing on reasoning-intensive tasks (coding, mathematics, science, still rule-based) with additional ‚Äúlanguage consistency‚Äù reward. Leading coherent, readable performance on reasoning tasks\n\n3/4 RL ‚Üí SFT: Collect 600k synthetic samples using Reject Sampling with the model (2/4) focusing on writing, role-playing, and other general-purpose tasks using DS v3 as LLM Judge. Adding additionally 200k samples for factual QA and translation from DS 3 training.\n\n4/4 SFT ‚Üí RL: Use GRPO to improve helpfulness and harmlessness for reasoning tasks. Use rule-based RM for general tasks and use outcome RMs. Leading to DS R1 model\n\nInsights\n‚ùå¬†No, MCTS for search and synthetic data or Process Reward Models (PRM) used\nüß†¬†RL on Base model lead to ‚Äúaha moment‚Äù, where models learns to coherent ‚Äúreasoning‚Äù longer outputs\nüëÄ Pure Reinforcement Learning can lead to strong reasoning abilities in LLMs.\nüöÄ¬†SFT before RL can accelerate and stabilize training.\n6Ô∏è‚É£¬†Trained 6 additional open models including Llama and Qwen on 800k synthetic samples from R1\nüèÜ Distilled smaller models outperform previous versions.\nüìà DeepSeek-R1 achieves comparable performance to OpenAI-o1-1217 on reasoning benchmarks like AIME 2024 and MATH-500.\nüéØ Rule-based rewards for accuracy and format prove more effective than complex reward modeling\nüßÆ Excels particularly in STEM tasks and long-context question answering",
      "entities": {
        "mentions": [
          {
            "start": 40,
            "end": 52,
            "username": "deepseek_ai",
            "id": "1714580962569588736"
          },
          { "start": 82, "end": 89, "username": "OpenAI", "id": "4398626122" }
        ]
      }
    },
    "text": "Reinforcement Learning is all you need! @deepseek_ai R1 an open model that rivals @OpenAI o1 and other models on complex reasoning tasks just got released. But how is it trained? üëÄ¬† DeepSeek combines reinforcement learning with multi-stage training to achieve reasoning abilities‚Ä¶ https://t.co/1NlPD7DxSL https://t.co/qcmS2Jlzam",
    "author_id": "1141052916570214400",
    "created_at": "2025-01-20T19:17:05.000Z"
  },
  {
    "id": "1881420662000283887",
    "edit_history_tweet_ids": ["1881420662000283887"],
    "attachments": { "media_keys": ["3_1881420467560488961"] },
    "text": "hmm, I distinctly remember reading that LessWrong is livelier than ever, being shown tastefully colored charts, even. What's happening? https://t.co/zbroQIgF9C",
    "author_id": "192201556",
    "created_at": "2025-01-20T19:16:55.000Z"
  },
  {
    "id": "1881419976709742673",
    "edit_history_tweet_ids": ["1881419976709742673"],
    "text": "it constantly confuses \"user\" and \"assistant\". That's why it needs multi-agent training, to develop an ego boundary.\n \nI think we're having Base Models 2.0, in a sense. A very alien (if even more humanlike than RLHF-era assistants)  and pretty confused simulacra-running Mind. https://t.co/lnmo7mDpFZ",
    "author_id": "192201556",
    "created_at": "2025-01-20T19:14:12.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881416960984101257" }]
  },
  {
    "id": "1881419585322443219",
    "edit_history_tweet_ids": ["1881419585322443219"],
    "text": "I think OpenAI saw the same thing and then trained o3 https://t.co/iDjMO4RTl3",
    "author_id": "1825243643529027584",
    "created_at": "2025-01-20T19:12:38.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881416820982223211" }]
  },
  {
    "id": "1881418628857532905",
    "edit_history_tweet_ids": ["1881418588252438942", "1881418628857532905"],
    "text": "So nice to just do this from my phone on a snowy morning https://t.co/kLXkEQfKjQ",
    "author_id": "52247685",
    "created_at": "2025-01-20T19:08:50.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881412781330862132" }]
  },
  {
    "id": "1881418205975171539",
    "edit_history_tweet_ids": ["1881418205975171539"],
    "attachments": { "media_keys": ["3_1881417101878968321"] },
    "text": "this is a bit confusing\n\nwhere is the o1-nano model?\nlike a 14 or 32B reasoning model distilled from full o1\n\nbecause like this it seems super silly that Qwen-14B just mops the floor with GPT-4o and Sonnet 3.5 on these benchmarks https://t.co/4ZPQIFCtAT",
    "author_id": "1825243643529027584",
    "created_at": "2025-01-20T19:07:10.000Z"
  },
  {
    "id": "1881418042443542862",
    "edit_history_tweet_ids": ["1881418042443542862"],
    "text": "I would pay unhinged amounts of money for this. https://t.co/2DkyNJGNkZ",
    "author_id": "2434761475",
    "created_at": "2025-01-20T19:06:31.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881415989512073624" }]
  },
  {
    "id": "1881418005504266296",
    "edit_history_tweet_ids": ["1881418005504266296"],
    "text": "RT @JrKibs: OpenAI needs to roll out o3 and Operator ASAP. \nWe‚Äôll get Claude 4 before end of January. \nDeepSeek has changed the game!",
    "author_id": "2465283662",
    "created_at": "2025-01-20T19:06:22.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881417692013535358" }]
  },
  {
    "id": "1881417382327123983",
    "edit_history_tweet_ids": ["1881417382327123983"],
    "text": "üí• https://t.co/i8dwjuJxLx",
    "author_id": "1583730714",
    "created_at": "2025-01-20T19:03:53.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881389682380169608" }]
  },
  {
    "id": "1881417251448045958",
    "edit_history_tweet_ids": ["1881417251448045958"],
    "in_reply_to_user_id": "1589007443853340672",
    "text": "To check out these new updates, try out the LangSmith Playground ‚û°Ô∏è https://t.co/Yz7EuqlLc5",
    "author_id": "1589007443853340672",
    "created_at": "2025-01-20T19:03:22.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881417250172993706" }]
  },
  {
    "id": "1881417250172993706",
    "edit_history_tweet_ids": ["1881417250172993706"],
    "in_reply_to_user_id": "1589007443853340672",
    "attachments": { "media_keys": ["7_1881416556787433472"] },
    "note_tweet": {
      "text": "üìä Improved Prompt Comparison\n\nCompare results across different prompt versions side-by-side to help with prompt engineering."
    },
    "text": "üìä Improved Prompt Comparison\n\nCompare results across different prompt versions side-by-side to help with prompt engineering. https://t.co/S0kFKsFlLa https://t.co/ZIs8RHeks5",
    "author_id": "1589007443853340672",
    "created_at": "2025-01-20T19:03:22.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881417248579145851" }]
  },
  {
    "id": "1881417248579145851",
    "edit_history_tweet_ids": ["1881417248579145851"],
    "in_reply_to_user_id": "1589007443853340672",
    "attachments": { "media_keys": ["7_1881416196740046848"] },
    "note_tweet": {
      "text": "üõ†Ô∏è Manage Tools Easily\n\nEdit and organize your tools with ease in the new \"Manage tools\" modal. All your tools, one convenient view."
    },
    "text": "üõ†Ô∏è Manage Tools Easily\n\nEdit and organize your tools with ease in the new \"Manage tools\" modal. All your tools, one convenient view. https://t.co/Tx2xakg1zT https://t.co/8N2pwOxIQg",
    "author_id": "1589007443853340672",
    "created_at": "2025-01-20T19:03:21.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881417245961879804" }]
  },
  {
    "id": "1881417245961879804",
    "edit_history_tweet_ids": ["1881417245961879804"],
    "in_reply_to_user_id": "1589007443853340672",
    "attachments": { "media_keys": ["3_1881416087713284096"] },
    "note_tweet": {
      "text": "‚öôÔ∏è Set Default Model Config\n\nSave time by marking your preferred model configuration as default."
    },
    "text": "‚öôÔ∏è Set Default Model Config\n\nSave time by marking your preferred model configuration as default. https://t.co/dE1bAnrhkg https://t.co/19bHzIev1v",
    "author_id": "1589007443853340672",
    "created_at": "2025-01-20T19:03:21.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881417244313555284" }]
  },
  {
    "id": "1881417244313555284",
    "edit_history_tweet_ids": ["1881417244313555284"],
    "in_reply_to_user_id": "1589007443853340672",
    "attachments": { "media_keys": ["7_1881414850087415808"] },
    "note_tweet": {
      "text": "‚ú® New Prompt Settings UI\n\nManage all your prompt settings in one streamlined view. Stay organized while building and testing prompts."
    },
    "text": "‚ú® New Prompt Settings UI\n\nManage all your prompt settings in one streamlined view. Stay organized while building and testing prompts. https://t.co/K5DZJOi1mm https://t.co/fJX1Fm3xxZ",
    "author_id": "1589007443853340672",
    "created_at": "2025-01-20T19:03:20.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881417243239842042" }]
  },
  {
    "id": "1881417243239842042",
    "edit_history_tweet_ids": ["1881417243239842042"],
    "text": "We‚Äôve just launched updates to the LangSmith Playground! üïπÔ∏è Here's what‚Äôs new üëáüßµ",
    "author_id": "1589007443853340672",
    "created_at": "2025-01-20T19:03:20.000Z"
  },
  {
    "id": "1881416890809291141",
    "edit_history_tweet_ids": ["1881416890809291141"],
    "text": "RT @perrymetzger: Every time you see something like this, every time you use cutting edge AI to get your work done, say to yourself, quietl‚Ä¶",
    "author_id": "7284012",
    "created_at": "2025-01-20T19:01:56.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881376099441209615" }]
  },
  {
    "id": "1881416820982223211",
    "edit_history_tweet_ids": ["1881416820982223211"],
    "attachments": { "media_keys": ["3_1881416102900543489"] },
    "note_tweet": {
      "text": "When will we see the first reasoning model grok?\n\nDo we need to include a response length penalty term or is it possible without it?\n\nI don't like the idea that response lengths just keep increasing as we keep training with RL.\nEspecially, when R1 get's above 90+% on basically all benchmarks."
    },
    "text": "When will we see the first reasoning model grok?\n\nDo we need to include a response length penalty term or is it possible without it?\n\nI don't like the idea that response lengths just keep increasing as we keep training with RL.\nEspecially, when R1 get's above 90+% on basically‚Ä¶ https://t.co/8bFkG5w6Xv https://t.co/ScMZoDb0Vy",
    "author_id": "1825243643529027584",
    "created_at": "2025-01-20T19:01:39.000Z"
  },
  {
    "id": "1881416406673109399",
    "edit_history_tweet_ids": ["1881416406673109399"],
    "attachments": { "media_keys": ["3_1881416404370386944"] },
    "note_tweet": {
      "text": "AI is set to drive the creation of 11 million jobs by 2030, as highlighted in the @wef Future of Jobs Report 2025. \n\nRoles like AI specialists and big data experts are at the forefront of this shift, reflecting the growing demand for cutting-edge skills. \n\nAccess the report here: https://t.co/jAhanGz3XC",
      "entities": {
        "mentions": [
          { "start": 82, "end": 86, "username": "wef", "id": "5120691" }
        ],
        "urls": [
          {
            "start": 281,
            "end": 304,
            "url": "https://t.co/jAhanGz3XC",
            "expanded_url": "https://hubs.la/Q0338VJ_0",
            "display_url": "hubs.la/Q0338VJ_0"
          }
        ]
      }
    },
    "text": "AI is set to drive the creation of 11 million jobs by 2030, as highlighted in the @wef Future of Jobs Report 2025. \n\nRoles like AI specialists and big data experts are at the forefront of this shift, reflecting the growing demand for cutting-edge skills. \n\nAccess the report here:‚Ä¶ https://t.co/vNU68HEj23 https://t.co/eK3nytejRY",
    "author_id": "992153930095251456",
    "created_at": "2025-01-20T19:00:01.000Z"
  },
  {
    "id": "1881416331473670229",
    "edit_history_tweet_ids": ["1881416331473670229"],
    "text": "RT @cloneofsimo: Even bitter-er-er lesson is that the more intellectually interesting something is less useful it is\n\nYou would see batshit‚Ä¶",
    "author_id": "354571530",
    "created_at": "2025-01-20T18:59:43.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881389467346547101" }]
  },
  {
    "id": "1881415989512073624",
    "edit_history_tweet_ids": ["1881415989512073624"],
    "text": "R1-Distill-70B on sram accelerators (@GroqInc, @CerebrasSystems, etc) would be a fever dream. 10x speed of o1-mini (https://t.co/VkM589qT5s) with o1-like capabilities/price.",
    "author_id": "1605840745960591360",
    "created_at": "2025-01-20T18:58:21.000Z"
  },
  {
    "id": "1881415744359141858",
    "edit_history_tweet_ids": ["1881415744359141858"],
    "text": "RT @ecats_: Really excited to help recruit for this new and unique role! Apply if you are ready to re-imagine the future üß†‚ú®",
    "author_id": "731538535795163136",
    "created_at": "2025-01-20T18:57:23.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881415037602148383" }]
  },
  {
    "id": "1881415482953380229",
    "edit_history_tweet_ids": ["1881415482953380229"],
    "text": "DeepSeek-R1-Distill-Llama-8B is a monster reasoning model that hallucinates knowledge like crazy. I love it.",
    "author_id": "3378986176",
    "created_at": "2025-01-20T18:56:20.000Z"
  },
  {
    "id": "1881415144825340391",
    "edit_history_tweet_ids": ["1881415144825340391"],
    "note_tweet": {
      "text": "I've heard enough sources say now that software engineering will be automated by the end of this year that it seems pretty clear to me that this will happen. \n\nWhen I tell people outside of labs this, they are still surprised or skeptical. This seems to be because they imagine that \"automated software engineering\" means large layoffs, and 0 people employed as software engineers in 2026. \n\nThat's not what it means. \n\nAutomated software engineering by the end of 2025 means no more interns, no more new grads. It means Cursor getting to $100M in revenue with ~ 30 people. It's the large workforce that didnt happen. Companies will still fight like crazy to hire great engineers. \n\nAutomated software engineering by the end of 2025 doesn't mean that Devin will build Cursor from scratch, with 0 people. It means that Devin will fix bugs and take on bigger and bigger issues while you make breakfast, making code happen in times where it wouldn't have otherwise. \n\nNew software eng grads have about 1-2 years to get as much real world experience as they can and otherwise demonstrate outlier ability. \n\nCompanies whose success depends on tech companies hiring lots of people got some stuff to figure out."
    },
    "text": "I've heard enough sources say now that software engineering will be automated by the end of this year that it seems pretty clear to me that this will happen. \n\nWhen I tell people outside of labs this, they are still surprised or skeptical. This seems to be because they imagine‚Ä¶ https://t.co/Ec3qQeQHy7",
    "author_id": "64183939",
    "created_at": "2025-01-20T18:55:00.000Z"
  },
  {
    "id": "1881414969075671087",
    "edit_history_tweet_ids": ["1881414969075671087"],
    "attachments": { "media_keys": ["3_1881414817161850880"] },
    "text": "R1 got me in the mood\n\nGIVE ME MOOOORE AI https://t.co/ffvRqkxAVj",
    "author_id": "1825243643529027584",
    "created_at": "2025-01-20T18:54:18.000Z"
  },
  {
    "id": "1881414960003334167",
    "edit_history_tweet_ids": ["1881414960003334167"],
    "text": "RT @R_H_Ebright: 2014 is the start date of NIH grant AI110964--the NIH grant that funded Wuhan research that caused COVID and that Fauci ap‚Ä¶",
    "author_id": "7284012",
    "created_at": "2025-01-20T18:54:16.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881384761597493551" }]
  },
  {
    "id": "1881414592078950618",
    "edit_history_tweet_ids": ["1881414592078950618"],
    "attachments": {
      "media_keys": [
        "3_1881412422872756224",
        "3_1881412636429930496",
        "3_1881413463513133056",
        "3_1881413804954689536"
      ]
    },
    "note_tweet": {
      "text": "R1 paper is short but sexy\n\nR1 it really is Sonnet 3.5 at home\n\nthis one is nice too, but I'm not so sure if it's a good thing - wouldn't we expect it to taper off, or even go down after TONS of training steps?\n\nthe table also gets me going\nbut I would appreciate it if they included the original numbers for these models for comparison\n\ni love this one: distillation is the way forward"
    },
    "text": "R1 paper is short but sexy\n\nR1 it really is Sonnet 3.5 at home\n\nthis one is nice too, but I'm not so sure if it's a good thing - wouldn't we expect it to taper off, or even go down after TONS of training steps?\n\nthe table also gets me going\nbut I would appreciate it if they‚Ä¶ https://t.co/71EauUe6LH https://t.co/SENzbvK7ZA",
    "author_id": "1825243643529027584",
    "created_at": "2025-01-20T18:52:48.000Z"
  },
  {
    "id": "1881414252801732876",
    "edit_history_tweet_ids": ["1881414252801732876"],
    "in_reply_to_user_id": "19111917",
    "text": "@mbusigin ?",
    "author_id": "1365020011123773442",
    "created_at": "2025-01-20T18:51:27.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881347203303887108" }]
  },
  {
    "id": "1881414178730394031",
    "edit_history_tweet_ids": ["1881414178730394031"],
    "text": "If you are a good builder and want to build something massive, @ycombinator is ALWAYS a no-brainer! https://t.co/hJHPjGiSi2",
    "author_id": "1583730714",
    "created_at": "2025-01-20T18:51:09.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881392930872807525" }]
  },
  {
    "id": "1881414042247651484",
    "edit_history_tweet_ids": ["1881414042247651484"],
    "in_reply_to_user_id": "192201556",
    "text": "@teortaxesTex Glad i don‚Äôt live there ü§ó",
    "author_id": "1365020011123773442",
    "created_at": "2025-01-20T18:50:37.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881345693597765870" }]
  },
  {
    "id": "1881414037323604224",
    "edit_history_tweet_ids": ["1881414037323604224"],
    "text": "RT @casper_hansen_: The DeepSeek R1 training procedure confused me at first. My brain refused to accept this powerful model could be incred‚Ä¶",
    "author_id": "2854214132",
    "created_at": "2025-01-20T18:50:36.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881404604518392144" }]
  },
  {
    "id": "1881413939617038742",
    "edit_history_tweet_ids": ["1881413939617038742"],
    "text": "ü§£ https://t.co/eSap9tXX3O",
    "author_id": "1583730714",
    "created_at": "2025-01-20T18:50:12.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881339827200880896" }]
  },
  {
    "id": "1881413601690599657",
    "edit_history_tweet_ids": ["1881413601690599657"],
    "text": "deepseek is rewriting history rn!! https://t.co/pk4wyb0vN5",
    "author_id": "70831441",
    "created_at": "2025-01-20T18:48:52.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }]
  },
  {
    "id": "1881413596430872814",
    "edit_history_tweet_ids": ["1881413596430872814"],
    "text": "Yes! You can run R1 on latest vLLM. Because it has the same architecture as V3, you can use the guide here https://t.co/Mu1pWNVE7l https://t.co/94ZgTkZ5lc",
    "author_id": "1774187564276289536",
    "created_at": "2025-01-20T18:48:51.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }]
  },
  {
    "id": "1881413227789336582",
    "edit_history_tweet_ids": ["1881413227789336582"],
    "in_reply_to_user_id": "1718879852827484160",
    "text": "@nrehiew_ Anthropic Sonnet almost feels like they distilled cot back tbh.",
    "author_id": "938616384572948480",
    "created_at": "2025-01-20T18:47:23.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881379264886710601" }]
  },
  {
    "id": "1881413088794349838",
    "edit_history_tweet_ids": ["1881413088794349838"],
    "in_reply_to_user_id": "800854096219471872",
    "attachments": { "media_keys": ["3_1881412896502202368"] },
    "text": "Naval really likes my content!\n\nfollow me if you haven't ;) https://t.co/BBW4qeiovI",
    "author_id": "800854096219471872",
    "created_at": "2025-01-20T18:46:49.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881398653845410286" }]
  },
  {
    "id": "1881413031231660375",
    "edit_history_tweet_ids": ["1881413031231660375"],
    "in_reply_to_user_id": "192201556",
    "attachments": { "media_keys": ["3_1881412979817689088"] },
    "text": "it does eventually crack the problem https://t.co/CqjzX9V8iq",
    "author_id": "192201556",
    "created_at": "2025-01-20T18:46:36.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881412032559554648" }]
  },
  {
    "id": "1881412975501939106",
    "edit_history_tweet_ids": ["1881412975501939106"],
    "in_reply_to_user_id": "245262377",
    "text": "Gonna try &gt;=4-bit on 3 M2 Ultras next.. let's see if we can get it to run fast with minimal quality loss.\n\nExample script here: https://t.co/jjArrKb59T",
    "author_id": "245262377",
    "created_at": "2025-01-20T18:46:22.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881412271236346233" }]
  },
  {
    "id": "1881412831306002897",
    "edit_history_tweet_ids": ["1881412831306002897"],
    "attachments": { "media_keys": ["3_1881412685255905280"] },
    "note_tweet": {
      "text": "Summary of the DeepSeek models released today!\n\nDeepSeek-R1-Zero\n\n> Base Model: DeepSeek-V3-Base\n> Training Approach: Pure reinforcement learning (RL) without any supervised fine-tuning (SFT) as a preliminary step\n> RL Algorithm: Group Relative Policy Optimization (GRPO), which foregoes the critic model and estimates the baseline from group scores\n> Reward Modeling: Uses a rule-based reward system with accuracy rewards (for correct responses) and format rewards (for adhering to specified output formats)\n> Training Template: A simple template that requires the model to produce a reasoning process followed by the final answer, enclosed in specific tags\n> Performance: Achieves significant improvements in reasoning benchmarks, such as increasing the pass@1 score on AIME 2024 from 15.6% to 71.0%\n> Challenges: Faces issues like poor readability and language mixing\n\nDeepSeek-R1\n\n> Base Model: DeepSeek-V3-Base\n> Training Approach: Incorporates multi-stage training and cold-start data before RL\n> Cold Start: Collects thousands of long Chain-of-Thought (CoT) data to fine-tune the model as the initial RL actor\n> Reasoning-oriented RL: Applies large-scale RL training to enhance reasoning capabilities, focusing on tasks like coding, mathematics, and logic reasoning\n> Rejection Sampling and SFT: Uses rejection sampling to collect SFT data from the RL checkpoint, combined with supervised data from DeepSeek-V3 in various domains\n> Secondary RL Stage: Implements a secondary RL stage to align the model with human preferences, improving helpfulness and harmlessness while refining reasoning capabilities\n\n> Performance: Achieves performance comparable to OpenAI-o1-1217 on reasoning tasks and excels in various benchmarks, including MMLU, MATH-500, and Codeforces\n\nDistillation: Smaller Models\n\n> Base Models: Qwen2.5 and Llama series (1.5B, 7B, 8B, 14B, 32B, 70B)\n> Training Approach: Direct distillation from DeepSeek-R1 to smaller dense models using 800k curated samples\n> Performance: Distilled models, such as R1-Distill-Qwen-7B and R1-Distill-Qwen-32B, outperform non-reasoning models like GPT-4o-0513 and set new records on reasoning benchmark"
    },
    "text": "Summary of the DeepSeek models released today!\n\nDeepSeek-R1-Zero\n\n&gt; Base Model: DeepSeek-V3-Base\n&gt; Training Approach: Pure reinforcement learning (RL) without any supervised fine-tuning (SFT) as a preliminary step\n&gt; RL Algorithm: Group Relative Policy Optimization (GRPO), which‚Ä¶ https://t.co/RK3kUHAXhf https://t.co/Iv1hduuVdM",
    "author_id": "874987512850128897",
    "created_at": "2025-01-20T18:45:48.000Z"
  },
  {
    "id": "1881412483841425527",
    "edit_history_tweet_ids": ["1881412483841425527"],
    "in_reply_to_user_id": "972435243876544512",
    "text": "@StringChaos Who ever has the largest diverse prompt set wins.",
    "author_id": "938616384572948480",
    "created_at": "2025-01-20T18:44:25.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881406348610650412" }]
  },
  {
    "id": "1881412365977309628",
    "edit_history_tweet_ids": ["1881412365977309628"],
    "in_reply_to_user_id": "1641378826537295874",
    "text": "@deepseek_ai Chat &amp; vote at https://t.co/gxIFU9kIc2!",
    "author_id": "1641378826537295874",
    "created_at": "2025-01-20T18:43:57.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881412277053919426" }]
  },
  {
    "id": "1881412277053919426",
    "edit_history_tweet_ids": ["1881412277053919426"],
    "in_reply_to_user_id": "1641378826537295874",
    "text": "@deepseek_ai DeepSeek-R1 technical report\nhttps://t.co/VePF3wPZbb",
    "author_id": "1641378826537295874",
    "created_at": "2025-01-20T18:43:36.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881412232204206186" }]
  },
  {
    "id": "1881412271236346233",
    "edit_history_tweet_ids": ["1881412119217987680", "1881412271236346233"],
    "attachments": { "media_keys": ["7_1881411953492692993"] },
    "text": "DeepSeek R1 671B running on 2 M2 Ultras faster than reading speed.\n\nGetting close to open-source O1, at home, on consumer hardware.\n\nWith mlx.distributed and mlx-lm, 3-bit quantization (~4 bpw) https://t.co/RnkYxwZG3c",
    "author_id": "245262377",
    "created_at": "2025-01-20T18:43:35.000Z"
  },
  {
    "id": "1881412232204206186",
    "edit_history_tweet_ids": ["1881412232204206186"],
    "in_reply_to_user_id": "1641378826537295874",
    "text": "@deepseek_ai DeepSeek-R1 release\nhttps://t.co/wHrPgRrSSm",
    "author_id": "1641378826537295874",
    "created_at": "2025-01-20T18:43:25.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881318130334814301" },
      { "type": "replied_to", "id": "1881411458678014215" }
    ]
  },
  {
    "id": "1881412167855218771",
    "edit_history_tweet_ids": ["1881412167855218771"],
    "in_reply_to_user_id": "783098774130401280",
    "text": "this is the name of the paper:\n\"Human Side of Tesla Autopilot: Exploration of Functional Vigilance in Real-World Human-Machine Collaboration\" (Fridman et al., 2018)\n\ni'm sure it's still out there somewhere",
    "author_id": "783098774130401280",
    "created_at": "2025-01-20T18:43:10.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881411595974369357" }]
  },
  {
    "id": "1881412118563758294",
    "edit_history_tweet_ids": ["1881412118563758294"],
    "text": "Writing out well-stated prompts is a forcing function to think through a problem clearly",
    "author_id": "1395499471",
    "created_at": "2025-01-20T18:42:58.000Z"
  },
  {
    "id": "1881412073844023586",
    "edit_history_tweet_ids": ["1881412073844023586"],
    "text": "RT @CoreyAtad: even a single drop of AI is too much, says person who‚Äôs been watching movies with algorithmically generated effects for 25 y‚Ä¶",
    "author_id": "1618757089",
    "created_at": "2025-01-20T18:42:48.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880993828288795130" }]
  },
  {
    "id": "1881412032559554648",
    "edit_history_tweet_ids": ["1881412032559554648"],
    "attachments": { "media_keys": ["3_1881411317736554496"] },
    "text": "‚Äúperhaps the guinea pig can be used as a rope or something‚Äù\nR1-llama-8B has all the characteristic fretful silliness of R1-preview. it's not much use but you can see the diversity that only free exploration could unearth. It remembers your silly riddles. It's not a Riddler model. https://t.co/86eX8yUbDt",
    "author_id": "192201556",
    "created_at": "2025-01-20T18:42:38.000Z"
  },
  {
    "id": "1881411925655101698",
    "edit_history_tweet_ids": ["1881411925655101698"],
    "text": "RT @ArchAngelDDay: Wrote a short blurb on a collab technique I've used in the past, when needing to use another hacker's private research!‚Ä¶",
    "author_id": "260411518",
    "created_at": "2025-01-20T18:42:12.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881410867092509093" }]
  },
  {
    "id": "1881411595974369357",
    "edit_history_tweet_ids": ["1881411595974369357"],
    "note_tweet": {
      "text": "most people don't know that lex fridman's bizarre character arc actually started in research.  here's the real story:\n\n> around 2018 tesla deploys Autopilot, software that lets the car drive for you on highways. but only as your hands are on the steering wheel\n> all research finds that people stop paying attention  when they are just holding their hands on a wheel without doing anything\n> one person wrote a paper saying that actually, contrary to every other finding ‚Äì¬† humans do pay attention while sitting there and doing nothing! \n> that person is lex fridman\n> turns out the paper only used a sample of n=21, and was generally criticized for lack of rigor\n> lex somehow still leverages this into a friendship with elon (still unsure how)\n> lex gets elon to come on his \"AI Podcast\" in like the third episode\n> lex uses his part-time research position at MIT to cosplay as a professor online\n> lex gets a lot more well-known guests to come on the pod\n> now podcast is everywhere and lex wants to befriend putin\n\nps. the driver monitoring paper is now scrubbed from the internet"
    },
    "text": "most people don't know that lex fridman's bizarre character arc actually started in research.  here's the real story:\n\n&gt; around 2018 tesla deploys Autopilot, software that lets the car drive for you on highways. but only as your hands are on the steering wheel\n&gt; all research‚Ä¶ https://t.co/mQ9GqUGCdw https://t.co/C7hb7U29IS",
    "author_id": "783098774130401280",
    "created_at": "2025-01-20T18:40:54.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881245844122570903" }]
  },
  {
    "id": "1881411500151386566",
    "edit_history_tweet_ids": ["1881411500151386566"],
    "attachments": { "media_keys": ["3_1881410801099055104"] },
    "text": "Maybe the most interesting section of the @deepseek_ai paper!!\n\n&gt; No MCTS for search and data generation\n&gt; No Process Reward Models (PRM) for RL https://t.co/u0CHijM1xY",
    "author_id": "1141052916570214400",
    "created_at": "2025-01-20T18:40:31.000Z"
  },
  {
    "id": "1881411458678014215",
    "edit_history_tweet_ids": ["1881411458678014215"],
    "attachments": { "media_keys": ["3_1881407238197407745"] },
    "note_tweet": {
      "text": "DeepSeek-R1 is now in the Arenaüî•\n\nCongrats @deepseek_ai on R1 release! An open reasoning model matching OpenAI o1 in hard benchmarks like GPQA/SWE-Bench/AIME!\n\nNow for the real-world challenge‚ÄîR1 is in https://t.co/azF9dwf43Y for human evaluation. Bring your toughest prompts and challenge it!",
      "entities": {
        "mentions": [
          {
            "start": 43,
            "end": 55,
            "username": "deepseek_ai",
            "id": "1714580962569588736"
          }
        ],
        "urls": [
          {
            "start": 202,
            "end": 225,
            "url": "https://t.co/azF9dwf43Y",
            "expanded_url": "http://lmarena.ai",
            "display_url": "lmarena.ai"
          }
        ]
      }
    },
    "text": "DeepSeek-R1 is now in the Arenaüî•\n\nCongrats @deepseek_ai on R1 release! An open reasoning model matching OpenAI o1 in hard benchmarks like GPQA/SWE-Bench/AIME!\n\nNow for the real-world challenge‚ÄîR1 is in https://t.co/gxIFU9kIc2 for human evaluation. Bring your toughest prompts and‚Ä¶ https://t.co/qfUw9QFUa7 https://t.co/UnJHdwcDsP",
    "author_id": "1641378826537295874",
    "created_at": "2025-01-20T18:40:21.000Z"
  },
  {
    "id": "1881410967474688246",
    "edit_history_tweet_ids": ["1881410967474688246"],
    "attachments": { "media_keys": ["3_1881410761718697984"] },
    "text": "normalize including failed attempts https://t.co/2YzTTs8Ah8",
    "author_id": "1825243643529027584",
    "created_at": "2025-01-20T18:38:24.000Z"
  },
  {
    "id": "1881410672204132542",
    "edit_history_tweet_ids": ["1881410672204132542"],
    "in_reply_to_user_id": "874987512850128897",
    "text": "@reach_vb Unbelievable.\n\nWe will have super smart 1B models in the future, running locally on our phone.",
    "author_id": "800854096219471872",
    "created_at": "2025-01-20T18:37:13.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881319500089634954" }]
  },
  {
    "id": "1881410470713954788",
    "edit_history_tweet_ids": ["1881410278568730971", "1881410470713954788"],
    "text": "Excited to share we are hiring for a new type of scholar role. \n\nAlgorithm interface scholars will re-imagine how humans interact with algorithms. \n\nThese scholars will lead the frontier in UI-algorithm co-design. üî•\n\nJoin us at @CohereForAI @cohere ‚ú®\n\nhttps://t.co/w9wYXGi8iG",
    "author_id": "731538535795163136",
    "created_at": "2025-01-20T18:36:25.000Z"
  },
  {
    "id": "1881410296197300417",
    "edit_history_tweet_ids": ["1881410296197300417"],
    "attachments": { "media_keys": ["3_1881410258725208064"] },
    "text": "[REDACTED] GC best GC. https://t.co/7ru9vujJFl",
    "author_id": "1499415401763115019",
    "created_at": "2025-01-20T18:35:44.000Z"
  },
  {
    "id": "1881409912808656955",
    "edit_history_tweet_ids": ["1881409912808656955"],
    "attachments": { "media_keys": ["3_1881335441519198208"] },
    "text": "RT @leloykun: soon we'll have reasoning finetuning speedruns and y'all are gonna love and hate it https://t.co/tpWjnGcTzs",
    "author_id": "821092604821536768",
    "created_at": "2025-01-20T18:34:12.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881335959574458617" }]
  },
  {
    "id": "1881409605722657213",
    "edit_history_tweet_ids": ["1881409605722657213"],
    "text": "RT @pablovelagomez1: @_akhaliq Wow, that worked really well. Made a sudoku game from it",
    "author_id": "2465283662",
    "created_at": "2025-01-20T18:32:59.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881409420183412830" }]
  },
  {
    "id": "1881409072165236894",
    "edit_history_tweet_ids": ["1881409072165236894"],
    "text": "The hard part was never the doing. It was knowing what to do.",
    "author_id": "788107483306942464",
    "created_at": "2025-01-20T18:30:52.000Z"
  },
  {
    "id": "1881408406596338094",
    "edit_history_tweet_ids": ["1881408406596338094"],
    "text": "RT @hsu_steve: There may be some sarcasm here. He attended a very good university in China (Zhejiang University), but it's not that famous‚Ä¶",
    "author_id": "192201556",
    "created_at": "2025-01-20T18:28:13.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881405336793276874" }]
  },
  {
    "id": "1881408316276179006",
    "edit_history_tweet_ids": ["1881408316276179006"],
    "text": "this is my take too https://t.co/43FlgWLbGT",
    "author_id": "1495078042498002950",
    "created_at": "2025-01-20T18:27:52.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881386934557397444" }]
  },
  {
    "id": "1881407749617283204",
    "edit_history_tweet_ids": ["1881407749617283204"],
    "text": "RT @davidpfahler: It‚Äòs actually baffling how @jeremyphoward has been saying for years that you shouldn‚Äôt stop training just because validat‚Ä¶",
    "author_id": "175282603",
    "created_at": "2025-01-20T18:25:37.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881251644467499226" }]
  },
  {
    "id": "1881406988833415529",
    "edit_history_tweet_ids": ["1881406988833415529"],
    "text": "incredible work, amazing results, and yet another reminder of how disappointingly boring and narrow the scope of typical evals is\n\n(multiple choice tests, narrow code gen, and math word problems *yawn*) https://t.co/bkrWAOMDfg",
    "author_id": "1605274291569799168",
    "created_at": "2025-01-20T18:22:35.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881316758218535039" }]
  },
  {
    "id": "1881406348610650412",
    "edit_history_tweet_ids": ["1881406348610650412"],
    "in_reply_to_user_id": "938616384572948480",
    "text": "@_arohan_ What does large look like these days üôà?\nFor (competition) coding, you can get maybe 50-100k problems with meticulous problem collection.",
    "author_id": "972435243876544512",
    "created_at": "2025-01-20T18:20:03.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881376463905325080" }]
  },
  {
    "id": "1881406157874729177",
    "edit_history_tweet_ids": ["1881406157874729177"],
    "in_reply_to_user_id": "33521530",
    "text": "@swyx Leaving this here \n\nhttps://t.co/qRKYfFxyJO",
    "author_id": "825766640",
    "created_at": "2025-01-20T18:19:17.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881400671246880954" }]
  },
  {
    "id": "1881405666520416761",
    "edit_history_tweet_ids": ["1881405533636497713", "1881405666520416761"],
    "text": "No SFT before RL is just a hyper parameter wont be consequential decision unless SFT is messed up by overdoing it. Not sure why people got nerdsniped by it.",
    "author_id": "938616384572948480",
    "created_at": "2025-01-20T18:17:20.000Z"
  },
  {
    "id": "1881405429697425879",
    "edit_history_tweet_ids": ["1881405429697425879"],
    "attachments": { "media_keys": ["3_1881405427520303105"] },
    "text": "53 years of federal service. Thank you Biden. https://t.co/lOzsY6iyve",
    "author_id": "441465751",
    "created_at": "2025-01-20T18:16:23.000Z"
  },
  {
    "id": "1881405361200234933",
    "edit_history_tweet_ids": ["1881405361200234933"],
    "in_reply_to_user_id": "2465283662",
    "text": "app: https://t.co/yL4EvPFZpl",
    "author_id": "2465283662",
    "created_at": "2025-01-20T18:16:07.000Z",
    "referenced_tweets": [{ "type": "replied_to", "id": "1881405358931059004" }]
  },
  {
    "id": "1881405358931059004",
    "edit_history_tweet_ids": ["1881405358931059004"],
    "attachments": { "media_keys": ["3_1881405013378949120"] },
    "text": "this is insane ü§Ø\n\nDeepSeek-R1 Coder is now available in anychat\n\nits like cursor or v0 in the browser\n\nmade a tic tac toe game in seconds\n\nwill try to keep it working as long as I have credits üòÄ https://t.co/YFtqP4D9Xw",
    "author_id": "2465283662",
    "created_at": "2025-01-20T18:16:07.000Z"
  },
  {
    "id": "1881404791181750338",
    "edit_history_tweet_ids": ["1881404791181750338"],
    "text": "RT @weaviate_io: Looking for the best embedding model for your documents mixed with images and text?\n\nWeaviate now supports @VoyageAI‚Äôs mul‚Ä¶",
    "author_id": "95016894",
    "created_at": "2025-01-20T18:13:51.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881386264697397632" }]
  },
  {
    "id": "1881404542509777114",
    "edit_history_tweet_ids": ["1881404542509777114"],
    "text": "I love you guys!  So much! üòçü•∞ü§© https://t.co/6xtM8zb6gr",
    "author_id": "2854214132",
    "created_at": "2025-01-20T18:12:52.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318138937233664" }]
  },
  {
    "id": "1881402637008142481",
    "edit_history_tweet_ids": ["1881402637008142481"],
    "text": "this is pretty huge https://t.co/IiD5QaRdsj",
    "author_id": "260411518",
    "created_at": "2025-01-20T18:05:18.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318138937233664" }]
  },
  {
    "id": "1881401994310774969",
    "edit_history_tweet_ids": ["1881401994310774969"],
    "text": "RT @0xTyllen: Nine months ago we ushered in AI Payments to the mainstream, with our announcement of @PaymanAI. Today we‚Äôre excited to launc‚Ä¶",
    "author_id": "2728439146",
    "created_at": "2025-01-20T18:02:44.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881398365579350439" }]
  },
  {
    "id": "1881401836483252705",
    "edit_history_tweet_ids": ["1881401836483252705"],
    "note_tweet": {
      "text": "The past few years of LLM research show that if you can (i) define a meaningful objective and (ii) leave enough \"room\" for the system to fit it, like CoT, tool use, or multi-stage modules, we have plenty of ways of fitting your downstream signal.\n\nThe hard part is defining the objective & the scaffolding of that \"room\". That's why DSPy exists: you handle the program and the metric; you delegate the fitting of prompts or weights."
    },
    "text": "The past few years of LLM research show that if you can (i) define a meaningful objective and (ii) leave enough \"room\" for the system to fit it, like CoT, tool use, or multi-stage modules, we have plenty of ways of fitting your downstream signal.\n\nThe hard part is defining the‚Ä¶ https://t.co/hE8vNJFRd9 https://t.co/XCul7uwtJ2",
    "author_id": "1605274291569799168",
    "created_at": "2025-01-20T18:02:07.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881398258318369136" }]
  },
  {
    "id": "1881401711929246086",
    "edit_history_tweet_ids": ["1881401711929246086"],
    "text": "RT @4katluvrs: Who chose this guy to sing the National Anthem for the inauguration?? There are so many better singers out there who could h‚Ä¶",
    "author_id": "441465751",
    "created_at": "2025-01-20T18:01:37.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881401126970679778" }]
  },
  {
    "id": "1881400824720711705",
    "edit_history_tweet_ids": ["1881400824720711705"],
    "attachments": { "media_keys": ["3_1881173627225116672"] },
    "text": "RT @onlyyagirl_: #same https://t.co/FTcEpWAIh2",
    "author_id": "821092604821536768",
    "created_at": "2025-01-20T17:58:06.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881173634481570166" }]
  },
  {
    "id": "1881400671246880954",
    "edit_history_tweet_ids": ["1881400671246880954"],
    "text": "recently spoke to a good consumer ai founder who got turned down by a VC with a \"what if Apple does this?\"\n\nI think I lean more positive than most when it comes to Apple Intelligence, but... come on man that VC is in the wrong business lmao",
    "author_id": "33521530",
    "created_at": "2025-01-20T17:57:29.000Z"
  },
  {
    "id": "1881400577839759681",
    "edit_history_tweet_ids": ["1881400577839759681"],
    "attachments": { "media_keys": ["3_1881397664610144256"] },
    "text": "RT @nanulled: Seeing what R1 can do I think that DeepSeek R2 will be superhuman (99.9%) in many domains https://t.co/xCjzlzeKyW",
    "author_id": "192201556",
    "created_at": "2025-01-20T17:57:07.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881397813998989793" }]
  },
  {
    "id": "1881400285261930615",
    "edit_history_tweet_ids": ["1881400285261930615"],
    "text": "idk who needs to read this but you need to read this https://t.co/QhG5lBpeTh",
    "author_id": "192201556",
    "created_at": "2025-01-20T17:55:57.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1748601754759864816" }]
  },
  {
    "id": "1881400054633893991",
    "edit_history_tweet_ids": ["1881400054633893991"],
    "text": "RT @krishnanrohit: &gt; say we know how to build AGI\n&gt; say we're now looking at ASI\n&gt; closed door govt sessions for \"PhD level model\"\n&gt; consta‚Ä¶",
    "author_id": "821092604821536768",
    "created_at": "2025-01-20T17:55:02.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881343795918503955" }]
  },
  {
    "id": "1881399873775489076",
    "edit_history_tweet_ids": ["1881399873775489076"],
    "note_tweet": {
      "text": "Benchmarks were really key in the evolution of systems research and in ML when key research was about core methods (think optimizers or architectures).\n\nAt this point now, benchmarking is starting to be counterproductive. Yes, o1 impressed people by being good at some math benchmarks, but replicating that win doesn't actually replicate o1."
    },
    "text": "Benchmarks were really key in the evolution of systems research and in ML when key research was about core methods (think optimizers or architectures).\n\nAt this point now, benchmarking is starting to be counterproductive. Yes, o1 impressed people by being good at some math‚Ä¶ https://t.co/VCCrebHapK https://t.co/XCul7uwtJ2",
    "author_id": "1605274291569799168",
    "created_at": "2025-01-20T17:54:19.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881398258318369136" }]
  },
  {
    "id": "1881399579079512502",
    "edit_history_tweet_ids": ["1881399579079512502"],
    "text": "RT @rtk254: Video models != world models \n\n\"We find that across a range of current models (Sora, Runway, Pika, Lumiere, Stable Video Diffus‚Ä¶",
    "author_id": "10834752",
    "created_at": "2025-01-20T17:53:09.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881096518234726555" }]
  },
  {
    "id": "1881399501208072619",
    "edit_history_tweet_ids": ["1881399501208072619"],
    "text": "Nice visualizations are important for popular appeal https://t.co/5u9eZ7vaEv",
    "author_id": "192201556",
    "created_at": "2025-01-20T17:52:50.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881366695178367069" }]
  },
  {
    "id": "1881399374561083539",
    "edit_history_tweet_ids": ["1881399374561083539"],
    "attachments": { "media_keys": ["3_1881399367342403584"] },
    "text": "Find a job that:\n- you‚Äôre good at\n- pays well \n- you love\n\nReally rare to see a technical paper written with such palpable passion and i think thats beautiful https://t.co/sSQZ3lfefH https://t.co/kBJ4WmCeu0",
    "author_id": "1718879852827484160",
    "created_at": "2025-01-20T17:52:20.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881322975313739779" }]
  },
  {
    "id": "1881399176203997475",
    "edit_history_tweet_ids": ["1881399176203997475"],
    "in_reply_to_user_id": "1202267633049100291",
    "text": "one thing I really loved about this release is distilled variants üòç https://t.co/4iSszaHKct",
    "author_id": "1202267633049100291",
    "created_at": "2025-01-20T17:51:32.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881318135850213834" },
      { "type": "replied_to", "id": "1881398626058166434" }
    ]
  },
  {
    "id": "1881398988131455276",
    "edit_history_tweet_ids": ["1881398988131455276"],
    "text": "I've been saying this for months.\nHow neat, then, that we've got superhuman programming copilots first. https://t.co/J6208GVkDN",
    "author_id": "192201556",
    "created_at": "2025-01-20T17:50:48.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881383080528924868" }]
  },
  {
    "id": "1881398741154083082",
    "edit_history_tweet_ids": ["1881398741154083082"],
    "attachments": { "media_keys": ["3_1881319080285646848"] },
    "text": "RT @TheXeophon: The models, they just want to yap https://t.co/mCXT4kX5lW",
    "author_id": "821092604821536768",
    "created_at": "2025-01-20T17:49:49.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881319117480939630" }]
  },
  {
    "author_id": "800854096219471872",
    "note_tweet": {
      "text": "This \"Aha moment\" in the DeepSeek-R1 paper is huge:\n\nPure reinforcement learning (RL) enables an LLM to automatically learn to think and reflect.\n\nThis challenges the prior belief that replicating OpenAI's o1 reasoning models requires extensive CoT data. It turns out you just need to give it the right incentives.\n\nWe are so back in the AlphaGo excitement era: by playing countless Go games and maximizing the reward function (winning the game) using pure RL, AlphaGo beat the best human players.\n\nNow we are entering the LLM RL era.\n2025 could be the year of RL."
    },
    "text": "This \"Aha moment\" in the DeepSeek-R1 paper is huge:\n\nPure reinforcement learning (RL) enables an LLM to automatically learn to think and reflect.\n\nThis challenges the prior belief that replicating OpenAI's o1 reasoning models requires extensive CoT data. It turns out you just‚Ä¶ https://t.co/dIJ3l1XCGk https://t.co/5qBR75LD0n",
    "id": "1881398653845410286",
    "created_at": "2025-01-20T17:49:28.000Z",
    "edit_history_tweet_ids": ["1881398653845410286"],
    "attachments": { "media_keys": ["3_1881392953555615744"] }
  },
  {
    "author_id": "1202267633049100291",
    "text": "I can't wait to the day we get infinitely good multimodal reasoning models with Apache 2.0 license ü§†\n\nmaybe R1-vision (let's call it that) will be that ü•π",
    "id": "1881398626058166434",
    "created_at": "2025-01-20T17:49:21.000Z",
    "edit_history_tweet_ids": ["1881398626058166434"]
  },
  {
    "author_id": "1605274291569799168",
    "text": "I would caution in expecting this to be a good model in general and would lean towards expecting it not to work all that well within bespoke pipelines or for more open-ended tasks out of the box *just yet*.",
    "id": "1881398499721585108",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881398258318369136" }
    ],
    "in_reply_to_user_id": "1605274291569799168",
    "created_at": "2025-01-20T17:48:51.000Z",
    "edit_history_tweet_ids": ["1881398499721585108"]
  },
  {
    "author_id": "829108178059096064",
    "text": "RT @1a3orn: The R1 paper is great, but includes ~approximately nothing~ about the details of the RL environments.\n\nIt's worth noticing. If‚Ä¶",
    "id": "1881398283903648209",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881386146825142408" }],
    "created_at": "2025-01-20T17:48:00.000Z",
    "edit_history_tweet_ids": ["1881398283903648209"]
  },
  {
    "author_id": "1605274291569799168",
    "text": "Excitement is justified, but the most reinforced takeaways from R1 seem to be that:\n\n- If you know how to measure a downstream outcome, you should RL your way out of it. (It's basically a many-task STaR?)\n\n- The math and coding tasks o1 benchmarked on aren't all that difficult.",
    "id": "1881398258318369136",
    "created_at": "2025-01-20T17:47:54.000Z",
    "edit_history_tweet_ids": ["1881398258318369136"]
  },
  {
    "author_id": "185910194",
    "text": "@swyx No, but I desperately need a model that can recognize \"pyproject.toml\", so I might need to try it out üòÉ",
    "id": "1881398174985945162",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881392910459150496" }
    ],
    "in_reply_to_user_id": "33521530",
    "created_at": "2025-01-20T17:47:34.000Z",
    "edit_history_tweet_ids": ["1881398174985945162"]
  },
  {
    "author_id": "2465283662",
    "note_tweet": {
      "text": "its now available in ai-gradio      \n\npip install --upgrade \"ai-gradio[deepseek]\"    \n\nimport gradio as gr   \nimport ai_gradio      \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry).launch()    \n\ngithub: https://t.co/f2s3ck8OL9 \n\nquick start colab: https://t.co/j6kyZOfoAb",
      "entities": {
        "urls": [
          {
            "start": 223,
            "end": 246,
            "url": "https://t.co/f2s3ck8OL9",
            "expanded_url": "https://github.com/AK391/ai-gradio",
            "display_url": "github.com/AK391/ai-gradio"
          },
          {
            "start": 268,
            "end": 291,
            "url": "https://t.co/j6kyZOfoAb",
            "expanded_url": "https://colab.research.google.com/drive/1Ilz8LRQp0lQHxXu26PEJkXtXmvj1MrFe?usp=sharing",
            "display_url": "colab.research.google.com/drive/1Ilz8LRQ‚Ä¶"
          }
        ]
      }
    },
    "text": "@skirano its now available in ai-gradio      \n\npip install --upgrade \"ai-gradio[deepseek]\"    \n\nimport gradio as gr   \nimport ai_gradio      \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry).launch()    \n\ngithub: https://t.co/vy68ARTizv \n\nquick start colab:‚Ä¶ https://t.co/EYjPRSVjb1 https://t.co/2q5rXWBKx3",
    "id": "1881398089740947629",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881351047312191960" }
    ],
    "in_reply_to_user_id": "73105934",
    "created_at": "2025-01-20T17:47:13.000Z",
    "edit_history_tweet_ids": ["1881398089740947629"],
    "attachments": { "media_keys": ["3_1881398023667716097"] }
  },
  {
    "author_id": "192201556",
    "text": "between r1 and LittleRedBook America keeps raking in cultural Ls in 2025 and it's all self-inflicted https://t.co/T4EoEoLlyY",
    "id": "1881397859821695196",
    "created_at": "2025-01-20T17:46:19.000Z",
    "edit_history_tweet_ids": ["1881397859821695196"],
    "attachments": { "media_keys": ["3_1881397554497134594"] }
  },
  {
    "author_id": "155933891",
    "text": "RT @natolambert: OpenAI definitely still has a lead on reasoning models, but they're going to destroy their motivation and culture if their‚Ä¶",
    "id": "1881397620029157657",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881371174090756417" }],
    "created_at": "2025-01-20T17:45:21.000Z",
    "edit_history_tweet_ids": ["1881397620029157657"]
  },
  {
    "author_id": "2465283662",
    "note_tweet": {
      "text": "its now available in ai-gradio      \n\npip install --upgrade \"ai-gradio[deepseek]\"    \n\nimport gradio as gr   \nimport ai_gradio      \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry, ).launch()    \n\ngithub: https://t.co/f2s3ck8gVB \n\nquick start colab: https://t.co/j6kyZOeQKD",
      "entities": {
        "urls": [
          {
            "start": 225,
            "end": 248,
            "url": "https://t.co/f2s3ck8gVB",
            "expanded_url": "https://github.com/AK391/ai-gradio",
            "display_url": "github.com/AK391/ai-gradio"
          },
          {
            "start": 270,
            "end": 293,
            "url": "https://t.co/j6kyZOeQKD",
            "expanded_url": "https://colab.research.google.com/drive/1Ilz8LRQp0lQHxXu26PEJkXtXmvj1MrFe?usp=sharing",
            "display_url": "colab.research.google.com/drive/1Ilz8LRQ‚Ä¶"
          }
        ]
      }
    },
    "text": "@Teknium1 its now available in ai-gradio      \n\npip install --upgrade \"ai-gradio[deepseek]\"    \n\nimport gradio as gr   \nimport ai_gradio      \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry, ).launch()    \n\ngithub: https://t.co/vy68ARSKJX \n\nquick start colab:‚Ä¶ https://t.co/BbMg5HziVw https://t.co/iFXVZByWmC",
    "id": "1881397550072152358",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881316758218535039" }
    ],
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T17:45:05.000Z",
    "edit_history_tweet_ids": ["1881397550072152358"],
    "attachments": { "media_keys": ["3_1881397520946855940"] }
  },
  {
    "author_id": "33836629",
    "text": "@joannejang LOL",
    "id": "1881397435916034131",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880683751497482290" }
    ],
    "in_reply_to_user_id": "1040475510193545216",
    "created_at": "2025-01-20T17:44:38.000Z",
    "edit_history_tweet_ids": ["1881397435916034131"]
  },
  {
    "author_id": "759894532649545732",
    "text": "Congratulations to President @realDonaldTrump on being inaugurated as the 47th President of the United States of America üá∫üá∏! So much optimism and excitement for the future here in DC. Let‚Äôs make search great again with unbiased uncensored information universally accessible!",
    "id": "1881397143333896303",
    "created_at": "2025-01-20T17:43:28.000Z",
    "edit_history_tweet_ids": ["1881397143333896303"]
  },
  {
    "author_id": "308867922",
    "text": "Cc @cognition_labs",
    "id": "1881397097792192612",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881369743229419952" }
    ],
    "in_reply_to_user_id": "308867922",
    "created_at": "2025-01-20T17:43:17.000Z",
    "edit_history_tweet_ids": ["1881397097792192612"]
  },
  {
    "author_id": "2465283662",
    "note_tweet": {
      "text": "its now available in ai-gradio    \n\npip install --upgrade \"ai-gradio[deepseek]\"  \n\nimport gradio as gr  \nimport ai_gradio    \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry, ).launch()  \n\ngithub: https://t.co/f2s3ck8OL9\n\nquick start colab: https://t.co/j6kyZOfoAb",
      "entities": {
        "urls": [
          {
            "start": 216,
            "end": 239,
            "url": "https://t.co/f2s3ck8OL9",
            "expanded_url": "https://github.com/AK391/ai-gradio",
            "display_url": "github.com/AK391/ai-gradio"
          },
          {
            "start": 260,
            "end": 283,
            "url": "https://t.co/j6kyZOfoAb",
            "expanded_url": "https://colab.research.google.com/drive/1Ilz8LRQp0lQHxXu26PEJkXtXmvj1MrFe?usp=sharing",
            "display_url": "colab.research.google.com/drive/1Ilz8LRQ‚Ä¶"
          }
        ]
      }
    },
    "text": "@AravSrinivas its now available in ai-gradio    \n\npip install --upgrade \"ai-gradio[deepseek]\"  \n\nimport gradio as gr  \nimport ai_gradio    \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry, ).launch()  \n\ngithub: https://t.co/vy68ARTizv\n\nquick start colab:‚Ä¶ https://t.co/xII2r8xiok https://t.co/vcZhxtMy6h",
    "id": "1881396944163188840",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881372861405036773" }
    ],
    "in_reply_to_user_id": "759894532649545732",
    "created_at": "2025-01-20T17:42:40.000Z",
    "edit_history_tweet_ids": ["1881396944163188840"],
    "attachments": { "media_keys": ["3_1881396832208613376"] }
  },
  {
    "author_id": "731538535795163136",
    "text": "I also think these human evals highlight how it is very possible for a 32B open-weights model to outperform much larger models like Claude, Mistral Large 2, Llama 405B. \n\nGetting away with scale alone is no longer enough.",
    "id": "1881396759295045680",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881391184377160161" }
    ],
    "in_reply_to_user_id": "731538535795163136",
    "created_at": "2025-01-20T17:41:56.000Z",
    "edit_history_tweet_ids": ["1881396759295045680"]
  },
  {
    "author_id": "615818451",
    "text": "https://t.co/dvh4Zpo0Yz",
    "id": "1881396642152370307",
    "referenced_tweets": [
      { "type": "quoted", "id": "1801331034916851995" },
      { "type": "replied_to", "id": "1881393611520270690" }
    ],
    "in_reply_to_user_id": "615818451",
    "created_at": "2025-01-20T17:41:28.000Z",
    "edit_history_tweet_ids": ["1881396642152370307"]
  },
  {
    "author_id": "615818451",
    "text": "MEI üá∫üá∏\n\nhow it started                     how it‚Äôs going https://t.co/XJu98wR1F3",
    "id": "1881396374643908972",
    "created_at": "2025-01-20T17:40:25.000Z",
    "edit_history_tweet_ids": ["1881396374643908972"],
    "attachments": {
      "media_keys": ["3_1881396367349653504", "3_1881396367345500160"]
    }
  },
  {
    "author_id": "55854264",
    "text": "RT @robertarail: We‚Äôve been optimising LLM reasoning with RL before it was cool with @Dahoas1 @d_yuqing @tesatory @pabbeel @erichammy @shar‚Ä¶",
    "id": "1881396308889772469",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881005452286144696" }],
    "created_at": "2025-01-20T17:40:09.000Z",
    "edit_history_tweet_ids": ["1881396308889772469"]
  },
  {
    "author_id": "52247685",
    "text": "... how deeply, Claude? https://t.co/1zCO8eVgYn",
    "id": "1881395899106226393",
    "created_at": "2025-01-20T17:38:31.000Z",
    "edit_history_tweet_ids": ["1881395899106226393"],
    "attachments": { "media_keys": ["3_1881395874078625792"] }
  },
  {
    "author_id": "192201556",
    "text": "this will never not be funny no matter how far OpenAI gets with ill-gotten compute https://t.co/PnomdjbEEt https://t.co/Ebr33CrEY2",
    "id": "1881395176947794340",
    "referenced_tweets": [{ "type": "quoted", "id": "1860825413724828022" }],
    "created_at": "2025-01-20T17:35:39.000Z",
    "edit_history_tweet_ids": ["1881395176947794340"],
    "attachments": { "media_keys": ["3_1881394980477935616"] }
  },
  {
    "author_id": "2854214132",
    "text": "Wow @microcenter! For $500 I should buy 20 of them and run @deepseek_ai R1 on it with @exolabs! https://t.co/6n9scX39Ny",
    "id": "1881394417896218667",
    "created_at": "2025-01-20T17:32:38.000Z",
    "edit_history_tweet_ids": ["1881394417896218667"],
    "attachments": { "media_keys": ["3_1881394415559753728"] }
  },
  {
    "author_id": "2465283662",
    "text": "Nice https://t.co/GJlsXq39TP https://t.co/OvOT8lckzH",
    "id": "1881393871449677960",
    "referenced_tweets": [{ "type": "quoted", "id": "1881374261555945938" }],
    "created_at": "2025-01-20T17:30:28.000Z",
    "edit_history_tweet_ids": ["1881393871449677960"],
    "attachments": { "media_keys": ["3_1881393868035239936"] }
  },
  {
    "author_id": "829108178059096064",
    "text": "SFT seems fine if you have the implicit dataset generated by online RL. https://t.co/E1eyZJWYtk https://t.co/MPG7shk3gX",
    "id": "1881393695020478940",
    "referenced_tweets": [{ "type": "quoted", "id": "1878466954945495140" }],
    "created_at": "2025-01-20T17:29:46.000Z",
    "edit_history_tweet_ids": ["1881393619174936668", "1881393695020478940"],
    "attachments": { "media_keys": ["3_1881393556683980800"] }
  },
  {
    "author_id": "615818451",
    "text": "Trump just announced he will end DEI, and ensure that our country is ‚Äúcolorblind and merit-based‚Äù.\n\nMEI all the way\nMerit, excellence, and intelligence üá∫üá∏üí™",
    "id": "1881393611520270690",
    "created_at": "2025-01-20T17:29:26.000Z",
    "edit_history_tweet_ids": ["1881393611520270690"]
  },
  {
    "author_id": "825766640",
    "text": "I think it‚Äôs because it‚Äôs usually fixing a bug or adding a feature I desperately need",
    "id": "1881393485108121968",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881393264991068294" }
    ],
    "in_reply_to_user_id": "825766640",
    "created_at": "2025-01-20T17:28:56.000Z",
    "edit_history_tweet_ids": ["1881393485108121968"]
  },
  {
    "author_id": "2465283662",
    "text": "RT @hAru_mAki_ch: DeepSeek-R1 Coder „Çí‰Ωø„Å£„Å¶„Åø„Åü‚ë°\nHugging Face „ÅÆspace„ÅÆ„ÇÆ„É£„É©„É™„Éº„Çí‰ΩúÊàê„Åó„Å¶„ÇÇ„Çâ„Å£„ÅüÔºÅ„Åì„ÅÆÂÆåÊàêÂ∫¶„ÅØÁµêÊßã„Ç®„Ç∞„Ç§„ÅûÔºÅÔºÅ https://t.co/WwgYeAeyV4",
    "id": "1881393327935046071",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881378359189606713" }],
    "created_at": "2025-01-20T17:28:18.000Z",
    "edit_history_tweet_ids": ["1881393327935046071"],
    "attachments": { "media_keys": ["7_1881378334380261377"] }
  },
  {
    "author_id": "825766640",
    "text": "It ceases to bring me delight when I make a PR that is merged on a open source project \n\nIt always hits the same no matter how many times I do it",
    "id": "1881393264991068294",
    "created_at": "2025-01-20T17:28:03.000Z",
    "edit_history_tweet_ids": ["1881393264991068294"]
  },
  {
    "author_id": "33521530",
    "text": "@gneubig tried superwhisper?",
    "id": "1881392910459150496",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881374505098182832" }
    ],
    "in_reply_to_user_id": "185910194",
    "created_at": "2025-01-20T17:26:39.000Z",
    "edit_history_tweet_ids": ["1881392910459150496"]
  },
  {
    "author_id": "2465283662",
    "text": "RT @hAru_mAki_ch: DeepSeek-R1 Coder „Çí‰Ωø„Å£„Å¶„Åø„ÅüÔºÅÔºÅ\nÊôÆÈÄö„Å´ËâØ„Åï„Åù„ÅÜ„ÄÅ„ÄÅ„ÄÅ‰æ°Ê†ºÁöÑ„Å´„ÇÇ„Åì„Çå„Å™„ÇâÁµêÊßãÈáçÂÆù„Åó„Åù„ÅÜÔºÅÔºÅÔºÅ https://t.co/j8Y3qGmWMH",
    "id": "1881391643095605373",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881374261555945938" }],
    "created_at": "2025-01-20T17:21:36.000Z",
    "edit_history_tweet_ids": ["1881391643095605373"],
    "attachments": { "media_keys": ["7_1881374117561241601"] }
  },
  {
    "author_id": "2854214132",
    "text": "Dear Joe Biden:\n\nYou can't pardon someone who has never been charged with any crime. \n\nAre you ok?",
    "id": "1881391341365764196",
    "created_at": "2025-01-20T17:20:24.000Z",
    "edit_history_tweet_ids": ["1881391341365764196"]
  },
  {
    "author_id": "731538535795163136",
    "text": "This has further convinced me of the need for private third-party evals. \n\nOn many academic benchmarks, this spread in perf is not visible because models saturate perf due to test set contagion.\n\nIn contrast, these private human evals are way closer to our internal estimates. https://t.co/2rBkw63bRV",
    "id": "1881391184377160161",
    "referenced_tweets": [{ "type": "quoted", "id": "1881386848397975688" }],
    "created_at": "2025-01-20T17:19:47.000Z",
    "edit_history_tweet_ids": ["1881391184377160161"]
  },
  {
    "author_id": "610552974",
    "text": "RT @CohereForAI: On @scale_AI's private multilingual protocol, Aya Expanse is indexed as the best open-weights model\n\nIn some languages we'‚Ä¶",
    "id": "1881390269020721505",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881386848397975688" }],
    "created_at": "2025-01-20T17:16:09.000Z",
    "edit_history_tweet_ids": ["1881390269020721505"]
  },
  {
    "author_id": "1188812448767336449",
    "text": "RT @lhoestq: Cool pandas trick: Filter `conversations` datasets with nested DataFrames‚ú®ü§ó\n\nü§îGet first message\nüí°df[\"conversations\"].df[0]\n\nü§îG‚Ä¶",
    "id": "1881390095489785938",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881366148303974608" }],
    "created_at": "2025-01-20T17:15:27.000Z",
    "edit_history_tweet_ids": ["1881390095489785938"]
  },
  {
    "author_id": "829108178059096064",
    "text": "Discussing DeepSeek R1 https://t.co/bS5dnCKehj",
    "id": "1881389845593104772",
    "created_at": "2025-01-20T17:14:28.000Z",
    "edit_history_tweet_ids": ["1881389845593104772"]
  },
  {
    "author_id": "52247685",
    "text": "Overusing and overloading the term intelligence\n\nWill and Desire compel us https://t.co/S40O5UA7Hr",
    "id": "1881388932228948193",
    "referenced_tweets": [{ "type": "quoted", "id": "1881388530813002117" }],
    "created_at": "2025-01-20T17:10:50.000Z",
    "edit_history_tweet_ids": ["1881388932228948193"]
  },
  {
    "author_id": "13614262",
    "text": "Quick colab on using Deepseek-R1 to generate data: https://t.co/9tNZEBaMmx\n\nLet me know if you guys want a full-fledged example of deepseek-distillation: generate data and fine-tune a model. https://t.co/zV1HE7sufa",
    "id": "1881388860602745116",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881379171299123661" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T17:10:33.000Z",
    "edit_history_tweet_ids": ["1881388860602745116"],
    "attachments": { "media_keys": ["3_1881388646496161792"] }
  },
  {
    "author_id": "3378986176",
    "text": "RT @natolambert: For those trying to understand DeepSeeks Group Relative Policy Optimization (GRPO): GRPO is just PPO without a value funct‚Ä¶",
    "id": "1881388823999070456",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881380809153847711" }],
    "created_at": "2025-01-20T17:10:24.000Z",
    "edit_history_tweet_ids": ["1881388823999070456"]
  },
  {
    "author_id": "192201556",
    "text": "RT @a_karvonen: Just image how different the discussion would be today if Deepseek R1 was a closed source reasoning model. \n\nEveryone would‚Ä¶",
    "id": "1881388602682425620",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881385661976260944" }],
    "created_at": "2025-01-20T17:09:32.000Z",
    "edit_history_tweet_ids": ["1881388602682425620"]
  },
  {
    "author_id": "1245260977626587136",
    "text": "RT @srush_nlp: Really neat implications. The most pressing one is that we need to code up verifiers for absolutely everything that can be v‚Ä¶",
    "id": "1881388542653542891",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881383080528924868" }],
    "created_at": "2025-01-20T17:09:17.000Z",
    "edit_history_tweet_ids": ["1881388542653542891"]
  },
  {
    "author_id": "2854214132",
    "text": "RT @casper_hansen_: DeepSeek R1 is highly competitive while being up to 10x cheaper than o1. Quants coming soon‚Ñ¢ https://t.co/RfcvocxNPj",
    "id": "1881388200226422896",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881318037879705842" }],
    "created_at": "2025-01-20T17:07:56.000Z",
    "edit_history_tweet_ids": ["1881388200226422896"],
    "attachments": { "media_keys": ["3_1881317597645303808"] }
  },
  {
    "author_id": "192201556",
    "note_tweet": {
      "text": "situational a-Whaleness\nincidentally the running gag of Unsong is cringeworthy whale puns\nHey @slatestarcodex, you going to finally Notice this or not? It's a story not unlike any you could've proudly written",
      "entities": {
        "mentions": [
          {
            "start": 94,
            "end": 109,
            "username": "slatestarcodex",
            "id": "1526643050"
          }
        ]
      }
    },
    "text": "situational a-Whaleness\nincidentally the running gag of Unsong is cringeworthy whale puns\nHey @slatestarcodex, you going to finally Notice this or not? It's a story not unlike any you could've proudly written https://t.co/TOlMjZPPhr https://t.co/iCeWQB634n",
    "id": "1881388176545038337",
    "referenced_tweets": [{ "type": "quoted", "id": "1881387524687606263" }],
    "created_at": "2025-01-20T17:07:50.000Z",
    "edit_history_tweet_ids": ["1881388176545038337"]
  },
  {
    "author_id": "441465751",
    "text": "It begins https://t.co/WWopY9kEXS",
    "id": "1881387941404332461",
    "created_at": "2025-01-20T17:06:54.000Z",
    "edit_history_tweet_ids": ["1881387941404332461"],
    "attachments": { "media_keys": ["3_1881387939109711872"] }
  },
  {
    "author_id": "192201556",
    "text": "I'm inclined to say that the next Big Thing is, indeed, multi-agent training. You can't do \"honest\" RL for agentic and multi-turn performance without it. You need a DeepSeek-Prompter pestering DeepSeek-Solver, in a tight loop, and with async tools.\nRLHF dies in 2025.",
    "id": "1881387194004467964",
    "created_at": "2025-01-20T17:03:56.000Z",
    "edit_history_tweet_ids": ["1881387194004467964"]
  },
  {
    "author_id": "245262377",
    "note_tweet": {
      "text": "Command:\n\nmlx_lm.generate --model mlx-community/DeepSeek-R1-Distill-Qwen-7B-4bit --max-tokens 256 --prompt \"Two eight-sided dice each have faces numbered 1 through 8. When the dice are rolled, each face has an equal probability of appearing on the top. What is the probability that the product of the two top numbers is greater than their sum? Express your answer as a common fraction.\" -m 4096"
    },
    "text": "Command:\n\nmlx_lm.generate --model mlx-community/DeepSeek-R1-Distill-Qwen-7B-4bit --max-tokens 256 --prompt \"Two eight-sided dice each have faces numbered 1 through 8. When the dice are rolled, each face has an equal probability of appearing on the top. What is the probability‚Ä¶ https://t.co/hNjsJsfF14",
    "id": "1881387077033705877",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881386796266946743" }
    ],
    "in_reply_to_user_id": "245262377",
    "created_at": "2025-01-20T17:03:28.000Z",
    "edit_history_tweet_ids": ["1881387077033705877"]
  },
  {
    "author_id": "245262377",
    "text": "Wow, DeepSeek R1 Distill Qwen 7B (in 4-bit) nailed the first hard math question I asked it.\n\nThought for ~3200 tokens in about 35 seconds on M4 Max with mlx-lm. https://t.co/ZQ3lLnKn5x",
    "id": "1881386796266946743",
    "created_at": "2025-01-20T17:02:21.000Z",
    "edit_history_tweet_ids": ["1881386796266946743"],
    "attachments": { "media_keys": ["7_1881386527739310080"] }
  },
  {
    "author_id": "1007413134",
    "text": "And a *second* paper dropped today. Can't be coincidence. üòÇ\n\nhttps://t.co/RGi5wlOaIb",
    "id": "1881386537352609970",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881382618627019050" },
      { "type": "replied_to", "id": "1881353126210687089" }
    ],
    "in_reply_to_user_id": "1007413134",
    "created_at": "2025-01-20T17:01:19.000Z",
    "edit_history_tweet_ids": ["1881386537352609970"]
  },
  {
    "author_id": "1825243643529027584",
    "text": "they will drop the best model in Feb and then they will continue cooking silently https://t.co/DuaQPvJ0Nh https://t.co/uhGSQAlgdq",
    "id": "1881385797792010271",
    "referenced_tweets": [{ "type": "quoted", "id": "1881374280837165191" }],
    "created_at": "2025-01-20T16:58:23.000Z",
    "edit_history_tweet_ids": ["1881385797792010271"],
    "attachments": { "media_keys": ["16_1881385789029769216"] }
  },
  {
    "author_id": "192201556",
    "text": "will be hilarious if sama, being salty, finds a bs reason to skip o4 and go straight to \"o5\". All influencers will lose their minds about \"exponential acceleration of capabilities\"",
    "id": "1881385700463116725",
    "created_at": "2025-01-20T16:58:00.000Z",
    "edit_history_tweet_ids": ["1881385700463116725"]
  },
  {
    "author_id": "245262377",
    "text": "RT @ronaldmannak: How to install DeepSeek R1 on MLX on Pico AI Homelab TestFlight:\n1. Open settings (Pico menubar icon -&gt; Settings...)\n2. S‚Ä¶",
    "id": "1881384784448180398",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881384475017498689" }],
    "created_at": "2025-01-20T16:54:21.000Z",
    "edit_history_tweet_ids": ["1881384784448180398"]
  },
  {
    "author_id": "1499415401763115019",
    "text": "i don't care\ni'm here for ml\nleave me alone https://t.co/Un2QVTXuNu",
    "id": "1881384519124779263",
    "created_at": "2025-01-20T16:53:18.000Z",
    "edit_history_tweet_ids": ["1881384519124779263"],
    "attachments": { "media_keys": ["3_1881384487973457920"] }
  },
  {
    "author_id": "1499415401763115019",
    "text": "two people who are into saes read this and are like cool",
    "id": "1881384114676486504",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881379908800377072" }
    ],
    "in_reply_to_user_id": "1499415401763115019",
    "created_at": "2025-01-20T16:51:42.000Z",
    "edit_history_tweet_ids": ["1881384114676486504"]
  },
  {
    "author_id": "192201556",
    "text": "&gt; everything hes asking for\nI may overdose on hopium today\nImagine Wenfeng awkwardly saying ‚Äúw‚Ä¶well, me and the boys have written down this list of recs for Huawei‚Ä¶ if you don't mind, it would be very handy with training ASI, Comrade Premier‚Ä¶‚Äù https://t.co/LkODhl9tBw https://t.co/nbd8qdPTEW",
    "id": "1881383866595995789",
    "referenced_tweets": [{ "type": "quoted", "id": "1881379294091542774" }],
    "created_at": "2025-01-20T16:50:42.000Z",
    "edit_history_tweet_ids": ["1881383866595995789"],
    "attachments": { "media_keys": ["3_1881383231141937152"] }
  },
  {
    "author_id": "821092604821536768",
    "text": "RT @fermatslibrary: In the fall of 1972, President Nixon announced that \"the rate of increase of inflation was decreasing\". Probably the fi‚Ä¶",
    "id": "1881383658428510605",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881271439107506657" }],
    "created_at": "2025-01-20T16:49:53.000Z",
    "edit_history_tweet_ids": ["1881383658428510605"]
  },
  {
    "author_id": "95016894",
    "text": "RT @aestheticedwar1: Show me a better duo than @GoogleAI  ‚ù§Ô∏è @weaviate_io !\n\nDid you know that Google's¬†Vertex AI RAG Engine works seamless‚Ä¶",
    "id": "1881383594901581965",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881335754758017222" }],
    "created_at": "2025-01-20T16:49:38.000Z",
    "edit_history_tweet_ids": ["1881383594901581965"]
  },
  {
    "author_id": "1007413134",
    "text": "Whitepaper link: https://t.co/w1MvvbAd5h",
    "id": "1881383342840651978",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881382618627019050" }
    ],
    "in_reply_to_user_id": "1007413134",
    "created_at": "2025-01-20T16:48:38.000Z",
    "edit_history_tweet_ids": ["1881383342840651978"]
  },
  {
    "author_id": "821092604821536768",
    "text": "RT @C_Kavanagh: Rogan‚Äôs going to be so mad. He‚Äôs always complaining about stuff like this when it comes to politicians making money off sto‚Ä¶",
    "id": "1881382975335735559",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881277744094609654" }],
    "created_at": "2025-01-20T16:47:10.000Z",
    "edit_history_tweet_ids": ["1881382975335735559"]
  },
  {
    "author_id": "1007413134",
    "note_tweet": {
      "text": "That a *second* paper dropped with tons of RL flywheel secrets and *multimodal* o1-style reasoning is not on my bingo card today. Kimi's (another startup) and DeepSeek's papers remarkably converged on similar findings:\n\n> No need for complex tree search like MCTS. Just linearize the thought trace and do good old autoregressive prediction;\n> No need for value functions that require another expensive copy of the model;\n> No need for dense reward modeling. Rely as much as possible on groundtruth, end result. \n\nDifferences:\n\n> DeepSeek does AlphaZero approach - purely bootstrap through RL w/o human input, i.e. \"cold start\". Kimi does AlphaGo-Master approach: light SFT to warm up through prompt-engineered CoT traces.\n> DeepSeek weights are MIT license (thought leadership!); Kimi does not have a model release yet.\n> Kimi shows strong multimodal performance (!) on benchmarks like MathVista, which requires visual understanding of geometry, IQ tests, etc.\n> Kimi paper has a LOT more details on the system design: RL infrastructure, hybrid cluster, code sandbox, parallelism strategies; and learning details: long context, CoT compression, curriculum, sampling strategy, test case generation, etc.\n\nUpbeat reads on a holiday!"
    },
    "text": "That a *second* paper dropped with tons of RL flywheel secrets and *multimodal* o1-style reasoning is not on my bingo card today. Kimi's (another startup) and DeepSeek's papers remarkably converged on similar findings:\n\n&gt; No need for complex tree search like MCTS. Just linearize‚Ä¶ https://t.co/GgZ18jb3Vv https://t.co/NrV2WyunC9",
    "id": "1881382618627019050",
    "created_at": "2025-01-20T16:45:45.000Z",
    "edit_history_tweet_ids": ["1881382618627019050"],
    "attachments": { "media_keys": ["3_1881378108139601920"] }
  },
  {
    "author_id": "192201556",
    "text": "In previous episodes \nhttps://t.co/jr4hlRFzrL",
    "id": "1881382564843462950",
    "referenced_tweets": [
      { "type": "quoted", "id": "1802165240194371941" },
      { "type": "replied_to", "id": "1881382326074282401" }
    ],
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T16:45:32.000Z",
    "edit_history_tweet_ids": ["1881382564843462950"]
  },
  {
    "author_id": "192201556",
    "text": "I can't believe China bros are still dealing with this, long after models they cook can score 80+ on MMLU and speak better English than me\nhttps://t.co/6TczIZkAW8 https://t.co/taCH6xgeT3 https://t.co/t4P2uXCLvs",
    "id": "1881382326074282401",
    "referenced_tweets": [{ "type": "quoted", "id": "1881339505359339931" }],
    "created_at": "2025-01-20T16:44:35.000Z",
    "edit_history_tweet_ids": ["1881382326074282401"],
    "attachments": { "media_keys": ["3_1881382093994758144"] }
  },
  {
    "author_id": "192201556",
    "text": "in one very aesthetic timeline Zhean and his comrades get huge golden statues as liberators of humanity from the bane of power centralization https://t.co/1rWPGuni5w",
    "id": "1881381443219362189",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318441334005941" }],
    "created_at": "2025-01-20T16:41:05.000Z",
    "edit_history_tweet_ids": ["1881381443219362189"]
  },
  {
    "author_id": "192201556",
    "text": "RT @TheXeophon: https://t.co/KVODWdhhxS",
    "id": "1881380281980268792",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881372532999369048" }],
    "created_at": "2025-01-20T16:36:28.000Z",
    "edit_history_tweet_ids": ["1881380281980268792"],
    "attachments": { "media_keys": ["3_1881372510379204608"] }
  },
  {
    "author_id": "992153930095251456",
    "text": "Nvidia presented Project Digits, a personal supercomputer designed for students, developers, and researchers to run, train, and fine-tune large AI models locally. \n\nLearn more in The Batch: https://t.co/PAlBvRZXOR https://t.co/2SgQrsNHui",
    "id": "1881380064731832466",
    "created_at": "2025-01-20T16:35:36.000Z",
    "edit_history_tweet_ids": ["1881380064731832466"],
    "attachments": { "media_keys": ["3_1881380062978576385"] }
  },
  {
    "author_id": "1499415401763115019",
    "text": "sub 100 l0, am happy",
    "id": "1881379908800377072",
    "created_at": "2025-01-20T16:34:59.000Z",
    "edit_history_tweet_ids": ["1881379908800377072"]
  },
  {
    "author_id": "1271482878958940160",
    "text": "@DrJimFan Open source really matters, because it's also very inspiring and helpful to witness how DeepSeek smartly combines RL and high-quality training data to create this new DeepSeek-R1, just like a perfect puzzle",
    "id": "1881379709814186060",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881353126210687089" }
    ],
    "in_reply_to_user_id": "1007413134",
    "created_at": "2025-01-20T16:34:11.000Z",
    "edit_history_tweet_ids": ["1881379709814186060"]
  },
  {
    "author_id": "1718879852827484160",
    "text": "The Anthropic reasoner on top of the best base model there is (Sonnet) gonna hit like absolute crack https://t.co/pRp3mFwvhX",
    "id": "1881379264886710601",
    "referenced_tweets": [{ "type": "quoted", "id": "1881376463905325080" }],
    "created_at": "2025-01-20T16:32:25.000Z",
    "edit_history_tweet_ids": ["1881379264886710601"]
  },
  {
    "author_id": "13614262",
    "text": "Wow https://t.co/LcYSFYrLw6",
    "id": "1881379171299123661",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881333582800847147" },
      { "type": "replied_to", "id": "1881379169843675578" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T16:32:03.000Z",
    "edit_history_tweet_ids": ["1881379171299123661"]
  },
  {
    "author_id": "13614262",
    "text": "https://t.co/1TfkgIl6kO",
    "id": "1881379169843675578",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881331287010550119" },
      { "type": "replied_to", "id": "1881379168258261039" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T16:32:03.000Z",
    "edit_history_tweet_ids": ["1881379169843675578"]
  },
  {
    "author_id": "13614262",
    "text": "https://t.co/fWgOjI3oEY",
    "id": "1881379168258261039",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881341537499619822" },
      { "type": "replied_to", "id": "1881379166878388641" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T16:32:02.000Z",
    "edit_history_tweet_ids": ["1881379168258261039"]
  },
  {
    "author_id": "13614262",
    "text": "Attaching other related discourse.\n\n\"Dylan normally knows\" -&gt; yes!\nhttps://t.co/zJrkyJruA2",
    "id": "1881379166878388641",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881363343468036522" },
      { "type": "replied_to", "id": "1881378070650859852" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T16:32:02.000Z",
    "edit_history_tweet_ids": ["1881379166878388641"]
  },
  {
    "author_id": "68538286",
    "text": "It looks like China has roughly caught up. Any AI strategy that depends on a lasting U.S. lead is fragile. https://t.co/65dXkBxeeX",
    "id": "1881378931552715216",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "created_at": "2025-01-20T16:31:06.000Z",
    "edit_history_tweet_ids": ["1881378931552715216"]
  },
  {
    "author_id": "1375579341178818561",
    "text": "https://t.co/uHzqDg8WwL",
    "id": "1881378707480457312",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881378704338952475" }
    ],
    "in_reply_to_user_id": "1375579341178818561",
    "created_at": "2025-01-20T16:30:12.000Z",
    "edit_history_tweet_ids": ["1881378707480457312"]
  },
  {
    "author_id": "1375579341178818561",
    "text": "We're psyched to team up with @MorganBarrettX on the first Tech Breakfast Club of 2025 in NYC!\n\n‚Äã‚ÄãIf you're an AI leader living in New York, come join us this Tuesday for a hearty breakfast and good conversation. https://t.co/Yxsja6ChKy",
    "id": "1881378704338952475",
    "created_at": "2025-01-20T16:30:12.000Z",
    "edit_history_tweet_ids": ["1881378704338952475"],
    "attachments": { "media_keys": ["3_1881376761470193664"] }
  },
  {
    "author_id": "874987512850128897",
    "text": "you can find the notebook here:\n\nhttps://t.co/xtD5D8jRMq",
    "id": "1881378426403348769",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881377609445167380" }
    ],
    "in_reply_to_user_id": "874987512850128897",
    "created_at": "2025-01-20T16:29:05.000Z",
    "edit_history_tweet_ids": ["1881378426403348769"]
  },
  {
    "author_id": "13614262",
    "text": "They use GRPO: https://t.co/btLze6VJTu",
    "id": "1881378070650859852",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881378068868264036" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T16:27:41.000Z",
    "edit_history_tweet_ids": ["1881378070650859852"]
  },
  {
    "author_id": "13614262",
    "text": "2. No process reward model or MCTS https://t.co/dciXY9YTRL",
    "id": "1881378068868264036",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881378067123466569" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T16:27:40.000Z",
    "edit_history_tweet_ids": ["1881378068868264036"],
    "attachments": { "media_keys": ["3_1881377379723223042"] }
  },
  {
    "author_id": "13614262",
    "text": "Distillation is going to be huge. \nCurator is going to make distillation seamless. :) https://t.co/uPzQrHOA82",
    "id": "1881378067123466569",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881378064401334399" }
    ],
    "in_reply_to_user_id": "13614262",
    "created_at": "2025-01-20T16:27:40.000Z",
    "edit_history_tweet_ids": ["1881378067123466569"],
    "attachments": { "media_keys": ["3_1881376761424105473"] }
  },
  {
    "author_id": "13614262",
    "note_tweet": {
      "text": "Deepseek has done it again! This time, lots of action packed insights, stuff that the top labs are not willing to share.\n\nSome insights:\n\n1. \"We directly apply reinforcement learning (RL) to the base model without relying on supervised fine-tuning (SFT) as a preliminary step.\" \n\nThis will take some time to sink in, given how clearly it's been laid out. This has been known in a few circles (@natolambert has also talked about this many times), but lots of people don't seem to get the magnitude of this. \n\nBut of course, note that RL is great for reasoning, and there are many problems where reasoning is not needed or not useful and SFT is great.",
      "entities": {
        "mentions": [
          {
            "start": 393,
            "end": 405,
            "username": "natolambert",
            "id": "2939913921"
          }
        ]
      }
    },
    "text": "Deepseek has done it again! This time, lots of action packed insights, stuff that the top labs are not willing to share.\n\nSome insights:\n\n1. \"We directly apply reinforcement learning (RL) to the base model without relying on supervised fine-tuning (SFT) as a preliminary step.\"‚Ä¶ https://t.co/1ia1YhF0DB https://t.co/cgRGtNkJuM https://t.co/7Nv2HtJY4L",
    "id": "1881378064401334399",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "created_at": "2025-01-20T16:27:39.000Z",
    "edit_history_tweet_ids": ["1881378064401334399"],
    "attachments": { "media_keys": ["3_1881376451066568704"] }
  },
  {
    "author_id": "874987512850128897",
    "text": "Try out R1 Distill Qwen 1.5B in a FREE Google Colab! üî•\n\nThe vibes are looking gooood! https://t.co/dXvYLoOFuk https://t.co/IQApPfEjzG",
    "id": "1881377609445167380",
    "referenced_tweets": [{ "type": "quoted", "id": "1881319500089634954" }],
    "created_at": "2025-01-20T16:25:51.000Z",
    "edit_history_tweet_ids": ["1881377609445167380"],
    "attachments": { "media_keys": ["7_1881377422135676928"] }
  },
  {
    "author_id": "2434761475",
    "text": "y'all need to start letting people BID ON TOKENS no more of this Instagram popup line around the block where you run out of sandwiches halfway through nonsense. https://t.co/EyTyNuPknA",
    "id": "1881377417736200487",
    "referenced_tweets": [{ "type": "quoted", "id": "1881375436644741410" }],
    "created_at": "2025-01-20T16:25:05.000Z",
    "edit_history_tweet_ids": ["1881377417736200487"]
  },
  {
    "author_id": "2465283662",
    "text": "@deepseek_ai quick start colab: https://t.co/gIJgCzRKgs",
    "id": "1881377305333055514",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881356534200049994" }
    ],
    "in_reply_to_user_id": "2465283662",
    "created_at": "2025-01-20T16:24:38.000Z",
    "edit_history_tweet_ids": ["1881377305333055514"]
  },
  {
    "author_id": "192201556",
    "text": "yeah I think he can understand the scale of the whale\nI'm not 100% hopeful only because there were other people there making the case for their turf, and court politics might not be Wenfeng's forte\nhttps://t.co/2O1amssCgc https://t.co/2hc6fRb8b4",
    "id": "1881377187191980271",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881335004015292434" },
      { "type": "replied_to", "id": "1881375948773486646" }
    ],
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T16:24:10.000Z",
    "edit_history_tweet_ids": ["1881377187191980271"],
    "attachments": { "media_keys": ["3_1881376782835720193"] }
  },
  {
    "author_id": "938616384572948480",
    "text": "R1 shows you need a good base model, a large math and code prompt reward set, prompting+cleaning then any RL technique+long decode+gpu go brr",
    "id": "1881376463905325080",
    "created_at": "2025-01-20T16:21:17.000Z",
    "edit_history_tweet_ids": ["1881376463905325080"]
  },
  {
    "author_id": "788107483306942464",
    "text": "@gallabytes that was fast",
    "id": "1881376042885255331",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881374280837165191" }
    ],
    "in_reply_to_user_id": "2434761475",
    "created_at": "2025-01-20T16:19:37.000Z",
    "edit_history_tweet_ids": ["1881376042885255331"]
  },
  {
    "author_id": "1513853205125681162",
    "text": "Wow, time to kms https://t.co/h60PW3gozQ https://t.co/Ai1cEi7gQX",
    "id": "1881375994650710284",
    "referenced_tweets": [{ "type": "quoted", "id": "1881372780081582397" }],
    "created_at": "2025-01-20T16:19:26.000Z",
    "edit_history_tweet_ids": ["1881375994650710284"],
    "attachments": { "media_keys": ["3_1881375910940835840"] }
  },
  {
    "author_id": "192201556",
    "text": "Li Qiang is #2 guy in China. If he managed to comprehend even 30% of what Wenfeng could tell him, this might be a real Situational Awareness moment. Finally. https://t.co/fTg28ErnML",
    "id": "1881375948773486646",
    "referenced_tweets": [{ "type": "quoted", "id": "1881364598143737880" }],
    "created_at": "2025-01-20T16:19:15.000Z",
    "edit_history_tweet_ids": ["1881375948773486646"]
  },
  {
    "author_id": "1495078042498002950",
    "text": "@johnowhitaker Yes, agreed. That‚Äôs the one place I think there‚Äôs a role for them",
    "id": "1881375910785626378",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881375341580804335" }
    ],
    "in_reply_to_user_id": "4004364327",
    "created_at": "2025-01-20T16:19:06.000Z",
    "edit_history_tweet_ids": ["1881375910785626378"]
  },
  {
    "author_id": "1718879852827484160",
    "text": "Likely that Anthropic has a reasoner but they simply dont have the compute to serve it if they are already facing limits now https://t.co/HTFTfsIIPK",
    "id": "1881375436644741410",
    "referenced_tweets": [{ "type": "quoted", "id": "1881374280837165191" }],
    "created_at": "2025-01-20T16:17:13.000Z",
    "edit_history_tweet_ids": ["1881375436644741410"]
  },
  {
    "author_id": "4004364327",
    "text": "@finbarrtimbers Maybe there's a place for them during search?",
    "id": "1881375341580804335",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881345977568866710" }
    ],
    "in_reply_to_user_id": "1495078042498002950",
    "created_at": "2025-01-20T16:16:50.000Z",
    "edit_history_tweet_ids": ["1881375341580804335"]
  },
  {
    "author_id": "52247685",
    "text": "I‚Äôm gonna be honest, in day to day use I don‚Äôt ask any of the frontier models about Tiananmen Square or which world leaders look like Winnie the Pooh",
    "id": "1881375310119424404",
    "created_at": "2025-01-20T16:16:42.000Z",
    "edit_history_tweet_ids": ["1881375310119424404"]
  },
  {
    "author_id": "759894532649545732",
    "text": "It's kinda wild to see reasoning get commoditized this fast.  We should fully expect an o3 level model that's open-sourced by the end of the year, probably even mid-year. https://t.co/oyIXkS4uDM",
    "id": "1881375063246835910",
    "created_at": "2025-01-20T16:15:43.000Z",
    "edit_history_tweet_ids": ["1881375063246835910"],
    "attachments": { "media_keys": ["3_1881374834615009280"] }
  },
  {
    "author_id": "800854096219471872",
    "text": "@hkproj Luckily we can speak it :)",
    "id": "1881374775970603248",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881340261735027194" }
    ],
    "in_reply_to_user_id": "967757817355653120",
    "created_at": "2025-01-20T16:14:35.000Z",
    "edit_history_tweet_ids": ["1881374775970603248"]
  },
  {
    "author_id": "185910194",
    "text": "I was feeling that my typing speed was a barrier to how quickly I could code with OpenHands, so I tried it out with speech input and ü§Ø\n\nSpeech input is easy to enable on Mac: https://t.co/xJQTS0VBia¬†\n\nThen you just need to press F5 to start transcribing instructions.",
    "id": "1881374505098182832",
    "created_at": "2025-01-20T16:13:30.000Z",
    "edit_history_tweet_ids": ["1881374505098182832"]
  },
  {
    "author_id": "2434761475",
    "text": "deepseek caught up faster than I expected. sick af.\n\none question though - where THE FUCK is Anthropic? https://t.co/MwgntVPfvf",
    "id": "1881374280837165191",
    "referenced_tweets": [{ "type": "quoted", "id": "1881373186744590406" }],
    "created_at": "2025-01-20T16:12:37.000Z",
    "edit_history_tweet_ids": ["1881374280837165191"]
  },
  {
    "author_id": "615818451",
    "text": "üá∫üá∏üá∫üá∏üí™ https://t.co/kByOjofSYE",
    "id": "1881374170564776326",
    "referenced_tweets": [{ "type": "quoted", "id": "1881373848827986188" }],
    "created_at": "2025-01-20T16:12:11.000Z",
    "edit_history_tweet_ids": ["1881374170564776326"]
  },
  {
    "author_id": "441465751",
    "text": "https://t.co/FuNjPGLDJ0",
    "id": "1881373443654082578",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881373186744590406" }
    ],
    "in_reply_to_user_id": "441465751",
    "created_at": "2025-01-20T16:09:17.000Z",
    "edit_history_tweet_ids": ["1881373443654082578"]
  },
  {
    "author_id": "2465283662",
    "text": "github: https://t.co/zNFkhJO3Bl",
    "id": "1881373309373407356",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881373192989602049" }
    ],
    "in_reply_to_user_id": "2465283662",
    "created_at": "2025-01-20T16:08:45.000Z",
    "edit_history_tweet_ids": ["1881373309373407356"]
  },
  {
    "author_id": "95016894",
    "text": "üôå This podcast with Barry Hayles from Temy was much fun!\nüí° I've shared how we've been building @weaviate_io over the past couple of years\nüëâ watch it here: https://t.co/NabWhSZVUI https://t.co/HClFOSH3E6",
    "id": "1881373201097425152",
    "created_at": "2025-01-20T16:08:20.000Z",
    "edit_history_tweet_ids": ["1881373201097425152"],
    "attachments": { "media_keys": ["3_1881372854249201664"] }
  },
  {
    "id": "1881373192989602049",
    "attachments": { "media_keys": ["3_1881373043060002816"] },
    "text": "Introducing Kimi k1.5 \n\nan o1-level multi-modal model  \n\n-Sota short-CoT performance, outperforming GPT-4o and Claude Sonnet 3.5 on üì∑AIME, üì∑ LiveCodeBench by a large margin (up to +550%) \n\n-Long-CoT performance matches o1 across multiple modalities (üì∑MathVista, üì∑Codeforces,‚Ä¶ https://t.co/dgbCimJxxS https://t.co/9OnDIUEeBj",
    "edit_history_tweet_ids": ["1881373192989602049"],
    "created_at": "2025-01-20T16:08:18.000Z",
    "author_id": "2465283662",
    "note_tweet": {
      "text": "Introducing Kimi k1.5 \n\nan o1-level multi-modal model  \n\n-Sota short-CoT performance, outperforming GPT-4o and Claude Sonnet 3.5 on üì∑AIME, üì∑ LiveCodeBench by a large margin (up to +550%) \n\n-Long-CoT performance matches o1 across multiple modalities (üì∑MathVista, üì∑Codeforces, etc)  Tech report: i-k1.5‚Ä¶ \n\nKey ingredients of k1.5 -Long context scaling. Up to 128k tokens for RL generation. Efficient training with partial rollouts. \n\n-Improved policy optimization: online mirror descent, sampling strategies, length penalty, and others.\n\n-Multi modalities. Joint reasoning over text and vision."
    }
  },
  {
    "id": "1881373186744590406",
    "attachments": { "media_keys": ["3_1881373183162396672"] },
    "text": "Okay so this is so far the most important paper in AI of the year https://t.co/xzMoqYM9hj",
    "edit_history_tweet_ids": ["1881373186744590406"],
    "created_at": "2025-01-20T16:08:16.000Z",
    "author_id": "441465751"
  },
  {
    "id": "1881372868706988453",
    "text": "ü§ñ From this week's issue: Inspired by the human vocal tract, a new AI model can produce and understand vocal imitations of everyday sounds. The method could help build new sonic interfaces for entertainment and education. https://t.co/PTpNw0V165",
    "edit_history_tweet_ids": ["1881372868706988453"],
    "created_at": "2025-01-20T16:07:00.000Z",
    "author_id": "763368160527544320"
  },
  {
    "id": "1881372861405036773",
    "attachments": { "media_keys": ["3_1881372859013984256"] },
    "text": "DeepSeek has largely replicated o1-mini and has open sourced it. https://t.co/2TbQ5p5l2c",
    "edit_history_tweet_ids": ["1881372861405036773"],
    "created_at": "2025-01-20T16:06:59.000Z",
    "author_id": "759894532649545732"
  },
  {
    "id": "1881372463709532175",
    "attachments": {
      "media_keys": ["3_1881372414115721216", "3_1881372414115807232"]
    },
    "text": "like clockwork https://t.co/PORbjeipYb https://t.co/6IBF9kjqVJ",
    "edit_history_tweet_ids": ["1881372463709532175"],
    "created_at": "2025-01-20T16:05:24.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881272791510507756" }],
    "author_id": "192201556"
  },
  {
    "id": "1881372239658107318",
    "text": "Open AI! I like the sound of that üòÉ https://t.co/Jz7Udq9SiN",
    "edit_history_tweet_ids": ["1881372239658107318"],
    "created_at": "2025-01-20T16:04:30.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318135850213834" }],
    "author_id": "19510090"
  },
  {
    "id": "1881371967263252639",
    "attachments": { "media_keys": ["3_1881371965853683712"] },
    "text": "Bezos, Pichai, Musk, (and Zuckerberg cut off on the side)\n\nTech titans apparently united under Trump https://t.co/wu4Nng0RIm",
    "edit_history_tweet_ids": ["1881371967263252639"],
    "created_at": "2025-01-20T16:03:25.000Z",
    "author_id": "441465751"
  },
  {
    "id": "1881371863789781127",
    "text": "Trying DeekSeek R1 https://t.co/X6Z7oPhnJi",
    "edit_history_tweet_ids": ["1881371863789781127"],
    "created_at": "2025-01-20T16:03:01.000Z",
    "author_id": "829108178059096064"
  },
  {
    "id": "1881371520272060454",
    "text": "@jd_pressman gn",
    "edit_history_tweet_ids": ["1881371520272060454"],
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T16:01:39.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881370599177798084" }
    ],
    "author_id": "192201556"
  },
  {
    "id": "1881371108584161345",
    "attachments": { "media_keys": ["3_1881371105392304128"] },
    "text": "ü§ñ üîÑ Build Smarter AI Agents\n\nLangGraph introduces state-aware AI workflows for sophisticated reasoning and decision-making. This tutorial shows you how to create advanced AI applications with powerful cyclical processing capabilities.\n\nLearn more: https://t.co/gisX3eURU5 https://t.co/a3Sw6LMulZ",
    "edit_history_tweet_ids": ["1881371108584161345"],
    "created_at": "2025-01-20T16:00:01.000Z",
    "author_id": "1589007443853340672"
  },
  {
    "id": "1881371102204821532",
    "text": "@jd_pressman bro I literally said something",
    "edit_history_tweet_ids": ["1881371102204821532"],
    "in_reply_to_user_id": "829108178059096064",
    "created_at": "2025-01-20T15:59:59.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881346529728094485" }
    ],
    "author_id": "192201556"
  },
  {
    "id": "1881370599177798084",
    "text": "@jd_pressman I can't speak rn but thanks for hosting this",
    "edit_history_tweet_ids": ["1881370599177798084"],
    "in_reply_to_user_id": "829108178059096064",
    "created_at": "2025-01-20T15:57:59.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881346529728094485" }
    ],
    "author_id": "192201556"
  },
  {
    "id": "1881370119491993905",
    "attachments": { "media_keys": ["3_1881370108070895616"] },
    "text": "https://t.co/PQ3WYO1VB8 https://t.co/tceyMDREJK",
    "edit_history_tweet_ids": ["1881370119491993905"],
    "created_at": "2025-01-20T15:56:05.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881349799888433548" }],
    "author_id": "1513853205125681162"
  },
  {
    "id": "1881370002030559634",
    "text": "quick start colab: https://t.co/gIJgCzRKgs",
    "edit_history_tweet_ids": ["1881370002030559634"],
    "in_reply_to_user_id": "2465283662",
    "created_at": "2025-01-20T15:55:37.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881367237929615631" }
    ],
    "author_id": "2465283662"
  },
  {
    "id": "1881369743229419952",
    "text": "Call for agent - a specialized coding agent that can use git bisect / logs to search through past commits and figure out where a specific bug originated. Should be more than doable at this point.",
    "edit_history_tweet_ids": ["1881369743229419952"],
    "created_at": "2025-01-20T15:54:35.000Z",
    "author_id": "308867922"
  },
  {
    "id": "1881369363112239556",
    "text": "RT @gptbrooke: Swyx is a total sweetheart that I have IRL vetted- check out date me doc here!",
    "edit_history_tweet_ids": ["1881369363112239556"],
    "created_at": "2025-01-20T15:53:04.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881227698170970312" }],
    "author_id": "33521530"
  },
  {
    "id": "1881368754514231540",
    "attachments": { "media_keys": ["3_1881368618161635328"] },
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 351,
            "end": 374,
            "url": "https://t.co/TxFc1kst7B",
            "expanded_url": "https://msty.app/",
            "display_url": "msty.app"
          },
          {
            "start": 492,
            "end": 515,
            "url": "https://t.co/OLIthsQXps",
            "expanded_url": "https://newsletter.danielmiessler.com/subscribe",
            "display_url": "newsletter.danielmiessler.com/subscribe"
          },
          {
            "start": 632,
            "end": 655,
            "url": "https://t.co/hPHM6sAK78",
            "expanded_url": "https://discord.com/channels/1110206757227216916/shop?redirect_from=rez0",
            "display_url": "discord.com/channels/11102‚Ä¶"
          },
          {
            "start": 709,
            "end": 732,
            "url": "https://t.co/PBrZMF0vWd",
            "expanded_url": "https://cursor.sh/",
            "display_url": "cursor.sh"
          },
          {
            "start": 818,
            "end": 841,
            "url": "https://t.co/WClyiJCtGi",
            "expanded_url": "https://claude.ai",
            "display_url": "claude.ai"
          },
          {
            "start": 981,
            "end": 1004,
            "url": "https://t.co/R6YQbk6DL1",
            "expanded_url": "https://haizelabs.com/",
            "display_url": "haizelabs.com"
          },
          {
            "start": 1276,
            "end": 1299,
            "url": "https://t.co/RdqNa9dElm",
            "expanded_url": "https://www.dwarkeshpatel.com/p/leopold-aschenbrenner",
            "display_url": "dwarkeshpatel.com/p/leopold-asch‚Ä¶"
          },
          {
            "start": 1439,
            "end": 1462,
            "url": "https://t.co/DOjiKVT6On",
            "expanded_url": "https://samcurry.net/hacking-kia",
            "display_url": "samcurry.net/hacking-kia"
          },
          {
            "start": 1564,
            "end": 1587,
            "url": "https://t.co/mrci2Barc2",
            "expanded_url": "https://github.com/danielmiessler/fabric",
            "display_url": "github.com/danielmiessler‚Ä¶"
          },
          {
            "start": 1724,
            "end": 1747,
            "url": "https://t.co/HWhgHW0tsr",
            "expanded_url": "https://bughunters.google.com/",
            "display_url": "bughunters.google.com"
          },
          {
            "start": 1867,
            "end": 1890,
            "url": "https://t.co/OzUqLIdlcS",
            "expanded_url": "https://github.com/elder-plinius/L1B3RT4S/",
            "display_url": "github.com/elder-plinius/‚Ä¶"
          },
          {
            "start": 2097,
            "end": 2120,
            "url": "https://t.co/htk7WQ4uvl",
            "expanded_url": "https://www.whiterabbitneo.com/",
            "display_url": "whiterabbitneo.com"
          },
          {
            "start": 2252,
            "end": 2275,
            "url": "https://t.co/9t3ECVhLtP",
            "expanded_url": "https://www.oreilly.com/library/view/ai-engineering/9781098166298/",
            "display_url": "oreilly.com/library/view/a‚Ä¶"
          },
          {
            "start": 2439,
            "end": 2462,
            "url": "https://t.co/nhdjBUEOUQ",
            "expanded_url": "https://www.youtube.com/@matthew_berman",
            "display_url": "youtube.com/@matthew_berman"
          },
          {
            "start": 2575,
            "end": 2598,
            "url": "https://t.co/kFDNGLGdkr",
            "expanded_url": "https://olickel.com/everything-i-know-about-prompting-llms",
            "display_url": "olickel.com/everything-i-k‚Ä¶"
          },
          {
            "start": 2725,
            "end": 2748,
            "url": "https://t.co/8ViWEaEhPz",
            "expanded_url": "https://github.com/SouthBridgeAI/offmute",
            "display_url": "github.com/SouthBridgeAI/‚Ä¶"
          },
          {
            "start": 2802,
            "end": 2825,
            "url": "https://t.co/GSqFOAvtii",
            "expanded_url": "https://thacker.beehiiv.com/subscribe",
            "display_url": "thacker.beehiiv.com/subscribe"
          }
        ],
        "mentions": [
          {
            "start": 395,
            "end": 410,
            "username": "DanielMiessler",
            "id": "1543121"
          },
          {
            "start": 618,
            "end": 630,
            "username": "ctbbpodcast",
            "id": "1600519214519013377"
          },
          {
            "start": 871,
            "end": 881,
            "username": "haizelabs",
            "id": "1744848449403748352"
          },
          {
            "start": 1057,
            "end": 1069,
            "username": "dwarkesh_sp",
            "id": "1209960539390201864"
          },
          {
            "start": 1352,
            "end": 1360,
            "username": "samwcyo",
            "id": "825606932887134212"
          },
          {
            "start": 1616,
            "end": 1626,
            "username": "GoogleVRP",
            "id": "972044366205411330"
          },
          {
            "start": 1825,
            "end": 1839,
            "username": "elder_plinius",
            "id": "1656536425087500288"
          },
          {
            "start": 2304,
            "end": 2318,
            "username": "MatthewBerman",
            "id": "6681172"
          },
          {
            "start": 2530,
            "end": 2539,
            "username": "hrishioa",
            "id": "1548645654"
          },
          {
            "start": 2687,
            "end": 2696,
            "username": "hrishioa",
            "id": "1548645654"
          }
        ]
      },
      "text": "I sent this to my email list and people loved it, so I wanted to post it here. It's a completely subjective list of stuff I loved in 2024. I hope you love it tooüòä \n\nBest MacOS Desktop App\nmsty - fantastic AI client that supports local and API usage of models. You can use multiple models at the same time. You can fork the conversation. It's awesome.\nhttps://t.co/TxFc1kst7B\n---\nBest Newsletter\n@DanielMiessler's Newsletter - He covers the best in cybersecurity and AI (kinda like me, haha).\nhttps://t.co/OLIthsQXps\n---\nBest Discord Channel\nCTBB \"Critical Thinkers\" Chat - direct access to the worlds top 300 hackers. @ctbbpodcast \nhttps://t.co/hPHM6sAK78\n---\nBest AI App\ncursor - the AI-powered code editor.\nhttps://t.co/PBrZMF0vWd\n---\nBest Model\nClaude Sonnet - simply because of how fast, good, and flexible it is.\nhttps://t.co/WClyiJCtGi\n---\nBest Red Teaming Company\n@haizelabs  - for their automated red teaming. (More detailed description written earlier in the newsletter.)\nhttps://t.co/R6YQbk6DL1\n---\nBest Podcast Episode\nThe Leopold episode on the @dwarkesh_sp  Podcast fundamentally changed the way I view AI safety/security. You have to listen to it. In general, the Dwarkesh Podcast is my favorite podcast besides Critical Thinking (of which I'm now the co-host).\nhttps://t.co/RdqNa9dElm\n---\nBest Impactful Security Write-Up\nHacking Kia by @samwcyo  and friends is super impactful continued research in their car-hacking saga.\nhttps://t.co/DOjiKVT6On\n---\nBest Command-Line AI Tool\nFabric - fantastic for piping content into LLMs from the command line.\nhttps://t.co/mrci2Barc2\n---\nBest Bug Bounty Program\n@GoogleVRP  - I spent the most time on it this year, and I got to go to Spain for their live hacking event.\nhttps://t.co/HWhgHW0tsr\n---\nBest AI Jailbreaking Resource\nL1B3RT4S - a collection of jailbreaks from @elder_plinius . I use this all the time.\nhttps://t.co/OzUqLIdlcS\n---\nBest Cybersecurity Model\nWhite Rabbit NEO - it's still got some work to do to get better, but I love the idea of a hacking-specific model that is pre-jailbroken so I can ask without getting rejections.\nhttps://t.co/htk7WQ4uvl\n---\nBest AI Engineering Book\nAI Engineering - this is basically the only book at this point, but I've heard great things about it.\nhttps://t.co/9t3ECVhLtP\n---\nBest AI YouTube Channel\n@MatthewBerman  Channel - He does chase the news a bit, but he works hard, is down-to-earth, and keeps improving. I enjoy his content.\nhttps://t.co/nhdjBUEOUQ\n---\nBest Prompting Guide\nEverything I Know About Prompting LLMs by @hrishioa  - my favorite guide to prompting.\nhttps://t.co/kFDNGLGdkr\n---\nBest Transcription App\nOffmute - using multimodal LLMs as STT was an idea i had and @hrishioa  nailed the execution here.\nhttps://t.co/8ViWEaEhPz\n\nTo get content like this, sign up to my email list: https://t.co/GSqFOAvtii"
    },
    "text": "I sent this to my email list and people loved it, so I wanted to post it here. It's a completely subjective list of stuff I loved in 2024. I hope you love it tooüòä \n\nBest MacOS Desktop App\nmsty - fantastic AI client that supports local and API usage of models. You can use‚Ä¶ https://t.co/mmOTUG2UJi https://t.co/tgZi36FfBs",
    "edit_history_tweet_ids": ["1881368754514231540"],
    "created_at": "2025-01-20T15:50:39.000Z",
    "author_id": "260411518"
  },
  {
    "id": "1881368466055381082",
    "text": "RT @xiangyue96: Part of my views on measuring AI performance were covered by Nature article recently. Defining and measuring intelligence i‚Ä¶",
    "edit_history_tweet_ids": ["1881368466055381082"],
    "created_at": "2025-01-20T15:49:31.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881364671816507432" }],
    "author_id": "185910194"
  },
  {
    "id": "1881367858355282190",
    "text": "If anyone wants to follow along with the \"mimick me\" prompt sequence this is the few shot prompt I am modifying.\nhttps://t.co/w5pypGerPW",
    "edit_history_tweet_ids": ["1881367858355282190"],
    "in_reply_to_user_id": "829108178059096064",
    "created_at": "2025-01-20T15:47:06.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881346529728094485" }
    ],
    "author_id": "829108178059096064"
  },
  {
    "id": "1881367535033176331",
    "attachments": { "media_keys": ["3_1881367523750191104"] },
    "text": "Honored to be invited to attend the Inaugural at the Capitol! Optimism about AI and tech is palpable in DC this week. üá∫üá∏\n\nProud to be an American. https://t.co/EufBE0kItE",
    "edit_history_tweet_ids": ["1881367535033176331"],
    "created_at": "2025-01-20T15:45:49.000Z",
    "author_id": "615818451"
  },
  {
    "id": "1881367237929615631",
    "text": "now available in ai-gradio\n\npip install --upgrade \"ai-gradio[deepseek]\"\n\nimport gradio as gr\nimport ai_gradio\n\ngr.load(\nname='deepseek:deepseek-reasoner',\nsrc=ai_gradio.registry,\ncoder=true\n).launch()\n\ngithub: https://t.co/vy68ARTizv",
    "edit_history_tweet_ids": ["1881367237929615631"],
    "in_reply_to_user_id": "2465283662",
    "created_at": "2025-01-20T15:44:38.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881364292374802514" }
    ],
    "author_id": "2465283662"
  },
  {
    "id": "1881367029665632359",
    "text": "Magic is what happens when an unstoppable RL optimization algorithm powered by sufficient compute meets an unhackable RL environment https://t.co/LvCPtDntPh",
    "edit_history_tweet_ids": ["1881367029665632359"],
    "created_at": "2025-01-20T15:43:48.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881329993206374443" }],
    "author_id": "1718879852827484160"
  },
  {
    "id": "1881366875382468777",
    "text": "I can't stop chortling\nIt's a good day https://t.co/2c88GYOcSy",
    "edit_history_tweet_ids": ["1881366875382468777"],
    "created_at": "2025-01-20T15:43:11.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318570132664359" }],
    "author_id": "2854214132"
  },
  {
    "id": "1881366760630452523",
    "text": "wow @angelusm0rt1s kept telling me that Moonshot is an important lab and then they drop this. The paper seems legit. Also it's multimodal!\n\nI see no details about the model though. https://t.co/d7zV2p6FYx",
    "edit_history_tweet_ids": ["1881366760630452523"],
    "created_at": "2025-01-20T15:42:44.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881332472748851259" }],
    "author_id": "192201556"
  },
  {
    "id": "1881366569152049504",
    "text": "To celebrate this milestone, I'm working hard on an update to the Mamba guide (with animations!) and there's also a video version almost ready to record!\n\nLink to the newsletter:\nhttps://t.co/5dehBmx0XT",
    "edit_history_tweet_ids": ["1881366569152049504"],
    "in_reply_to_user_id": "1260142508748804096",
    "created_at": "2025-01-20T15:41:58.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881366561145200845" }
    ],
    "author_id": "1260142508748804096"
  },
  {
    "id": "1881366561145200845",
    "attachments": { "media_keys": ["3_1881366402642087936"] },
    "text": "I'm incredibly grateful that \"Exploring Language Models\" has reached over 10k subscribersüî•\n\nA big thank you to all readers who have enjoyed my visual guides to Mixture of Experts (MoE), Quantization, State Space Models (SSMs) and Mamba ü§ó https://t.co/j4GB6abawP",
    "edit_history_tweet_ids": ["1881366561145200845"],
    "created_at": "2025-01-20T15:41:56.000Z",
    "author_id": "1260142508748804096"
  },
  {
    "id": "1881366340768027119",
    "text": "RT @casper_hansen_: This is the funniest thing I have seen all day. Max cope",
    "edit_history_tweet_ids": ["1881366340768027119"],
    "created_at": "2025-01-20T15:41:04.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881339841998373080" }],
    "author_id": "2854214132"
  },
  {
    "id": "1881365646082191610",
    "text": "@jxmnop I‚Äôm glad we agree",
    "edit_history_tweet_ids": ["1881365646082191610"],
    "in_reply_to_user_id": "783098774130401280",
    "created_at": "2025-01-20T15:38:18.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881365290925351002" }
    ],
    "author_id": "967757817355653120"
  },
  {
    "id": "1881365461851636195",
    "text": "I don‚Äôt understand why this is the case. MCTS seems like it should be a straight improvement here, particularly given that we have a good reward signal. \n\nIt‚Äôs unclear to me if anyone is trying PUCT vs just UCT from the papers. https://t.co/gb6xkJUFaK",
    "edit_history_tweet_ids": ["1881365461851636195"],
    "created_at": "2025-01-20T15:37:34.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881348105586855962" }],
    "author_id": "1495078042498002950"
  },
  {
    "id": "1881365290925351002",
    "text": "@hkproj üòï\nhttps://t.co/6oS9T0DhlE",
    "edit_history_tweet_ids": ["1881365290925351002"],
    "in_reply_to_user_id": "967757817355653120",
    "created_at": "2025-01-20T15:36:54.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1874895850796945593" },
      { "type": "replied_to", "id": "1881340261735027194" }
    ],
    "author_id": "783098774130401280"
  },
  {
    "id": "1881364292374802514",
    "attachments": { "media_keys": ["3_1881364183570100224"] },
    "text": "DeepSeek-R1 Coder\n\nits like cursor in the browser https://t.co/mI2mxpjT9H",
    "edit_history_tweet_ids": ["1881364292374802514"],
    "created_at": "2025-01-20T15:32:56.000Z",
    "author_id": "2465283662"
  },
  {
    "id": "1881364078733791411",
    "text": "‚ÄúLet me tell you how this indie movie should have spent more money‚Äù https://t.co/DnNT9vFj2t",
    "edit_history_tweet_ids": ["1881364078733791411"],
    "created_at": "2025-01-20T15:32:05.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881054605783765278" }],
    "author_id": "52247685"
  },
  {
    "id": "1881364073314742448",
    "text": "@Teknium1 At 4bit, it could run on 16 3090s or Mac minis, so a dedicated hobbyist could potentially get it running at home...",
    "edit_history_tweet_ids": ["1881364073314742448"],
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T15:32:03.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881316758218535039" }
    ],
    "author_id": "2854214132"
  },
  {
    "id": "1881363608208310594",
    "text": "RT @ariG23498: Discussions under Hugging Face articles is a very good way to engage with the post authors.\n\nhttps://t.co/jq9Afnkrfo https:/‚Ä¶",
    "edit_history_tweet_ids": ["1881363608208310594"],
    "created_at": "2025-01-20T15:30:12.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881237555993252103" }],
    "author_id": "186420551"
  },
  {
    "id": "1881363572271587461",
    "text": "Conner Mantz breaks the American half marathon record and DeepSeek fires back by releasing R1 üßê",
    "edit_history_tweet_ids": ["1881363572271587461"],
    "created_at": "2025-01-20T15:30:04.000Z",
    "author_id": "3378986176"
  },
  {
    "id": "1881363442155901125",
    "text": "RT @Hesamation: Hugging Face is pre-registering for a free AI Agents course, and over 35,000 people have already signed up in a few days. h‚Ä¶",
    "edit_history_tweet_ids": ["1881363442155901125"],
    "created_at": "2025-01-20T15:29:33.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881292274178691271" }],
    "author_id": "186420551"
  },
  {
    "id": "1881363399780544671",
    "text": "Awesome new open source AI models released!\n\n@deepseek_ai leapfrogs OpenAI o1 (Deepseek-R1) but also distills that ability into smaller models (DeepSeek-R1-Distill) we can run on consumer hardware.\n\nAnd @MiniMax__AI has created a very competitive multimodal model (MiniMax-VL-01,‚Ä¶ https://t.co/GHbIWXF3ZV",
    "edit_history_tweet_ids": ["1881363399780544671"],
    "created_at": "2025-01-20T15:29:23.000Z",
    "author_id": "2854214132",
    "note_tweet": {
      "text": "Awesome new open source AI models released!\n\n@deepseek_ai leapfrogs OpenAI o1 (Deepseek-R1) but also distills that ability into smaller models (DeepSeek-R1-Distill) we can run on consumer hardware.\n\nAnd @MiniMax__AI has created a very competitive multimodal model (MiniMax-VL-01, MiniMax-Text-01), with up to 4 million token context.\n\nVery excited to see how these innovations shake things up.  Thank you for your amazing contributions to open source AI!",
      "entities": {
        "mentions": [
          {
            "start": 45,
            "end": 57,
            "username": "deepseek_ai",
            "id": "1714580962569588736"
          },
          {
            "start": 203,
            "end": 215,
            "username": "MiniMax__AI",
            "id": "1875078099538423808"
          }
        ]
      }
    }
  },
  {
    "id": "1881363373251760291",
    "text": "RT @casper_hansen_: R1 supported, AGI unlocked?\nüöÄAutoAWQ v0.2.8 is out!\n‚ú®Major fixes &amp; now supports DeepSeek V3 + R1\nüíæCompress your models‚Ä¶",
    "edit_history_tweet_ids": ["1881363373251760291"],
    "created_at": "2025-01-20T15:29:16.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881298724779094497" }],
    "author_id": "2854214132"
  },
  {
    "id": "1881363356982153541",
    "attachments": { "media_keys": ["3_1881362538161405954"] },
    "text": "RL and open-source for the win!\n\nThe DeepSeek-R1 is a beast though. It still relies on multi-stage training and cold-start data before RL. \n\n\"DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks\" https://t.co/Ge42ZFq67D https://t.co/yHgdDN4M1t",
    "edit_history_tweet_ids": ["1881363356982153541"],
    "created_at": "2025-01-20T15:29:13.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "author_id": "3448284313"
  },
  {
    "id": "1881363218708492705",
    "text": "RT @acharya_aditya2: @huggingface made it happen for AI community to deploy opensource models. thank you @ClementDelangue",
    "edit_history_tweet_ids": ["1881363218708492705"],
    "created_at": "2025-01-20T15:28:40.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881360279919063146" }],
    "author_id": "186420551"
  },
  {
    "id": "1881363210982564304",
    "attachments": { "media_keys": ["3_1881363032514691072"] },
    "text": "Full snippet from the paper for those who are interested. I find this very compelling. We can just train specialized, Alpaca-style reasoning models relatively easily on our domain of choice.  And, adopting the more complex (RL-based) strategy for doing this isn't beneficial. https://t.co/DimGASsgOF",
    "edit_history_tweet_ids": ["1881363210982564304"],
    "in_reply_to_user_id": "1425585940542763010",
    "created_at": "2025-01-20T15:28:38.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881362098141446598" }
    ],
    "author_id": "1425585940542763010"
  },
  {
    "id": "1881362591051911239",
    "attachments": { "media_keys": ["3_1881362016792674304"] },
    "text": "in 387 days, they achieved the Domain Expansion\nbut when @sybilhyz reported on Math-Shepherd, I knew it was already guaranteed to hit https://t.co/BwdjmGeyhE https://t.co/HEXDC9kjov",
    "edit_history_tweet_ids": ["1881362591051911239"],
    "created_at": "2025-01-20T15:26:10.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1740942083899441440" }],
    "author_id": "192201556"
  },
  {
    "id": "1881362098141446598",
    "text": "Seems like RL finetuning small models is definitively worse than distilling the capabilities of a much larger RL finetuned model. We truly are about to enter the Alpaca era of reasoning models. May the best CoT win! https://t.co/mHeMcozPzD",
    "edit_history_tweet_ids": ["1881362098141446598"],
    "created_at": "2025-01-20T15:24:12.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "author_id": "1425585940542763010"
  },
  {
    "id": "1881360806916530399",
    "text": "paper: https://t.co/WBBJJ7A7YU\n\nIf you want to learn how to build Agentic RAG systems, check out my new RAG course: https://t.co/xTt1D3nxq7",
    "edit_history_tweet_ids": ["1881360806916530399"],
    "in_reply_to_user_id": "3448284313",
    "created_at": "2025-01-20T15:19:05.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881360794019156362" }
    ],
    "author_id": "3448284313"
  },
  {
    "id": "1881360794019156362",
    "attachments": { "media_keys": ["3_1881360790470696961"] },
    "text": "Agentic RAG Overview\n\nThis is a great intro to LLM agents and Agentic RAG.\n\nIt provides a comprehensive exploration of Agentic RAG architectures, applications, and implementation strategies. https://t.co/rPIXwp3hiL",
    "edit_history_tweet_ids": ["1881360794019156362"],
    "created_at": "2025-01-20T15:19:01.000Z",
    "author_id": "3448284313"
  },
  {
    "id": "1881360724141937150",
    "attachments": { "media_keys": ["3_1881360673646559232"] },
    "text": "i have NEVER seen 20/mo o1 think for this long. holy crap https://t.co/hr5j1rPkpI",
    "edit_history_tweet_ids": ["1881360724141937150"],
    "created_at": "2025-01-20T15:18:45.000Z",
    "author_id": "260411518"
  },
  {
    "id": "1881360186562232397",
    "text": "github pages has been taking FOREVER to roll changes out",
    "edit_history_tweet_ids": ["1881360186562232397"],
    "created_at": "2025-01-20T15:16:37.000Z",
    "author_id": "260411518"
  },
  {
    "id": "1881359939635224796",
    "text": "@zizhpan congrats its now available in ai-gradio    \n\npip install --upgrade \"ai-gradio[deepseek]\"  \n\nimport gradio as gr  \nimport ai_gradio    \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry, ).launch()  \n\ngithub: https://t.co/vy68ARTizv",
    "edit_history_tweet_ids": ["1881359939635224796"],
    "in_reply_to_user_id": "1496348031494819842",
    "created_at": "2025-01-20T15:15:38.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881322593065869582" }
    ],
    "author_id": "2465283662"
  },
  {
    "id": "1881358685982830806",
    "text": "Looks like the DeepSeek-R1 paper that just came out supports this precisely. https://t.co/CG1zCYzy0f",
    "edit_history_tweet_ids": ["1881358685982830806"],
    "created_at": "2025-01-20T15:10:39.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1879993804201292065" }],
    "author_id": "1605274291569799168"
  },
  {
    "id": "1881358478029234618",
    "text": "RT @omarsar0: Windsurf makes coding insanely fun and fast!\n\nIt's quickly becoming my favorite coding tool.\n\nAnd the new features are üî•\n\n- W‚Ä¶",
    "edit_history_tweet_ids": ["1881358478029234618"],
    "created_at": "2025-01-20T15:09:49.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880646342265205169" }],
    "author_id": "3448284313"
  },
  {
    "id": "1881358405274857732",
    "text": "RT @UnslothAI: DeepSeek-R1 GGUF's are now on @HuggingFace!\n\nIncludes all Llama &amp; Qwen distilled models + 2 to 8-bit quantized versions.\n\nHo‚Ä¶",
    "edit_history_tweet_ids": ["1881358405274857732"],
    "created_at": "2025-01-20T15:09:32.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881357596717891955" }],
    "author_id": "717359704226172928"
  },
  {
    "id": "1881358298785710172",
    "text": "RT @dair_ai: Here are the top AI Papers of the Week (Jan 13-19):  \n\n- VideoRAG\n- MiniMax-01\n- Enhancing RAG\n- Self-Adaptive LLMs\n- Foundati‚Ä¶",
    "edit_history_tweet_ids": ["1881358298785710172"],
    "created_at": "2025-01-20T15:09:07.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880986912460300568" }],
    "author_id": "889050642903293953"
  },
  {
    "id": "1881358025925279764",
    "text": "quick start colab: https://t.co/gIJgCzRKgs",
    "edit_history_tweet_ids": ["1881358025925279764"],
    "in_reply_to_user_id": "2465283662",
    "created_at": "2025-01-20T15:08:01.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881352027273568411" }
    ],
    "author_id": "2465283662"
  },
  {
    "id": "1881357538501005635",
    "text": "RT @CarinaLHong: 1. OAI binds Epoch to an NDA until eve of o3 performance claim, preventing Epoch to disclose OAI is the donor and that OAI‚Ä¶",
    "edit_history_tweet_ids": ["1881357538501005635"],
    "created_at": "2025-01-20T15:06:05.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880820323597357273" }],
    "author_id": "2895499182"
  },
  {
    "id": "1881357171927191719",
    "text": "API-Guide: https://t.co/rU4kZ4aAnl\n\nPaper for more details: https://t.co/XQAw2l2YAS",
    "edit_history_tweet_ids": ["1881357171927191719"],
    "in_reply_to_user_id": "1271482878958940160",
    "created_at": "2025-01-20T15:04:38.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881357168814838064" }
    ],
    "author_id": "1271482878958940160"
  },
  {
    "id": "1881357168814838064",
    "text": ".@DeepSeek_ai showed how pure reinforcement learning (RL) can improve models' reasoning üëá\n\n‚Ä¢ They trained a base DeepSeek-V3 model using an RL framework called GRPO to get an improved model, DeepSeek-R1-Zero.\n\n‚Ä¢ Building on the success of DeepSeek-R1-Zero, researchers‚Ä¶ https://t.co/H5s25oyh9y https://t.co/vMhHvV1uZF",
    "edit_history_tweet_ids": ["1881357168814838064"],
    "created_at": "2025-01-20T15:04:37.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "author_id": "1271482878958940160",
    "note_tweet": {
      "text": ".@DeepSeek_ai showed how pure reinforcement learning (RL) can improve models' reasoning üëá\n\n‚Ä¢ They trained a base DeepSeek-V3 model using an RL framework called GRPO to get an improved model, DeepSeek-R1-Zero.\n\n‚Ä¢ Building on the success of DeepSeek-R1-Zero, researchers developed the top-performing DeepSeek-R1. \n\nThey added several other stages:\n\n1. Cold start training: \nTraining with high-quality data makes the process easier and improves model's outputs.\n\n2. The first RL stage:\nDeepSeek combined reasoning accuracy and language consistency into a single score to guide the training.\n\n3. They fine-tuned the model using 800k samples (600k reasoning and 200k non-reasoning) to improve its overall capabilities.\n\n- The final RL stage refines the model to balance reasoning, helpfulness, and safety.\n\nAnd so, DeepSeek-R1 achieves this top level performance, especially in math, code, and reasoning tasksüëá\n\nResearchers also transferred DeepSeek-R1's reasoning to smaller models like Qwen and Llama for better accessibility.",
      "entities": {
        "mentions": [
          {
            "start": 1,
            "end": 13,
            "username": "DeepSeek_ai",
            "id": "1714580962569588736"
          }
        ]
      }
    }
  },
  {
    "id": "1881357078448783597",
    "attachments": { "media_keys": ["3_1881356573609484288"] },
    "text": "This is how I'll be seeing all incoming snide social media remarks from FRonTiEr LaBs directed at the Whale. Voluntary self-debasement, parade of the vanquished. Back to your nuclear-powered hyperclusters, big boys, you're the master race, you have no time to cope. https://t.co/Ek3fAL6m2n https://t.co/1Jco0wdrHl",
    "edit_history_tweet_ids": ["1881357078448783597"],
    "created_at": "2025-01-20T15:04:16.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881349799888433548" }],
    "author_id": "192201556"
  },
  {
    "id": "1881356534200049994",
    "text": "@deepseek_ai congrats its now available in ai-gradio  \n\npip install --upgrade \"ai-gradio[deepseek]\"\n\nimport gradio as gr \nimport ai_gradio  \n\ngr.load(name='deepseek:deepseek-reasoner', src=ai_gradio.registry, ).launch()\n\ngithub: https://t.co/vy68ARTizv",
    "edit_history_tweet_ids": ["1881356534200049994"],
    "in_reply_to_user_id": "1714580962569588736",
    "created_at": "2025-01-20T15:02:06.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318130334814301" }
    ],
    "author_id": "2465283662"
  },
  {
    "id": "1881354975856734243",
    "text": "RT @CopilotKit: Thank you @LangChainAI for featuring this awesome tutorial by @dayvid_JS‚úçÔ∏è\n\nLearn how to build a Perplexity clone with Lang‚Ä¶",
    "edit_history_tweet_ids": ["1881354975856734243"],
    "created_at": "2025-01-20T14:55:54.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881278674009497756" }],
    "author_id": "2728439146"
  },
  {
    "id": "1881354637137306057",
    "attachments": { "media_keys": ["3_1881352507399847936"] },
    "text": "RT @BRussellsimp: Brutal https://t.co/egKurk6abV",
    "edit_history_tweet_ids": ["1881354637137306057"],
    "created_at": "2025-01-20T14:54:34.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881352510549770593" }],
    "author_id": "192201556"
  },
  {
    "id": "1881354463195353363",
    "text": "RT @hsu_steve: People don't realize that a +4 guy can be much better at hiring +3 or +4 guys for his team than a +3 guy who is an \"impressi‚Ä¶",
    "edit_history_tweet_ids": ["1881354463195353363"],
    "created_at": "2025-01-20T14:53:52.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881354088744665103" }],
    "author_id": "192201556"
  },
  {
    "id": "1881353562023993698",
    "attachments": { "media_keys": ["3_1881353454313934848"] },
    "text": "They literally ask everyone to distill from R1 to build better smaller models \n\nThis is what science is about https://t.co/VPpVuBrTWT",
    "edit_history_tweet_ids": ["1881353562023993698"],
    "created_at": "2025-01-20T14:50:17.000Z",
    "author_id": "1718879852827484160"
  },
  {
    "id": "1881353493023260890",
    "attachments": { "media_keys": ["3_1881353264513372160"] },
    "text": "Unravel the mystery of AGI with curiosity. Answer the essential question with long-termism.\n‚ÄúOkay, so the user is upset and called me a retard because of my previous answer. Let me try to figure out why.‚Äù\nYes. Let's. About damn time. https://t.co/kJs8gaAUJs https://t.co/gzGfTK9i8m",
    "edit_history_tweet_ids": ["1881353493023260890"],
    "created_at": "2025-01-20T14:50:01.000Z",
    "author_id": "192201556",
    "note_tweet": {
      "text": "Unravel the mystery of AGI with curiosity. Answer the essential question with long-termism.\n‚ÄúOkay, so the user is upset and called me a retard because of my previous answer. Let me try to figure out why.‚Äù\nYes. Let's. About damn time."
    }
  },
  {
    "id": "1881353140987208051",
    "text": "RT @Kimi_ai_: üöÄ Introducing Kimi k1.5 --- an o1-level multi-modal model\n\n-Sota short-CoT performance, outperforming GPT-4o and Claude Sonne‚Ä¶",
    "edit_history_tweet_ids": ["1881353140987208051"],
    "created_at": "2025-01-20T14:48:37.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881332472748851259" }],
    "author_id": "2854214132"
  },
  {
    "id": "1881353126210687089",
    "attachments": { "media_keys": ["3_1881345246191398912"] },
    "text": "We are living in a timeline where a non-US company is keeping the original mission of OpenAI alive - truly open, frontier research that empowers all. It makes no sense. The most entertaining outcome is the most likely.\n\nDeepSeek-R1 not only open-sources a barrage of models but‚Ä¶ https://t.co/lEwLMTWprV https://t.co/M7eZnEmCOY",
    "edit_history_tweet_ids": ["1881353126210687089"],
    "created_at": "2025-01-20T14:48:33.000Z",
    "author_id": "1007413134",
    "note_tweet": {
      "text": "We are living in a timeline where a non-US company is keeping the original mission of OpenAI alive - truly open, frontier research that empowers all. It makes no sense. The most entertaining outcome is the most likely.\n\nDeepSeek-R1 not only open-sources a barrage of models but also spills all the training secrets. They are perhaps the first OSS project that shows major, sustained growth of an RL flywheel.\n\nImpact can be done by \"ASI achieved internally\" or mythical names like \"Project Strawberry\". \nImpact can also be done by simply dumping the raw algorithms and matplotlib learning curves.\n\nI'm reading the paper:\n\n> Purely driven by RL, no SFT at all (\"cold start\"). Reminiscent of AlphaZero - master Go, Shogi, and Chess from scratch, without imitating human grandmaster moves first. This is the most significant takeaway from the paper.\n> Use groundtruth rewards computed by hardcoded rules. Avoid any learned reward models that RL can easily hack against.\n> Thinking time of the model steadily increases as training proceeds - this is not pre-programmed, but an emergent property! \n> Emergence of self-reflection and exploration behaviors.\n> GRPO instead of PPO: it removes the critic net from PPO and uses the average reward of multiple samples instead. Simple method to reduce memory use. Note that GRPO was also invented by DeepSeek in Feb 2024 ... what a cracked team."
    }
  },
  {
    "id": "1881352938175737863",
    "text": "Almost as if you will have everything you need to make anything you want. https://t.co/M8MB2pgdqd",
    "edit_history_tweet_ids": ["1881352938175737863"],
    "created_at": "2025-01-20T14:47:48.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881306578151965060" }],
    "author_id": "788107483306942464"
  },
  {
    "id": "1881352590098604099",
    "text": "Kudos @Khalid_OLN and the @JahezApp data team for this great write-up! Excited to see they found @cohere's embeddings \"to be the most powerful in embedding Arabic and Multilingual queries and documents at scale\". https://t.co/Dqzd1xeQRl https://t.co/qICO0g1zBg",
    "edit_history_tweet_ids": ["1881352590098604099"],
    "created_at": "2025-01-20T14:46:25.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1874487058330525791" }],
    "author_id": "1245260977626587136",
    "note_tweet": {
      "text": "Kudos @Khalid_OLN and the @JahezApp data team for this great write-up! Excited to see they found @cohere's embeddings \"to be the most powerful in embedding Arabic and Multilingual queries and documents at scale\".",
      "entities": {
        "mentions": [
          {
            "start": 6,
            "end": 17,
            "username": "Khalid_OLN",
            "id": "720629161"
          },
          {
            "start": 26,
            "end": 35,
            "username": "JahezApp",
            "id": "743383710305763328"
          },
          {
            "start": 97,
            "end": 104,
            "username": "cohere",
            "id": "1326237414025801729"
          }
        ]
      }
    }
  },
  {
    "id": "1881352312280822015",
    "text": "Telescope Magazine dot com https://t.co/EG3PH61L7g",
    "edit_history_tweet_ids": ["1881352312280822015"],
    "created_at": "2025-01-20T14:45:19.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881345897524572628" }],
    "author_id": "788107483306942464"
  },
  {
    "id": "1881352041953669434",
    "text": "Great to see @deepseek_ai keep pushing the boundaries of open models, and also importantly publish a significant number of details about how they did it! https://t.co/cgpyJTlQJ5",
    "edit_history_tweet_ids": ["1881352041953669434"],
    "created_at": "2025-01-20T14:44:15.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "author_id": "185910194"
  },
  {
    "id": "1881352027273568411",
    "text": "github: https://t.co/vy68ARTizv",
    "edit_history_tweet_ids": ["1881352027273568411"],
    "in_reply_to_user_id": "2465283662",
    "created_at": "2025-01-20T14:44:11.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881352022282383791" }
    ],
    "author_id": "2465283662"
  },
  {
    "id": "1881352022282383791",
    "attachments": { "media_keys": ["3_1881351925003624448"] },
    "text": "DeepSeek-R1 is here!  \n\nPerformance on par with OpenAI-o1, MIT licensed, and now available in ai-gradio\n\npip install --upgrade \"ai-gradio[deepseek]\n\nimport gradio as gr\nimport ai_gradio\n\ngr.load(\nname='deepseek:deepseek-reasoner',\nsrc=ai_gradio.registry,\n).launch() https://t.co/yOzi0lqKtC",
    "edit_history_tweet_ids": ["1881352022282383791"],
    "created_at": "2025-01-20T14:44:10.000Z",
    "author_id": "2465283662"
  },
  {
    "id": "1881351146570477895",
    "text": "https://t.co/xWdLNc1BvB",
    "edit_history_tweet_ids": ["1881351146570477895"],
    "in_reply_to_user_id": "73105934",
    "created_at": "2025-01-20T14:40:41.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881351047312191960" }
    ],
    "author_id": "73105934"
  },
  {
    "id": "1881351047312191960",
    "attachments": { "media_keys": ["7_1881349822793261060"] },
    "text": "I updated my repo, DeepSeek Engineer, to support the new reasoning model, deepseek-reasoner.\n\nThe script now:  \n- Shows the reasoning process before providing the final answer  \n- Maintains all original features (file operations, diff editing, etc.)  \n\nIt's pretty powerful! ‚ö°Ô∏è https://t.co/i27RQ3yxQP",
    "edit_history_tweet_ids": ["1881351047312191960"],
    "created_at": "2025-01-20T14:40:18.000Z",
    "author_id": "73105934"
  },
  {
    "id": "1881350241515164135",
    "attachments": { "media_keys": ["3_1881348938722144256"] },
    "text": "podcast interviewer: do you think open-source will catch up to frontier labs?\n\ntypical researcher @ frontier lab: nah, you just can't get the talent density and compute to make the breakthroughs we're making. open source will always be 1-2 years behind at best\n\nopen source: üê≥ https://t.co/Wg19mkBdRR",
    "edit_history_tweet_ids": ["1881350241515164135"],
    "created_at": "2025-01-20T14:37:06.000Z",
    "author_id": "1029493180704714753"
  },
  {
    "id": "1881350099202412678",
    "text": "Some providers: please don't distill our models\nWhale provider: here, we distilled them for you",
    "edit_history_tweet_ids": ["1881350099202412678"],
    "created_at": "2025-01-20T14:36:32.000Z",
    "author_id": "3378986176"
  },
  {
    "id": "1881349017843716337",
    "attachments": { "media_keys": ["3_1881349015436132352"] },
    "text": "This is frontier level because they've recovered newsonnet and flash distillation discoveries https://t.co/Z5AL4yhD4P",
    "edit_history_tweet_ids": ["1881349017843716337"],
    "created_at": "2025-01-20T14:32:14.000Z",
    "author_id": "3378986176"
  },
  {
    "id": "1881348630277202405",
    "text": "@sama As I said: https://t.co/KauR029uic",
    "edit_history_tweet_ids": ["1881348630277202405"],
    "in_reply_to_user_id": "1605",
    "created_at": "2025-01-20T14:30:41.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1870444425375309902" },
      { "type": "replied_to", "id": "1881258443669172470" }
    ],
    "author_id": "3448284313"
  },
  {
    "id": "1881348458877210745",
    "attachments": { "media_keys": ["3_1881348453823131649"] },
    "text": "https://t.co/pDglmq74DH",
    "edit_history_tweet_ids": ["1881348458877210745"],
    "created_at": "2025-01-20T14:30:01.000Z",
    "author_id": "1499415401763115019"
  },
  {
    "id": "1881348370238951447",
    "text": "Wow, incredible work. Opensource model matching o1 on math/code benchmarks is wild, as is cheap distilled models and zero SFT/pure RL artifacts. \n\nSo how do you scale this to o3? Generate more synthetic data, verify, improve reward model, repeat? Seems doable... https://t.co/rtWo0ZqCTF",
    "edit_history_tweet_ids": ["1881348370238951447"],
    "created_at": "2025-01-20T14:29:39.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "author_id": "811297774524317697"
  },
  {
    "id": "1881347730460774706",
    "text": "@nrehiew_ Right?!?",
    "edit_history_tweet_ids": ["1881347730460774706"],
    "in_reply_to_user_id": "1718879852827484160",
    "created_at": "2025-01-20T14:27:07.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881346646094885056" }
    ],
    "author_id": "1495078042498002950"
  },
  {
    "id": "1881347345432125447",
    "text": "@dylan522p 1.2 10.000s precisely\n\nbut sure I hope you're right\nthe question is, what are they doing with all those GPUs if not training models lol",
    "edit_history_tweet_ids": ["1881347345432125447"],
    "in_reply_to_user_id": "985281530070265862",
    "created_at": "2025-01-20T14:25:35.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881346673785618825" }
    ],
    "author_id": "192201556"
  },
  {
    "id": "1881347203303887108",
    "text": "@Teknium1 Clearly not tbh",
    "edit_history_tweet_ids": ["1881347203303887108"],
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T14:25:01.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881316758218535039" }
    ],
    "author_id": "19111917"
  },
  {
    "id": "1881346673785618825",
    "text": "@teortaxesTex They have employment ads up in China that state they have 10,000s of GPUs",
    "edit_history_tweet_ids": ["1881346673785618825"],
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T14:22:55.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881333430472020099" }
    ],
    "author_id": "985281530070265862"
  },
  {
    "id": "1881346646094885056",
    "text": "I always thought you needed both PRMs and ORMs because the reward would be too scarce otherwise. But what this shows is that the base model really has that dawg in it and RL just works https://t.co/SvJE8l8xjA",
    "edit_history_tweet_ids": ["1881346646094885056"],
    "created_at": "2025-01-20T14:22:48.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881345977568866710" }],
    "author_id": "1718879852827484160"
  },
  {
    "id": "1881346584912474351",
    "text": "RT @rudrankriyam: DeepSeek's new R1 Distill Qwen 1.5B outperforms GPT-4o and Claude-3.5-Sonnet with 28.9% on AIME and 83.9% on MATH!!\n\nAvai‚Ä¶",
    "edit_history_tweet_ids": ["1881346584912474351"],
    "created_at": "2025-01-20T14:22:34.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881326429222433187" }],
    "author_id": "245262377"
  },
  {
    "id": "1881346529728094485",
    "text": "Trying DeepSeek R1 https://t.co/HAvVF0LmE4",
    "edit_history_tweet_ids": ["1881346529728094485"],
    "created_at": "2025-01-20T14:22:21.000Z",
    "author_id": "829108178059096064"
  },
  {
    "id": "1881345979640869225",
    "attachments": { "media_keys": ["3_1881345976813699072"] },
    "text": "https://t.co/54nYlrucOA",
    "edit_history_tweet_ids": ["1881345979640869225"],
    "created_at": "2025-01-20T14:20:09.000Z",
    "author_id": "1718879852827484160"
  },
  {
    "id": "1881345977568866710",
    "text": "One aspect of r1 I am very pleased with is that PRMs weren‚Äôt useful. They violate my intuition. Outcome only rewards should be enough.",
    "edit_history_tweet_ids": ["1881345977568866710"],
    "created_at": "2025-01-20T14:20:09.000Z",
    "author_id": "1495078042498002950"
  },
  {
    "id": "1881345693597765870",
    "text": "@Teknium1 \"reasoning\" is a dirty, dirty token Tek\nlearn some shame, this is SV, you're making the world a better place there",
    "edit_history_tweet_ids": ["1881345693597765870"],
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T14:19:01.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318570132664359" }
    ],
    "author_id": "192201556"
  },
  {
    "id": "1881345378928427385",
    "attachments": { "media_keys": ["3_1881345008957083648"] },
    "text": "Distilling R1 onto Qwen 14B beats what the Qwen team did with the QwQ 32B model \n\nThis isn't talked about enough https://t.co/EtRqRzDSDa",
    "edit_history_tweet_ids": ["1881345378928427385"],
    "created_at": "2025-01-20T14:17:46.000Z",
    "author_id": "1718879852827484160"
  },
  {
    "id": "1881345205175300495",
    "text": "Mm, I'm going to have to reconfigure the weave-agent if I want it to make use of R1 I think. Oh well, back to Qwen 32B Instruct for the moment.",
    "edit_history_tweet_ids": ["1881345205175300495"],
    "created_at": "2025-01-20T14:17:05.000Z",
    "author_id": "829108178059096064"
  },
  {
    "id": "1881344893513297985",
    "attachments": { "media_keys": ["3_1881344346961649664"] },
    "text": "one more time for those in the back:\nQwen-14B SFT'd on R1 *strictly outperforms* deepseek-r1-lite-preview that used to be served on their web page\nI no longer care what that model was (tbh I do but they're not telling me), 16B, 27B, this is enough, thank you blessed whale https://t.co/NeMYYklEx5",
    "edit_history_tweet_ids": ["1881344893513297985"],
    "created_at": "2025-01-20T14:15:50.000Z",
    "author_id": "192201556"
  },
  {
    "id": "1881344806095601903",
    "attachments": { "media_keys": ["3_1881343937861861376"] },
    "text": "Reflection. https://t.co/05YwGfx1mJ",
    "edit_history_tweet_ids": ["1881344806095601903"],
    "created_at": "2025-01-20T14:15:30.000Z",
    "author_id": "1718879852827484160"
  },
  {
    "id": "1881344482316374286",
    "text": "RT @multimodalart: ComfyUI ‚Üí @huggingface Spaces ‚Üí serverless ZeroGPU ‚ú®üòå\n\nWe wrote a tutorial on how to turn any ComfyUI workflow into an e‚Ä¶",
    "edit_history_tweet_ids": ["1881344482316374286"],
    "created_at": "2025-01-20T14:14:12.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879200050439668177" }],
    "author_id": "1415428329210105859"
  },
  {
    "id": "1881343867309756854",
    "text": "feeling vindicated for telling people o1-mini is 8-20B https://t.co/eCeeD5oj1Z",
    "edit_history_tweet_ids": ["1881343867309756854"],
    "created_at": "2025-01-20T14:11:46.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881318135850213834" }],
    "author_id": "1499415401763115019"
  },
  {
    "id": "1881342682951496188",
    "text": "@nrehiew_ Haha ok",
    "edit_history_tweet_ids": ["1881342682951496188"],
    "in_reply_to_user_id": "1718879852827484160",
    "created_at": "2025-01-20T14:07:03.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881342545231524082" }
    ],
    "author_id": "1635195806855884801"
  },
  {
    "id": "1881342545231524082",
    "attachments": { "media_keys": ["3_1881342540361633792"] },
    "text": "@agihippo https://t.co/yfYC0Poq4m\n\nspecifcially https://t.co/2euMGNyIK6",
    "edit_history_tweet_ids": ["1881342545231524082"],
    "in_reply_to_user_id": "1635195806855884801",
    "created_at": "2025-01-20T14:06:31.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881341136507425018" }
    ],
    "author_id": "1718879852827484160"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881318135850213834" }],
    "edit_history_tweet_ids": ["1881342078506139881"],
    "text": "This was posted in September (on codeforces)‚Ä¶ now there is a 32B model distilled from r1 scoring 1600+ that you can run at home‚Ä¶ wow https://t.co/LmKqbENI2y https://t.co/d6Vabn3sZJ",
    "author_id": "70514287",
    "attachments": { "media_keys": ["3_1881342075460825088"] },
    "id": "1881342078506139881",
    "created_at": "2025-01-20T14:04:39.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881336647952019946" }
    ],
    "edit_history_tweet_ids": ["1881341136507425018"],
    "text": "@nrehiew_ ? What is that",
    "author_id": "1635195806855884801",
    "in_reply_to_user_id": "1718879852827484160",
    "id": "1881341136507425018",
    "created_at": "2025-01-20T14:00:55.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881241250789265855" }],
    "edit_history_tweet_ids": ["1881340583358161148"],
    "text": "Evaluations from the @deepseek_ai paper üí•\n\nDeepSeek-R1-Zero vs. OpenAI-o1-0912:\n\n&gt; R1-Zero achieves 71.0% pass@1 on AIME 2024, comparable to OpenAI-o1-0912 (74.4%)\n&gt; With majority voting, DeepSeek-R1-Zero reaches 86.7%, surpassing OpenAI-o1-0912\n\nDeepSeek-R1 vs. OpenAI-o1-1217:‚Ä¶ https://t.co/oDleCqhyqK https://t.co/HLE4DND0Mi",
    "author_id": "874987512850128897",
    "note_tweet": {
      "text": "Evaluations from the @deepseek_ai paper üí•\n\nDeepSeek-R1-Zero vs. OpenAI-o1-0912:\n\n> R1-Zero achieves 71.0% pass@1 on AIME 2024, comparable to OpenAI-o1-0912 (74.4%)\n> With majority voting, DeepSeek-R1-Zero reaches 86.7%, surpassing OpenAI-o1-0912\n\nDeepSeek-R1 vs. OpenAI-o1-1217:\n\n> R1 achieves 79.8% pass@1 on AIME 2024, slightly surpassing OpenAI-o1-1217 (79.2%)\n> On MATH-500, DeepSeek-R1 scores 97.3%, matching OpenAI-o1-1217\n\n> On coding tasks, DeepSeek-R1 achieves a 2029 Elo rating on Codeforces, outperforming 96.3% of human participants\n\nDistilled Models:\n\n> R1-Distill-Qwen-7B achieves 55.5% on AIME 2024, surpassing QwQ-32B-Preview\n> R1-Distill-Qwen-32B scores 72.6% on AIME 2024, 94.3% on MATH-500, and 57.2% on LiveCodeBench",
      "entities": {
        "mentions": [
          {
            "start": 21,
            "end": 33,
            "username": "deepseek_ai",
            "id": "1714580962569588736"
          }
        ]
      }
    },
    "id": "1881340583358161148",
    "created_at": "2025-01-20T13:58:43.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1617979122625712128" }],
    "edit_history_tweet_ids": ["1881340261735027194"],
    "text": "The hottest new programming language is Mandarin https://t.co/uJlnu7OXsd",
    "author_id": "967757817355653120",
    "id": "1881340261735027194",
    "created_at": "2025-01-20T13:57:26.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881339724545286257" }
    ],
    "edit_history_tweet_ids": ["1881339808200757757"],
    "text": "Totally undermining the whole moat set by OAI (there is none?)",
    "author_id": "70514287",
    "in_reply_to_user_id": "70514287",
    "id": "1881339808200757757",
    "created_at": "2025-01-20T13:55:38.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881339724545286257"],
    "text": "China releasing a MIT license model that is on par with o1 and 30x cheaper was not on my bingo card",
    "author_id": "70514287",
    "id": "1881339724545286257",
    "created_at": "2025-01-20T13:55:18.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881258443669172470" }
    ],
    "edit_history_tweet_ids": ["1881339512145825859"],
    "text": "@sama not AGI, but developers can start building with openai/agents and more here: https://t.co/vy68ARTizv\n\nusers can try it out here: https://t.co/yL4EvPFZpl",
    "author_id": "2465283662",
    "in_reply_to_user_id": "1605",
    "id": "1881339512145825859",
    "created_at": "2025-01-20T13:54:27.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881334350345891842" }
    ],
    "edit_history_tweet_ids": ["1881338873533583510"],
    "text": "@teortaxesTex The model is of course doing retrieval internally (I remember seeing a paper on knowledge graph embeddings that was mathematically very similar to RoPE) so it would make sense that you're going to have language like \"flagging this as an aha moment\" for the same reason you would.",
    "author_id": "829108178059096064",
    "in_reply_to_user_id": "829108178059096064",
    "id": "1881338873533583510",
    "created_at": "2025-01-20T13:51:55.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881330709929013440" }],
    "edit_history_tweet_ids": ["1881338419584057687"],
    "text": "RT @Grad62304977: No MCTS, no PRM, emergent behaviour, simple rl https://t.co/FpANJfu9Ex",
    "author_id": "1513853205125681162",
    "attachments": { "media_keys": ["3_1881330454197874688"] },
    "id": "1881338419584057687",
    "created_at": "2025-01-20T13:50:07.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881338206911877299"],
    "text": "now i just need a deepseek api with no training on input",
    "author_id": "1499415401763115019",
    "id": "1881338206911877299",
    "created_at": "2025-01-20T13:49:16.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881336647952019946" }],
    "edit_history_tweet_ids": ["1881338087676285086"],
    "text": "seriously. Their entire RLVR method and TULU paper is clearly vindicated https://t.co/esVRh9Gloz",
    "author_id": "1495078042498002950",
    "id": "1881338087676285086",
    "created_at": "2025-01-20T13:48:48.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881331287010550119" }],
    "edit_history_tweet_ids": ["1881337576117993553"],
    "text": "It isn't I agree https://t.co/y5LgXd5dUm",
    "author_id": "1365020011123773442",
    "id": "1881337576117993553",
    "created_at": "2025-01-20T13:46:46.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881336647952019946"],
    "text": "Biggest research winner today is the AI2 TULU 3 team",
    "author_id": "1718879852827484160",
    "id": "1881336647952019946",
    "created_at": "2025-01-20T13:43:05.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "edit_history_tweet_ids": ["1881336347644076499"],
    "text": "I would love to see how well this model fares on FrontierMath!\n\nAny chance you can evaluate it @EpochAIResearch ? https://t.co/hWIyHD4NF4",
    "author_id": "1029493180704714753",
    "id": "1881336347644076499",
    "created_at": "2025-01-20T13:41:53.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881334910528507989" }],
    "edit_history_tweet_ids": ["1881336152952918463"],
    "text": "RT @TheXeophon: Notes:\n- Two models, R1-Zero (V3-Base + RL, no SFT), R1 (SFT [CoT from R1-Zero] -&gt; RL [reasoning] -&gt; SFT [general] -&gt; RL [a‚Ä¶",
    "author_id": "1499415401763115019",
    "id": "1881336152952918463",
    "created_at": "2025-01-20T13:41:07.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881335375425425689" }],
    "edit_history_tweet_ids": ["1881335847779553734"],
    "text": "RT @LynaZhang: Code is now available at https://t.co/J27OlbsXN6",
    "author_id": "2465283662",
    "id": "1881335847779553734",
    "created_at": "2025-01-20T13:39:54.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318130334814301" }
    ],
    "edit_history_tweet_ids": ["1881334862864670769"],
    "text": "@deepseek_ai congrats on the release! - absolutely love this release:\n\nhttps://t.co/YV6AsCxHOl",
    "author_id": "874987512850128897",
    "in_reply_to_user_id": "1714580962569588736",
    "id": "1881334862864670769",
    "created_at": "2025-01-20T13:35:59.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881334820552556611"],
    "text": "learning mandarin now",
    "author_id": "1499415401763115019",
    "id": "1881334820552556611",
    "created_at": "2025-01-20T13:35:49.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881333772677001552" }
    ],
    "edit_history_tweet_ids": ["1881334350345891842"],
    "text": "@teortaxesTex That is, you can infer a lot about someone's cognitive strategy by how they use language. If someone uses a ton of extremely precise distinctions between things in their language this implies they want recall over exact inflections and concepts.",
    "author_id": "829108178059096064",
    "in_reply_to_user_id": "829108178059096064",
    "id": "1881334350345891842",
    "created_at": "2025-01-20T13:33:57.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881331554456371544" }
    ],
    "edit_history_tweet_ids": ["1881334278996562386"],
    "text": "@teortaxesTex @natolambert proud @natolambert believer",
    "author_id": "1499415401763115019",
    "in_reply_to_user_id": "192201556",
    "id": "1881334278996562386",
    "created_at": "2025-01-20T13:33:40.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881317131561922640" }
    ],
    "edit_history_tweet_ids": ["1881333772677001552"],
    "text": "@teortaxesTex So something I realized while thinking about retrieval and memory in the context of weave-agent is that using a precise, jargon-dense writing style where you're trying to maximize insight per token is actually a retrieval-maxxing strategy because it maximizes contrast.",
    "author_id": "829108178059096064",
    "in_reply_to_user_id": "192201556",
    "id": "1881333772677001552",
    "created_at": "2025-01-20T13:31:39.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881333024358539615" }],
    "edit_history_tweet_ids": ["1881333674563846311"],
    "text": "RT @sudu_cb: playjump image is LIVE for everyone\n\nCreate stunning images with FLUX from @bfl_ml \n„Éªuse Flux ultra, pro, dev and fast\n„Éªblazin‚Ä¶",
    "author_id": "834956706",
    "id": "1881333674563846311",
    "created_at": "2025-01-20T13:31:16.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1859302712803807696" }],
    "edit_history_tweet_ids": ["1881333351459717123", "1881333430472020099"],
    "text": "I don't think they have 50K Hopper GPUs, as they are still using GPU-poor methods like GRPO. \nWhat they might have is 20K IQ points total across their ‚âà140 researchers, however. Give or take.\n\nMaybe that's more important. https://t.co/9S9x3vWU5b",
    "author_id": "192201556",
    "id": "1881333430472020099",
    "created_at": "2025-01-20T13:30:17.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881333005865898407" }
    ],
    "edit_history_tweet_ids": ["1881333008818635007"],
    "text": "https://t.co/JrhISmblA5",
    "author_id": "1495078042498002950",
    "in_reply_to_user_id": "1495078042498002950",
    "id": "1881333008818635007",
    "created_at": "2025-01-20T13:28:37.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881316758218535039" }],
    "edit_history_tweet_ids": ["1881333005865898407"],
    "text": "actually ridiculous numbers https://t.co/XVqfDOgmor",
    "author_id": "1495078042498002950",
    "id": "1881333005865898407",
    "created_at": "2025-01-20T13:28:36.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881332030283423784"],
    "text": "Big milestones, big screens ‚ú®\n\nThanks for the spotlight, @NYSE üíô https://t.co/npw1lCQvtg",
    "author_id": "912955216559054848",
    "attachments": { "media_keys": ["3_1881331201933209600"] },
    "id": "1881332030283423784",
    "created_at": "2025-01-20T13:24:44.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881331287010550119" }
    ],
    "edit_history_tweet_ids": ["1881331554456371544"],
    "text": "total @natolambert victory",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "id": "1881331554456371544",
    "created_at": "2025-01-20T13:22:50.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881331287010550119"],
    "text": "perhaps the craziest thing is that they say that this is nowhere near the ceiling of 7-70B class models. Without any new data even. They have pushed them further, but just won't be sharing it. Driving a gaming-GPU-friendly checkpoint to o1 level: left as exercise for the reader. https://t.co/633Zq8Wep6 https://t.co/gluKb6FSdQ",
    "author_id": "192201556",
    "note_tweet": {
      "text": "perhaps the craziest thing is that they say that this is nowhere near the ceiling of 7-70B class models. Without any new data even. They have pushed them further, but just won't be sharing it. Driving a gaming-GPU-friendly checkpoint to o1 level: left as exercise for the reader."
    },
    "attachments": { "media_keys": ["3_1881330559101673472"] },
    "id": "1881331287010550119",
    "created_at": "2025-01-20T13:21:46.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881330757001502991" }
    ],
    "edit_history_tweet_ids": ["1881331142688989657"],
    "text": "my assumption always was that for distillation, sft reasoning traces would help with CoT formatting, and then get better results with RL on top, i didn't think it would help teach models which traces are correct and make it learn proper CoT reasoning",
    "author_id": "1499415401763115019",
    "in_reply_to_user_id": "1499415401763115019",
    "id": "1881331142688989657",
    "created_at": "2025-01-20T13:21:12.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881330794549182853"],
    "text": "This figure right here is the single biggest reason why we will never get o1/o3's reasoning traces.\n\nThe unreasonable effectiveness of distilling from a reasoner https://t.co/MwhBWQnInJ",
    "author_id": "1718879852827484160",
    "attachments": { "media_keys": ["3_1881330681336209408"] },
    "id": "1881330794549182853",
    "created_at": "2025-01-20T13:19:49.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881330757001502991"],
    "text": "this is the most surprising thing from the r1 paper to me:\n&gt;reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models.\n\ntotal sft victory https://t.co/xPwOAqnFTB https://t.co/rWSzHoLlZI",
    "author_id": "1499415401763115019",
    "note_tweet": {
      "text": "this is the most surprising thing from the r1 paper to me:\n>reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models.\n\ntotal sft victory"
    },
    "attachments": { "media_keys": ["3_1881330548229988352"] },
    "id": "1881330757001502991",
    "created_at": "2025-01-20T13:19:40.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881313255555305595" }
    ],
    "edit_history_tweet_ids": ["1881330229119246843"],
    "text": "‚ÄúDo something yourselves, we've told you everything there is to know‚Äù https://t.co/hfUuPggYS1",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "attachments": { "media_keys": ["3_1881330105005301760"] },
    "id": "1881330229119246843",
    "created_at": "2025-01-20T13:17:34.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881288088481132855" }],
    "edit_history_tweet_ids": ["1881330124857200998"],
    "text": "RT @uphillconf: üéâ Excited to announce our first talk for #UphillConf2025:\n\n\"The Rise of Small Models: On-Device Language Models and SmolLM\"‚Ä¶",
    "author_id": "1188812448767336449",
    "id": "1881330124857200998",
    "created_at": "2025-01-20T13:17:09.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881329993206374443"],
    "text": "Good morning. The biggest release of the past few months has arrived. \n\nThe first true o1 replication https://t.co/o9jqcyf5Qx",
    "author_id": "1718879852827484160",
    "attachments": { "media_keys": ["3_1881329316094521345"] },
    "id": "1881329993206374443",
    "created_at": "2025-01-20T13:16:38.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318686189137929" }
    ],
    "edit_history_tweet_ids": ["1881329351125549144"],
    "text": "And another unexpected win for @doomslide and @_xjdr  \nthe initial expectations for OpenAI hidden CoT were that it's‚Ä¶ not very human. that seems overblown but this is the first confirmation that naturally evolved CoTs can be weird. https://t.co/7IvaPjvuGm",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "attachments": { "media_keys": ["3_1881329003618836480"] },
    "id": "1881329351125549144",
    "created_at": "2025-01-20T13:14:05.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1880728370440548798" }],
    "edit_history_tweet_ids": ["1881328851898544583"],
    "text": "RT @kimmonismus: Nvidia's Jim Fan: We're training robots in a simulation that accelerates physics by 10,000x. The robots undergo 1 year of‚Ä¶",
    "author_id": "1007413134",
    "id": "1881328851898544583",
    "created_at": "2025-01-20T13:12:06.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881328112220418218"],
    "text": "i know some companies that have had months of work ruined by the fact r1 is open, mit licensed, with distillations at every size and with a paper hahaha",
    "author_id": "1499415401763115019",
    "id": "1881328112220418218",
    "created_at": "2025-01-20T13:09:09.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881327865851175071"],
    "text": "both \"aldorman\" and \"earl\" come from \"ealdorman\" lit. \"elder man\"",
    "author_id": "1195529113169039360",
    "id": "1881327865851175071",
    "created_at": "2025-01-20T13:08:11.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881327825078419772"],
    "text": "This is the paradigm. https://t.co/nSDnELiXWv",
    "author_id": "1825243643529027584",
    "attachments": { "media_keys": ["3_1881327487604400128"] },
    "id": "1881327825078419772",
    "created_at": "2025-01-20T13:08:01.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881326878772072818" }
    ],
    "edit_history_tweet_ids": ["1881327040529567745"],
    "text": "I NEED MORE GPUS",
    "author_id": "1499415401763115019",
    "in_reply_to_user_id": "1499415401763115019",
    "id": "1881327040529567745",
    "created_at": "2025-01-20T13:04:54.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881325197976064311" }],
    "edit_history_tweet_ids": ["1881327034921857051"],
    "text": "not quite what I had in mind, but‚Ä¶ that's how prophecies work isn't it https://t.co/mNG6gY60ly",
    "author_id": "192201556",
    "id": "1881327034921857051",
    "created_at": "2025-01-20T13:04:53.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881326878772072818"],
    "text": "deepseek officially released a distillation of r1 trained on llama 8b, time to try it at home https://t.co/XBWMO7IKgf",
    "author_id": "1499415401763115019",
    "attachments": { "media_keys": ["3_1881326762631512064"] },
    "id": "1881326878772072818",
    "created_at": "2025-01-20T13:04:15.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881321664702771482" }
    ],
    "edit_history_tweet_ids": ["1881326623439695889"],
    "text": "(and if the agent is training a model for you, you can always watch that loss curve go down)",
    "author_id": "185910194",
    "in_reply_to_user_id": "185910194",
    "id": "1881326623439695889",
    "created_at": "2025-01-20T13:03:15.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881326137848320076" }],
    "edit_history_tweet_ids": ["1881326352055537760"],
    "text": "RT @kalomaze: A BUFFET OF REWARD SEEKERS https://t.co/auzR8rxXgw",
    "author_id": "1499415401763115019",
    "attachments": { "media_keys": ["3_1881326133704069120"] },
    "id": "1881326352055537760",
    "created_at": "2025-01-20T13:02:10.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881290084378648839" }],
    "edit_history_tweet_ids": ["1881326097884946741"],
    "text": "RT @DataChaz: 35K ppl have already registered, and there's still time to sign up for the FREE @huggingface AI Agents Course! ü§ó\n\nIn this cou‚Ä¶",
    "author_id": "186420551",
    "id": "1881326097884946741",
    "created_at": "2025-01-20T13:01:09.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881315202978951528" }],
    "edit_history_tweet_ids": ["1881326015894753339"],
    "text": "RT @tokenbender: yo, deepseek dropping r1 distilled smaller models for the community to play with.\n\ncould they be any more awesome? https:/‚Ä¶",
    "author_id": "186420551",
    "id": "1881326015894753339",
    "created_at": "2025-01-20T13:00:50.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881248289053372727" }],
    "edit_history_tweet_ids": ["1881325814463303783"],
    "text": "ü§° https://t.co/M1f5P1Sycu",
    "author_id": "1583730714",
    "id": "1881325814463303783",
    "created_at": "2025-01-20T13:00:02.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881318138937233664" }],
    "edit_history_tweet_ids": ["1881324080147922982"],
    "text": "MIT licensed now.\n@DKokotajlo67142 here you go.I don't think we could ask for any better model organisms. Product of pure RL for reasoning, to wit ‚Äì goal achievement. Sizes from 1.5B to 685B, three model families. RL vs RL + cold start init vs SFT. Knock yourself out. https://t.co/viQrQ6sxIy https://t.co/aD3ftnIy6l",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881323299608608769"] },
    "id": "1881324080147922982",
    "created_at": "2025-01-20T12:53:08.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881322161228693549" }],
    "edit_history_tweet_ids": ["1881322775413141744"],
    "text": "RT @airkatakana: with deepseek now open sourcing a model that is strictly better than 3.6 sonnet (if you believe the benchmarks) it‚Äôs reall‚Ä¶",
    "author_id": "1513853205125681162",
    "id": "1881322775413141744",
    "created_at": "2025-01-20T12:47:57.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "edit_history_tweet_ids": ["1881322593065869582"],
    "text": "DeepSeek-R1:\n\n- Open weights\n- MIT license\n- API outputs can be used for finetuning.\n- Free to use on webpage and app.\n\nSalute to our R1 team for this amazing CNY delivery üéÅü´°üéâ! https://t.co/74jYwKVHv8",
    "author_id": "1496348031494819842",
    "id": "1881322593065869582",
    "created_at": "2025-01-20T12:47:14.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881319500089634954" }
    ],
    "edit_history_tweet_ids": ["1881322456587333980"],
    "text": "repo:\n\nhttps://t.co/CNUGDaxfkc",
    "author_id": "874987512850128897",
    "in_reply_to_user_id": "874987512850128897",
    "id": "1881322456587333980",
    "created_at": "2025-01-20T12:46:41.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881322418855432337" }
    ],
    "edit_history_tweet_ids": ["1881322422705750513"],
    "text": "made with the Glif Browser Extension using the \"Any Image Anywhere\" workflow\n\nget it here: https://t.co/blmaS8lE4K https://t.co/PZNfa0KpHn",
    "author_id": "5483052",
    "in_reply_to_user_id": "5483052",
    "attachments": { "media_keys": ["3_1881321242591899648"] },
    "id": "1881322422705750513",
    "created_at": "2025-01-20T12:46:33.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881208582324322341" }],
    "edit_history_tweet_ids": ["1881322418855432337"],
    "text": "hey, i have one of these! https://t.co/4iIafQxncX https://t.co/ea62ZzdIIq",
    "author_id": "5483052",
    "attachments": { "media_keys": ["3_1881320640990359552"] },
    "id": "1881322418855432337",
    "created_at": "2025-01-20T12:46:32.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881318686189137929" }],
    "edit_history_tweet_ids": ["1881322387091882491"],
    "text": "I have always argued that RL has to be worth it and that most RL people whined at me to do has **not been worth it** - and I don't apologize for it.\n\nThis RL, however, does seem worth it though, and we've been working on a system for reasoning RL that is pretty much exactly what‚Ä¶ https://t.co/VCMCHs4kfF https://t.co/Q1mLpiTAyx",
    "author_id": "1365020011123773442",
    "note_tweet": {
      "text": "I have always argued that RL has to be worth it and that most RL people whined at me to do has **not been worth it** - and I don't apologize for it.\n\nThis RL, however, does seem worth it though, and we've been working on a system for reasoning RL that is pretty much exactly what they did in deepseek. I dont know how they move so fast but its a blessing, and so is their paper release. \n\nI believe this RL does have the potential to create self improving models. Or at least, self improve to some higher point then the first round does. I also believe this kind of RL has the potential to be the most interesting way to train a model, because it learns to think **on its own** by exploring which thoughts lead to the correct outcome. Seeing the CoT is as much fun and is as intriguing to me as getting the right answer\n\nSFT from distillation simply offers more bang for your buck. In our experience has been between 2 and 14x less costly than RL, and the existing RLHF work, whether RM's, DPO datasets, etc out there have not improved the models much - surprisingly, much less at large scales (because the existing datasets likely reach a basin around 20-30B param model average nuanced preferences or something). Look at our Hermes 3 technical report, where 8B did benefit from RLHF, but 70B and 405B did not.\n\nThe challenges of working across multiple base models and sizes also makes it difficult to maintain what some people like Roon claim is basically a golden rule of RL, on policy data. Requiring new RM or DPO datasets for every damn model we want to improve. The overhead is large, so the benefit must be proportionally large!\n\nAnyone who is worried we aren't taking what actually effectively improves the model in an efficient way seriously does not need to worry.\n\nThe post training work continues!"
    },
    "id": "1881322387091882491",
    "created_at": "2025-01-20T12:46:25.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881304392072405483" }],
    "edit_history_tweet_ids": ["1881322149283283276"],
    "text": "RT @dennisknodt: Read something by @scottastevenson on how to get rid (reduce) the anxiety of foundership. \n\nWhen I read this - I felt seen‚Ä¶",
    "author_id": "89538466",
    "id": "1881322149283283276",
    "created_at": "2025-01-20T12:45:28.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318130334814301" }
    ],
    "edit_history_tweet_ids": ["1881322139099476382"],
    "text": "@deepseek_ai üî•üî•üî•",
    "author_id": "2895499182",
    "in_reply_to_user_id": "1714580962569588736",
    "id": "1881322139099476382",
    "created_at": "2025-01-20T12:45:25.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881320996298539123" }
    ],
    "edit_history_tweet_ids": ["1881321848744644732"],
    "text": "their concluding remarks point to a fair bit of engineering left. But it's not very important. They don't really have much to say. There is no ceiling to basic good-enough GRPO and a strong base model. This is it, the whole recipe. Enjoy. https://t.co/Yy5GZPmejh",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "attachments": {
      "media_keys": ["3_1881321365480882176", "3_1881321754594824192"]
    },
    "id": "1881321848744644732",
    "created_at": "2025-01-20T12:44:16.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881321664702771482"],
    "text": "\"Watching the agent do its work\" may be the new \"watching the loss curve go down\"",
    "author_id": "185910194",
    "id": "1881321664702771482",
    "created_at": "2025-01-20T12:43:32.000Z"
  },
  {
    "referenced_tweets": [{ "type": "retweeted", "id": "1881316755651576183" }],
    "edit_history_tweet_ids": ["1881321165425434857"],
    "text": "RT @ecommerceshares: Satya announcing YET ANOTHER VERSION of Copilot is almost a joke at this point. Constantly re-branded, re-designed, re‚Ä¶",
    "author_id": "1513853205125681162",
    "id": "1881321165425434857",
    "created_at": "2025-01-20T12:41:33.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881320996298539123"],
    "text": "Tick. Tock. We'll see a very smart V3.5 soon. Then a very polished R2.\nBut the next step is not picking up the shards of a wall their RL machine busted and fixing these petty regressions. It's putting together that 32K cluster and going BRRRR.\nDeepSeek has cracked the code. https://t.co/tNylLZIFP5",
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["3_1881320773832294400", "3_1881320950156693504"]
    },
    "id": "1881320996298539123",
    "created_at": "2025-01-20T12:40:53.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881319117480939630" }],
    "edit_history_tweet_ids": ["1881320664709353647"],
    "text": "R1 while training, perfecting the flaws inside itself https://t.co/I8G9UFlYj6 https://t.co/9jcvuzCTVG",
    "author_id": "1513853205125681162",
    "attachments": { "media_keys": ["3_1881320473247801344"] },
    "id": "1881320664709353647",
    "created_at": "2025-01-20T12:39:34.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881320402640928837"],
    "text": "A 1.5B model achieving 28% on AIME, 33.8% on GPQAm 16.9% on LiveCodeBench and 954 on CodeForces.ü§Ø\n\nhttps://t.co/PlwIxHM5bb",
    "author_id": "1141052916570214400",
    "id": "1881320402640928837",
    "created_at": "2025-01-20T12:38:31.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1880592755585700045" }],
    "edit_history_tweet_ids": ["1881320134725505035"],
    "text": "Another issue with this strat is you won't be able to compete on costs as well since the underlying infra is same and probably costs more here due to tariffs\n\nOnly move is better multi-lingual support or licensing for on-device usage to big companies https://t.co/kuaG1ej6Bx",
    "author_id": "1513853205125681162",
    "id": "1881320134725505035",
    "created_at": "2025-01-20T12:37:28.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881319516136972405" }
    ],
    "edit_history_tweet_ids": ["1881319947500126319"],
    "text": "See for example this Japanese sword master who, according to the comments, immediately reinvents something similar to the proper form for these Western weapons he's never used before based on his understanding of martial combat with swords.\nhttps://t.co/FRxWGvvbfM",
    "author_id": "829108178059096064",
    "in_reply_to_user_id": "829108178059096064",
    "id": "1881319947500126319",
    "created_at": "2025-01-20T12:36:43.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881319751680733238"],
    "text": "The new distilled @deepseek_ai models are fine-tuned versions of @Alibaba_Qwen or @AIatMeta Llama 3 using  800k samples curated with DeepSeek-R1. (no RL stage) https://t.co/2ytEgzZIvv",
    "author_id": "1141052916570214400",
    "attachments": { "media_keys": ["3_1881319663168077824"] },
    "id": "1881319751680733238",
    "created_at": "2025-01-20T12:35:56.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881319249828073676" }
    ],
    "edit_history_tweet_ids": ["1881319516136972405"],
    "text": "I don't just mean for machine learning either, that's what's important for humans too. Techniques are mostly useful to give you some ideas, they're cached computation but following a similar generative process or even deriving a process from the same goal should yield similar.",
    "author_id": "829108178059096064",
    "in_reply_to_user_id": "829108178059096064",
    "id": "1881319516136972405",
    "created_at": "2025-01-20T12:35:00.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881316215706313094" }],
    "edit_history_tweet_ids": ["1881319502861967635"],
    "text": "One question tho\n\nWith this approach, how can you force it to think longer other than the prompt\n\nI feel OpenAI's RL training is still different from the recipe they used here\n\nThat being said, this model is cooked to perfection and tastes good https://t.co/Ys1zLIzACO",
    "author_id": "1513853205125681162",
    "id": "1881319502861967635",
    "created_at": "2025-01-20T12:34:57.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881319500089634954"],
    "text": "\"DeepSeek-R1-Distill-Qwen-1.5B outperforms GPT-4o and Claude-3.5-Sonnet on math benchmarks with 28.9% on AIME and 83.9% on MATH.\"\n\n1.5B did WHAT? https://t.co/Pk6fOJNma2",
    "author_id": "874987512850128897",
    "attachments": { "media_keys": ["3_1881319353355755520"] },
    "id": "1881319500089634954",
    "created_at": "2025-01-20T12:34:56.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318130334814301" }
    ],
    "edit_history_tweet_ids": ["1881319414781628438"],
    "text": "@deepseek_ai Thanks whale, we will host them on Hyperbolic! https://t.co/j2GsXqQ448",
    "author_id": "800854096219471872",
    "in_reply_to_user_id": "1714580962569588736",
    "attachments": { "media_keys": ["16_1881319408431398913"] },
    "id": "1881319414781628438",
    "created_at": "2025-01-20T12:34:36.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318728564130208" }
    ],
    "edit_history_tweet_ids": ["1881319249828073676"],
    "text": "With the benefit of hindsight it's obvious that \"techniques\" don't matter very much. What's important is targets, heuristics, and corpuses of training data. LessWrong produced a handful of writers that poured themselves into an excellent corpus, which is more than most can say.",
    "author_id": "829108178059096064",
    "in_reply_to_user_id": "829108178059096064",
    "id": "1881319249828073676",
    "created_at": "2025-01-20T12:33:57.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881318966884454887"],
    "text": "Is it Christmas already? üéÑ Deepseek not only released the weights for their reasoning model! They only released distilled smaller version for,e.g. Llama or Qwen. https://t.co/QlPMZIA4Mz",
    "author_id": "1141052916570214400",
    "attachments": { "media_keys": ["3_1881318958118133760"] },
    "id": "1881318966884454887",
    "created_at": "2025-01-20T12:32:49.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1843845401688048112" }],
    "edit_history_tweet_ids": ["1881318728564130208"],
    "text": "One of the reasons I haven't written more LessWrong retrospectives is that I honestly don't think anything like it will be attempted again. LessWrong was the final gasp of the Californian human potential movement trying to force the square peg into the round hole. https://t.co/6EAqdskD6s https://t.co/Lq0GZrpJno",
    "author_id": "829108178059096064",
    "attachments": { "media_keys": ["3_1881318342470029312"] },
    "id": "1881318728564130208",
    "created_at": "2025-01-20T12:31:52.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881317131561922640" }
    ],
    "edit_history_tweet_ids": ["1881318686189137929"],
    "text": "btw this is an unexpected win for @Teknium1 \nSFT is SoTA in some very relevant scenarios https://t.co/Zt3xv5lPEJ",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "attachments": { "media_keys": ["3_1881318548867321857"] },
    "id": "1881318686189137929",
    "created_at": "2025-01-20T12:31:42.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881318570132664359"],
    "text": "OpenAI seething so hard I cant even paste r1's paper into o1 without a content violation what losers https://t.co/CmNkEJrby4",
    "author_id": "1365020011123773442",
    "attachments": { "media_keys": ["3_1881318563514126337"] },
    "id": "1881318570132664359",
    "created_at": "2025-01-20T12:31:14.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "edit_history_tweet_ids": ["1881318555960156287"],
    "text": "Whalebros delivered https://t.co/XwAO1hHnow",
    "author_id": "1825243643529027584",
    "id": "1881318555960156287",
    "created_at": "2025-01-20T12:31:11.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318453048676383" }
    ],
    "edit_history_tweet_ids": ["1881318540688666834"],
    "text": "read the report here:\n\nhttps://t.co/cJ2qu3sX6r",
    "author_id": "874987512850128897",
    "in_reply_to_user_id": "874987512850128897",
    "id": "1881318540688666834",
    "created_at": "2025-01-20T12:31:07.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881318453048676383"],
    "text": "based af, literally have an open source frontier LLM beating the shit out of sonnet, o1! üí• https://t.co/QcvfJ04Q6f",
    "author_id": "874987512850128897",
    "attachments": { "media_keys": ["3_1881318191835594752"] },
    "id": "1881318453048676383",
    "created_at": "2025-01-20T12:30:47.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881318130334814301" }],
    "edit_history_tweet_ids": ["1881318293384102130"],
    "text": "Here comes DeepSeek-R1, our latest reasoning model with significantly enhanced reasoning abilities. We also share a technical report on how we train the reasoning model with large-scale RL. Have fun! https://t.co/BVFNwMZTUc",
    "author_id": "1187046037099147265",
    "id": "1881318293384102130",
    "created_at": "2025-01-20T12:30:09.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318142083018951" }
    ],
    "edit_history_tweet_ids": ["1881318145761439995"],
    "text": "üåê API Access &amp; Pricing\n\n‚öôÔ∏è Use DeepSeek-R1 by setting model=deepseek-reasoner\nüí∞ $0.14 / million input tokens (cache hit)\nüí∞ $0.55 / million input tokens (cache miss)\nüí∞ $2.19 / million output tokens\n\nüìñ API guide: https://t.co/Qf97ASptDD\n\nüêã 5/n https://t.co/v5ho1VOex5",
    "author_id": "1714580962569588736",
    "in_reply_to_user_id": "1714580962569588736",
    "attachments": {
      "media_keys": ["3_1881317215393468416", "3_1881317224910299137"]
    },
    "id": "1881318145761439995",
    "created_at": "2025-01-20T12:29:33.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318138937233664" }
    ],
    "edit_history_tweet_ids": ["1881318142083018951"],
    "text": "üõ†Ô∏è DeepSeek-R1: Technical Highlights\n\nüìà Large-scale RL in post-training\nüèÜ Significant performance boost with minimal labeled data\nüî¢ Math, code, and reasoning tasks on par with OpenAI-o1\nüìÑ More details: https://t.co/jWMxMVhGAQ\n\nüêã 4/n https://t.co/mIUBn3qJhQ",
    "author_id": "1714580962569588736",
    "in_reply_to_user_id": "1714580962569588736",
    "attachments": { "media_keys": ["3_1881317132170059776"] },
    "id": "1881318142083018951",
    "created_at": "2025-01-20T12:29:32.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318135850213834" }
    ],
    "edit_history_tweet_ids": ["1881318138937233664"],
    "text": "üìú License Update!\n\nüîÑ DeepSeek-R1 is now MIT licensed for clear open access\nüîì Open for the community to leverage model weights &amp; outputs\nüõ†Ô∏è API outputs can now be used for fine-tuning &amp; distillation\n\nüêã 3/n",
    "author_id": "1714580962569588736",
    "in_reply_to_user_id": "1714580962569588736",
    "id": "1881318138937233664",
    "created_at": "2025-01-20T12:29:32.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881318130334814301" }
    ],
    "edit_history_tweet_ids": ["1881318135850213834"],
    "text": "üî• Bonus: Open-Source Distilled Models!\n\nüî¨ Distilled from DeepSeek-R1, 6 small models fully open-sourced\nüìè 32B &amp; 70B models on par with OpenAI-o1-mini\nü§ù Empowering the open-source community\n\nüåç Pushing the boundaries of **open AI**!\n\nüêã 2/n https://t.co/tfXLM2xtZZ",
    "author_id": "1714580962569588736",
    "in_reply_to_user_id": "1714580962569588736",
    "attachments": { "media_keys": ["3_1881316978297851904"] },
    "id": "1881318135850213834",
    "created_at": "2025-01-20T12:29:31.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881318130334814301"],
    "text": "üöÄ DeepSeek-R1 is here!\n\n‚ö° Performance on par with OpenAI-o1\nüìñ Fully open-source model &amp; technical report\nüèÜ MIT licensed: Distill &amp; commercialize freely!\n\nüåê Website &amp; API are live now! Try DeepThink at https://t.co/v1TFy7LHNy today!\n\nüêã 1/n https://t.co/7BlpWAPu6y",
    "author_id": "1714580962569588736",
    "attachments": { "media_keys": ["3_1881318116745150464"] },
    "id": "1881318130334814301",
    "created_at": "2025-01-20T12:29:30.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881317144862113807" }
    ],
    "edit_history_tweet_ids": ["1881317700678668509"],
    "text": "@Teknium1 no MCTS as well",
    "author_id": "1513853205125681162",
    "in_reply_to_user_id": "1365020011123773442",
    "id": "1881317700678668509",
    "created_at": "2025-01-20T12:27:47.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881317144862113807" }
    ],
    "edit_history_tweet_ids": ["1881317569967378641"],
    "text": "cc @Grad62304977",
    "author_id": "1365020011123773442",
    "in_reply_to_user_id": "1365020011123773442",
    "id": "1881317569967378641",
    "created_at": "2025-01-20T12:27:16.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881315419086291213" }
    ],
    "edit_history_tweet_ids": ["1881317527030305145"],
    "text": "check all of them out here:\n\nhttps://t.co/YV6AsCxHOl",
    "author_id": "874987512850128897",
    "in_reply_to_user_id": "874987512850128897",
    "id": "1881317527030305145",
    "created_at": "2025-01-20T12:27:06.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881315318771154991" }],
    "edit_history_tweet_ids": ["1881317199148937666"],
    "text": "We can give up on MCTS now fellas\ntime to stick to RL https://t.co/UI6t06W5Fy https://t.co/zdxc9CNftR",
    "author_id": "1513853205125681162",
    "attachments": { "media_keys": ["3_1881317131335376896"] },
    "id": "1881317199148937666",
    "created_at": "2025-01-20T12:25:48.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881317144862113807"],
    "text": "No PRM - as I hoped (and expected) based on what I was interpreting as o1's methods: https://t.co/ZvRDaa5B9a",
    "author_id": "1365020011123773442",
    "attachments": { "media_keys": ["3_1881317130773393408"] },
    "id": "1881317144862113807",
    "created_at": "2025-01-20T12:25:35.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881317131561922640"],
    "text": "somebody wake up Yud https://t.co/6mTO50qz5I",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881317025873534976"] },
    "id": "1881317131561922640",
    "created_at": "2025-01-20T12:25:32.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881316758218535039"],
    "text": "Destroys 4o; we have frontier models @ home I guess now https://t.co/v80G0DVHky",
    "author_id": "1365020011123773442",
    "attachments": { "media_keys": ["3_1881316683375378432"] },
    "id": "1881316758218535039",
    "created_at": "2025-01-20T12:24:02.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1879878219639447776" }],
    "edit_history_tweet_ids": ["1881316590886793685"],
    "text": "they know ü•π https://t.co/hAc5YmebJy https://t.co/7cP0dnFXeX",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881316525765791744"] },
    "id": "1881316590886793685",
    "created_at": "2025-01-20T12:23:23.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881315318771154991" }],
    "edit_history_tweet_ids": ["1881316215706313094"],
    "text": "Woowwwwww https://t.co/h73jzdqqP5 https://t.co/zdxc9CNftR",
    "author_id": "1513853205125681162",
    "attachments": { "media_keys": ["3_1881316196823527426"] },
    "id": "1881316215706313094",
    "created_at": "2025-01-20T12:21:53.000Z"
  },
  {
    "referenced_tweets": [{ "type": "quoted", "id": "1881297954042249231" }],
    "edit_history_tweet_ids": ["1881315569796043052"],
    "text": "R1 is going to be so much fun holy shit. https://t.co/SUVlYRS5YW",
    "author_id": "829108178059096064",
    "id": "1881315569796043052",
    "created_at": "2025-01-20T12:19:19.000Z"
  },
  {
    "edit_history_tweet_ids": ["1881315419086291213"],
    "text": "holy fuck, these gigachads dropped 6 distilled models right from 1.5B to 70B üî• https://t.co/DYq0cobPiq",
    "author_id": "874987512850128897",
    "attachments": { "media_keys": ["3_1881315249187328001"] },
    "id": "1881315419086291213",
    "created_at": "2025-01-20T12:18:43.000Z"
  },
  {
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881315318771154991" }
    ],
    "edit_history_tweet_ids": ["1881315398865518877"],
    "text": "https://t.co/0EBRsVJqf6",
    "author_id": "1513853205125681162",
    "in_reply_to_user_id": "1513853205125681162",
    "id": "1881315398865518877",
    "created_at": "2025-01-20T12:18:38.000Z"
  },
  {
    "id": "1881315318771154991",
    "text": "LFGGGGGGGGGGGGGGd https://t.co/xbv8mBMmlM",
    "author_id": "1513853205125681162",
    "attachments": { "media_keys": ["3_1881315296960737280"] },
    "created_at": "2025-01-20T12:18:19.000Z",
    "edit_history_tweet_ids": ["1881315318771154991"]
  },
  {
    "id": "1881314749788393864",
    "text": "&gt; they mog QwQ-32B-preview with Qwen-14B https://t.co/Xb9LpjT21q",
    "author_id": "192201556",
    "created_at": "2025-01-20T12:16:04.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881314212578046060" }],
    "edit_history_tweet_ids": ["1881314749788393864"]
  },
  {
    "id": "1881313275285274936",
    "text": "RT @tracewoodgrains: hm. the online right has teeth, just like the online left at the height of its power\n\nand it's not afraid to flash the‚Ä¶",
    "author_id": "829108178059096064",
    "created_at": "2025-01-20T12:10:12.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881159991710884139" }],
    "edit_history_tweet_ids": ["1881313275285274936"]
  },
  {
    "id": "1881313255555305595",
    "text": "holy crap they actually got tired of people complaining that their models are impossible to run locally, and just did the whole lineup\n\nIt will be really funny if this Qwen distill outperforms QwQ-preview https://t.co/gxVzMcbeUu https://t.co/CIhtLJaTBU",
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["3_1881312848384593920", "3_1881313021181448192"]
    },
    "created_at": "2025-01-20T12:10:07.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881311174610051491" }],
    "edit_history_tweet_ids": ["1881313255555305595"]
  },
  {
    "id": "1881312367667191933",
    "text": "i‚Äôm going through map-looking withdrawal, should i go back to crusader kings 2 or finally pull the trigger on 3?",
    "author_id": "1499415401763115019",
    "created_at": "2025-01-20T12:06:36.000Z",
    "edit_history_tweet_ids": ["1881312367667191933"]
  },
  {
    "id": "1881307948707942573",
    "text": "also it's regressed on the Atreus trial despite now knowing the game lore. It's over. AGI canceled\n\n(jk, I love this model already) https://t.co/ClZVTUozG3",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881307806797537280"] },
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T11:49:02.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881307787017457917" }
    ],
    "edit_history_tweet_ids": ["1881307948707942573"]
  },
  {
    "id": "1881307787017457917",
    "text": "They really should figure out self-esteem issues of R1 https://t.co/Rsc4qkJBYd https://t.co/XXhCH5TgxQ",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881304732318224384"] },
    "created_at": "2025-01-20T11:48:24.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881302156860621119" }],
    "edit_history_tweet_ids": ["1881307787017457917"]
  },
  {
    "id": "1881304470086447210",
    "text": "Thanks to „Ç®„Éå„É¶„É´ for bringing stan up-to-date with GHC 9.12. There weren't any breaking changes to deal with this time. Thanks GHC HQ for that!\n\nhttps://t.co/3qSOVlRMYZ",
    "author_id": "1344972712402366471",
    "created_at": "2025-01-20T11:35:13.000Z",
    "edit_history_tweet_ids": ["1881304470086447210"]
  },
  {
    "id": "1881303164336406582",
    "text": "Top stories in AI today:\n\n-OpenAI readies ‚Äòo3-mini‚Äô model launch\n-Altman to brief Washington on ‚ÄòPhD level SuperAgents‚Äô\n-Get automatic global news briefings with ChatGPT\n-Runway releases ‚ÄòFrames‚Äô image generation model\n-4 new AI tools &amp; 4 job opportunities \n\nRead more:‚Ä¶ https://t.co/nqfyjaE0pH https://t.co/PaXuZKTgkl",
    "note_tweet": {
      "text": "Top stories in AI today:\n\n-OpenAI readies ‚Äòo3-mini‚Äô model launch\n-Altman to brief Washington on ‚ÄòPhD level SuperAgents‚Äô\n-Get automatic global news briefings with ChatGPT\n-Runway releases ‚ÄòFrames‚Äô image generation model\n-4 new AI tools & 4 job opportunities \n\nRead more: https://t.co/yMkAMCRwFQ",
      "entities": {
        "urls": [
          {
            "start": 270,
            "end": 293,
            "url": "https://t.co/yMkAMCRwFQ",
            "expanded_url": "http://therundown.ai/p/openais-o3-mini-is-coming",
            "display_url": "therundown.ai/p/openais-o3-m‚Ä¶"
          }
        ]
      }
    },
    "author_id": "731917653506318336",
    "attachments": { "media_keys": ["3_1881303161614237696"] },
    "created_at": "2025-01-20T11:30:01.000Z",
    "edit_history_tweet_ids": ["1881303164336406582"]
  },
  {
    "id": "1881301637811384342",
    "text": "Promotion season is here\ntime to choose your next step carefully anon https://t.co/C8dkhKG7SK",
    "author_id": "1513853205125681162",
    "created_at": "2025-01-20T11:23:58.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1630284194311180288" }],
    "edit_history_tweet_ids": ["1881301637811384342"]
  },
  {
    "id": "1881301606727356474",
    "text": "come on @balajis just follow already I know you read me",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T11:23:50.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881153658978705635" }
    ],
    "edit_history_tweet_ids": ["1881301606727356474"]
  },
  {
    "id": "1881300868047495219",
    "text": "weights first\nAPI second\nrecipe third\nsocial media announcement‚Ä¶ if they don't forget\nhow can you not love this company?! https://t.co/JOoeS9s1Wm",
    "author_id": "192201556",
    "created_at": "2025-01-20T11:20:54.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881291833143439541" }],
    "edit_history_tweet_ids": ["1881300868047495219"]
  },
  {
    "id": "1881298065967239183",
    "text": "As VL2-27B LLM part is similar to V3, I guess that's the only \"lite\" they used to prep for R1.\nThere's never been a V2-based R1. I've been underestimating the Whale. They don't have compute to waste on half-measures.\nV3-R1 began training less than 1 month after o1 announcement. https://t.co/LTukt2AYby",
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["3_1881297822076563456", "3_1881297929740115968"]
    },
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T11:09:46.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881295618192077099" }
    ],
    "edit_history_tweet_ids": ["1881298065967239183"]
  },
  {
    "id": "1881297699171180943",
    "text": "RT @levie: The impact of giving everyone in the world instant expertise on every topic is incredible. This is why you don‚Äôt want to slow do‚Ä¶",
    "author_id": "3452911",
    "created_at": "2025-01-20T11:08:18.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881199738529411369" }],
    "edit_history_tweet_ids": ["1881297699171180943"]
  },
  {
    "id": "1881295618192077099",
    "text": "I conclude that R1, and by implication V3-base, were completed before December 10. It seems that V2.5-1210 is this ablation experiment in V3 paper (check LCB and MATH).\nWhale never trains models as mere products. Every single training run is a step in research towards AGI. https://t.co/o7VKGkQwap https://t.co/dDGrHyZZfi https://t.co/S9fZGZylCZ",
    "note_tweet": {
      "text": "I conclude that R1, and by implication V3-base, were completed before December 10. It seems that V2.5-1210 is this ablation experiment in V3 paper (check LCB and MATH).\nWhale never trains models as mere products. Every single training run is a step in research towards AGI."
    },
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["3_1881294158226235393", "3_1881294750055084032"]
    },
    "created_at": "2025-01-20T11:00:02.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1866426008108200244" }],
    "edit_history_tweet_ids": ["1881295618192077099"]
  },
  {
    "id": "1881293981700829415",
    "text": "deepseek is just so based, casually stealth drops the most powerful oss model ever,",
    "author_id": "1499415401763115019",
    "created_at": "2025-01-20T10:53:32.000Z",
    "edit_history_tweet_ids": ["1881293981700829415"]
  },
  {
    "id": "1881292115088671194",
    "text": "‚Äúdischarge plasma extreme ultraviolet lithography light source‚Äù, whatever that is https://t.co/zKUVI3wbC8",
    "author_id": "192201556",
    "created_at": "2025-01-20T10:46:07.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881289789292576830" }],
    "edit_history_tweet_ids": ["1881292115088671194"]
  },
  {
    "id": "1881290771229479237",
    "text": "this brings Q joy https://t.co/myG3WZLg6y",
    "author_id": "1499415401763115019",
    "attachments": { "media_keys": ["3_1881290704028119040"] },
    "in_reply_to_user_id": "1499415401763115019",
    "created_at": "2025-01-20T10:40:47.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881290558502732226" }
    ],
    "edit_history_tweet_ids": ["1881290771229479237"]
  },
  {
    "id": "1881290587900424401",
    "text": "@RichardMCNgo I find it comforting. I think there‚Äôs a chance that we are part of a multiversal slime mold which is exploring the branches of reality and finding the paths which best propagate life.\n\nI think most people are too intuitively tied to the physicalist/materialst religion they were‚Ä¶ https://t.co/5EQoBjj62e",
    "note_tweet": {
      "text": "I find it comforting. I think there‚Äôs a chance that we are part of a multiversal slime mold which is exploring the branches of reality and finding the paths which best propagate life.\n\nI think most people are too intuitively tied to the physicalist/materialst religion they were taught in grade school to be able to really ‚Äúfeel‚Äù these kinds of possibilities, even if they intellectually find them compelling. Bernardo Kastrup‚Äôs books changed this for me."
    },
    "author_id": "89538466",
    "in_reply_to_user_id": "85225861",
    "created_at": "2025-01-20T10:40:03.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881208833168838932" }
    ],
    "edit_history_tweet_ids": ["1881290587900424401"]
  },
  {
    "id": "1881290558502732226",
    "text": "so it finished and was indeed not as good as my expectations, started a new run this morning with improved hyperparameters, it's looking better already https://t.co/VsSiYaIknx",
    "author_id": "1499415401763115019",
    "created_at": "2025-01-20T10:39:56.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1880719503413428690" }],
    "edit_history_tweet_ids": ["1881290558502732226"]
  },
  {
    "id": "1881288056973713642",
    "text": "@fchollet from what evidence do you draw this? would love any public sources!",
    "author_id": "33521530",
    "in_reply_to_user_id": "68746721",
    "created_at": "2025-01-20T10:30:00.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880378880894333094" }
    ],
    "edit_history_tweet_ids": ["1881288056973713642"]
  },
  {
    "id": "1881287170499240371",
    "text": "@StringChaos @wireless_anon @synthwavedd ah this is interesting\nhttps://t.co/vHvjaXs0E1",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T10:26:28.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881064602546692534" },
      { "type": "replied_to", "id": "1881287070616023060" }
    ],
    "edit_history_tweet_ids": ["1881287170499240371"]
  },
  {
    "id": "1881287070616023060",
    "text": "@StringChaos @wireless_anon &gt; usually (but not always) defaulting to r1-lite-preview\n\nwhat's the evidence for (not always)? @synthwavedd shows that it calls the model r1-preview but I don't see any other option, and anyway DeepThink seems to me to work the same as always",
    "author_id": "192201556",
    "in_reply_to_user_id": "972435243876544512",
    "created_at": "2025-01-20T10:26:04.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881286479974142031" }
    ],
    "edit_history_tweet_ids": ["1881287070616023060"]
  },
  {
    "id": "1881286479974142031",
    "text": "@teortaxesTex @wireless_anon Note that the preview models are being served in DeepThink mode, usually (but not always) defaulting to r1-lite-preview. \n\nCredit:\n\nhttps://t.co/haqlKllPxA",
    "author_id": "972435243876544512",
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T10:23:44.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880616182363165057" },
      { "type": "replied_to", "id": "1881251064546291992" }
    ],
    "edit_history_tweet_ids": ["1881286479974142031"]
  },
  {
    "id": "1881286051295301766",
    "text": "@Teknium1 haha, this is so cute",
    "author_id": "874987512850128897",
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T10:22:01.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881267038091682191" }
    ],
    "edit_history_tweet_ids": ["1881286051295301766"]
  },
  {
    "id": "1881285946647478393",
    "text": "RT @dejavucoder: anjin: twitter hype is out of control again. we are not gonna deploy AGI next month, nor have we built it. we have some ve‚Ä¶",
    "author_id": "1513853205125681162",
    "created_at": "2025-01-20T10:21:36.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881280254607839471" }],
    "edit_history_tweet_ids": ["1881285946647478393"]
  },
  {
    "id": "1881277875502157873",
    "text": "RT @LiquidAI_: Introducing LFM-7B, our new best-in-class language model in English, Arabic, and Japanese optimized to be the substrate for‚Ä¶",
    "author_id": "923114064460558336",
    "created_at": "2025-01-20T09:49:32.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881236162893000944" }],
    "edit_history_tweet_ids": ["1881277875502157873"]
  },
  {
    "id": "1881277389415850159",
    "text": "There's this dude in eleuther discord (I lurk sometimes) who's like my antipode, his whole gimmick seems to be \"deepseek sucks and steals\" even in contexts when it's literally impossible. pretty hilarious stuff https://t.co/hH1vSLpSBx",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881276387190824960"] },
    "created_at": "2025-01-20T09:47:36.000Z",
    "edit_history_tweet_ids": ["1881277389415850159"]
  },
  {
    "id": "1881275162160746935",
    "text": "RT @Teknium1: @OfirPress Having access to most of the problems allows you to construct more of the exact types of problems to train around‚Ä¶",
    "author_id": "1188812448767336449",
    "created_at": "2025-01-20T09:38:45.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881022197906682261" }],
    "edit_history_tweet_ids": ["1881275162160746935"]
  },
  {
    "id": "1881275086394843449",
    "text": "@LiquidAI_ You can play with it on Liquid's Playground: https://t.co/890Zhdr5h6\n\nHere's the full blog post: https://t.co/ZNWTwS9YDF https://t.co/wEmgNO5kgW",
    "author_id": "923114064460558336",
    "attachments": { "media_keys": ["3_1881275077372596224"] },
    "in_reply_to_user_id": "923114064460558336",
    "created_at": "2025-01-20T09:38:27.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881274480821215246" }
    ],
    "edit_history_tweet_ids": ["1881275086394843449"]
  },
  {
    "id": "1881274480821215246",
    "text": "@LiquidAI_ Thanks to the LFM architecture, it also benefits from fast inference and much lower memory usage compared to other 7-8B models.\n\nIt delivers an effective 32k context window with top scores on LongBench v2 (32k without CoT). https://t.co/zy2BB4XP2h",
    "author_id": "923114064460558336",
    "attachments": { "media_keys": ["3_1881274461246107648"] },
    "in_reply_to_user_id": "923114064460558336",
    "created_at": "2025-01-20T09:36:03.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881274341385789830" }
    ],
    "edit_history_tweet_ids": ["1881274480821215246"]
  },
  {
    "id": "1881274341385789830",
    "text": "@LiquidAI_ This was made possible by combining supervised fine-tuning, preference alignment, and model merging with extremely high-quality data and comprehensive evaluations (the whole post-training loop). https://t.co/Ut7EnTk3IH",
    "author_id": "923114064460558336",
    "attachments": { "media_keys": ["3_1881274321147994112"] },
    "in_reply_to_user_id": "923114064460558336",
    "created_at": "2025-01-20T09:35:30.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881274092994933033" }
    ],
    "edit_history_tweet_ids": ["1881274341385789830"]
  },
  {
    "id": "1881274092994933033",
    "text": "ü•≥ Super happy to share the new model I've been working on: LFM-7B\n\nLFM-7B was designed for exceptional multilingual chat capabilities, including Arabic and Japanese.\n\nIt's by far our best post-training piece to date at @LiquidAI_. https://t.co/jfAXb5FHDw",
    "author_id": "923114064460558336",
    "attachments": { "media_keys": ["3_1881273904292937728"] },
    "created_at": "2025-01-20T09:34:30.000Z",
    "edit_history_tweet_ids": ["1881274092994933033"]
  },
  {
    "id": "1881273965072818663",
    "text": "Hey @EpochAIResearch , since you decided to share FrontierMath with OpenAI, want to also share it with @huggingface so we add it to the Open LLM Leaderboard?\n\nAt least that way it will benefit open source, not just closed source https://t.co/e6RBWUTO4k",
    "author_id": "1188812448767336449",
    "created_at": "2025-01-20T09:34:00.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1880946518980469081" }],
    "edit_history_tweet_ids": ["1881273965072818663"]
  },
  {
    "id": "1881271622545580362",
    "text": "Also here: https://t.co/PWyJVAPPAs",
    "author_id": "1188812448767336449",
    "in_reply_to_user_id": "1188812448767336449",
    "created_at": "2025-01-20T09:24:41.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880946518980469081" },
      { "type": "replied_to", "id": "1881269698920407334" }
    ],
    "edit_history_tweet_ids": ["1881271622545580362"]
  },
  {
    "id": "1881271423941124342",
    "text": "RT @manasjsaloi: Inside the mind of Alex Zhu (TikTok).\n\nFrom years ago. One of the best things I have read on product strategy. https://t.c‚Ä¶",
    "author_id": "85225861",
    "created_at": "2025-01-20T09:23:54.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880975536488677674" }],
    "edit_history_tweet_ids": ["1881271423941124342"]
  },
  {
    "id": "1881271005110538645",
    "text": "will be modernizing the grok tab over the next few days\n\nit will recommend cool things you can do with grok and surface interesting things you might want to know\n\nwe just shipped the first update\n\nlet us know what you think! https://t.co/Xp5e9yeQAh",
    "author_id": "1092693586263457792",
    "attachments": { "media_keys": ["3_1881268724080181248"] },
    "created_at": "2025-01-20T09:22:14.000Z",
    "edit_history_tweet_ids": ["1881271005110538645"]
  },
  {
    "id": "1881269698920407334",
    "text": "See here: https://t.co/1XAqeCcWCf\nand here: https://t.co/88RgnvoO2T",
    "author_id": "1188812448767336449",
    "in_reply_to_user_id": "1188812448767336449",
    "created_at": "2025-01-20T09:17:03.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881269696416342173" }
    ],
    "edit_history_tweet_ids": ["1881269698920407334"]
  },
  {
    "id": "1881269696416342173",
    "text": "Why we need independent 3rd party evals:   \n\nFrontierMath: \"hundreds of **unpublished**, expert-level mathematics problems that specialists spend days solving\"\n\nAlso FrontierMath: we're funded by OpenAI so they got access to the data! But they promised to not use for training üòá",
    "author_id": "1188812448767336449",
    "created_at": "2025-01-20T09:17:02.000Z",
    "edit_history_tweet_ids": ["1881269696416342173"]
  },
  {
    "id": "1881269148480844227",
    "text": "RT @Thom_Wolf: Wait! Over 35 *thousands* people registered for the AI Agent course\n\nin a few days...\n\ntime to find the biggest conference c‚Ä¶",
    "author_id": "1188812448767336449",
    "created_at": "2025-01-20T09:14:51.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881268455196054001" }],
    "edit_history_tweet_ids": ["1881269148480844227"]
  },
  {
    "id": "1881268887309955289",
    "text": "good example of the rampant anti-nuclear framing in German journalism - in this SPIEGEL visualization, the red plants are active, while the green ones have been shut down: the exact opposite of how you would usually visualize on/off\n\n67% of Germans want nuclear back btw https://t.co/P3DPtkC1NU",
    "author_id": "5483052",
    "attachments": { "media_keys": ["3_1881267943406739456"] },
    "created_at": "2025-01-20T09:13:49.000Z",
    "edit_history_tweet_ids": ["1881268887309955289"]
  },
  {
    "id": "1881268182721429744",
    "text": "@Teknium1 what if you tell it \"no yapping\" or \"bro don't overthink it pls\"?\n\nalso is that r1? I wonder if zero is at all different",
    "author_id": "192201556",
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T09:11:01.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881267038091682191" }
    ],
    "edit_history_tweet_ids": ["1881268182721429744"]
  },
  {
    "id": "1881267954769105015",
    "text": "RT @adcock_brett: A ton of great progress in AI and Robotics this week.\n\nI summarized everything from Unitree, OpenAI, Mirror Me, Microsoft‚Ä¶",
    "author_id": "3222018178",
    "created_at": "2025-01-20T09:10:07.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881024584515830239" }],
    "edit_history_tweet_ids": ["1881267954769105015"]
  },
  {
    "id": "1881267789446734102",
    "text": "Bro said \"Let me use my fingers to count. Hold up one finger on my left hand and one on my right. Now, if I put them together, that makes two fingers. Yep, that seems right.\" https://t.co/4Y0wp2Xi2n",
    "author_id": "1365020011123773442",
    "created_at": "2025-01-20T09:09:27.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881267038091682191" }],
    "edit_history_tweet_ids": ["1881267789446734102"]
  },
  {
    "id": "1881267126885109816",
    "text": "Let thy CoT be free",
    "author_id": "1365020011123773442",
    "created_at": "2025-01-20T09:06:49.000Z",
    "edit_history_tweet_ids": ["1881267126885109816"]
  },
  {
    "id": "1881267038091682191",
    "text": "Got me a deepseek reasoning model inferencing ^_^ https://t.co/XMIGjHFvcZ",
    "author_id": "1365020011123773442",
    "attachments": { "media_keys": ["3_1881267033587032064"] },
    "created_at": "2025-01-20T09:06:28.000Z",
    "edit_history_tweet_ids": ["1881267038091682191"]
  },
  {
    "id": "1881265031041646807",
    "text": "r1 out https://t.co/YhCw66JWr0",
    "author_id": "1499415401763115019",
    "created_at": "2025-01-20T08:58:30.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881211111439204378" }],
    "edit_history_tweet_ids": ["1881265031041646807"]
  },
  {
    "id": "1881264729148256491",
    "text": "RT @iScienceLuvr: nobody knew this but actually my sister @sopranotiara came up with the name MedARC https://t.co/Ha9rvyOPt7",
    "author_id": "441465751",
    "attachments": { "media_keys": ["3_1879829830658613248"] },
    "created_at": "2025-01-20T08:57:18.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879829890092126386" }],
    "edit_history_tweet_ids": ["1881264729148256491"]
  },
  {
    "id": "1881264279225331889",
    "text": "Incredible speed of investigation https://t.co/atAfoi3ZHo",
    "author_id": "192201556",
    "created_at": "2025-01-20T08:55:31.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881264063302557919" }],
    "edit_history_tweet_ids": ["1881264279225331889"]
  },
  {
    "id": "1881264166935425261",
    "text": "@teortaxesTex Only way I‚Äôd respond to it: https://t.co/pgIZCxamez",
    "author_id": "874987512850128897",
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T08:55:04.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881262570965021141" },
      { "type": "replied_to", "id": "1881262703710503020" }
    ],
    "edit_history_tweet_ids": ["1881264166935425261"]
  },
  {
    "id": "1881262703710503020",
    "text": "don't believe anything this man says until he screams \"Donald, Donald, rid me of these pesky competitors! for security! for MAGA!\" https://t.co/qmVWUA0HZF",
    "author_id": "192201556",
    "created_at": "2025-01-20T08:49:15.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881258443669172470" }],
    "edit_history_tweet_ids": ["1881262703710503020"]
  },
  {
    "id": "1881262656490963431",
    "text": "RT @A_K_Nain: It is happening! The much awaited moment. Good job whale bros! üéâüéâü•≥ü•≥ https://t.co/CW8MOkeLWo",
    "author_id": "175282603",
    "attachments": { "media_keys": ["3_1881245893657350144"] },
    "created_at": "2025-01-20T08:49:04.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881246076642209918" }],
    "edit_history_tweet_ids": ["1881262656490963431"]
  },
  {
    "id": "1881262570965021141",
    "text": "@sama we‚Äôre seeing sparks of AGI @ @deepseek_ai tho\n\nhttps://t.co/DgAQMWOA07",
    "author_id": "874987512850128897",
    "in_reply_to_user_id": "1605",
    "created_at": "2025-01-20T08:48:43.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881258443669172470" }
    ],
    "edit_history_tweet_ids": ["1881262570965021141"]
  },
  {
    "id": "1881261699342426480",
    "text": "RT @TheXeophon: R1 is dropping and no western provider is hosting them smh",
    "author_id": "175282603",
    "created_at": "2025-01-20T08:45:15.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881238185390563661" }],
    "edit_history_tweet_ids": ["1881261699342426480"]
  },
  {
    "id": "1881261626491576472",
    "text": "RT @lmsysorg: Tomorrow is Martin Luther King day in the US. But our SGLang team is continuing working at the fireline of LLM serving! We ar‚Ä¶",
    "author_id": "192201556",
    "created_at": "2025-01-20T08:44:58.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881258285296447977" }],
    "edit_history_tweet_ids": ["1881261626491576472"]
  },
  {
    "id": "1881261288296489440",
    "text": "@sama that's fine\ni just want to know why o1-2024-12-17 is not yet available in chatgpt",
    "author_id": "1513853205125681162",
    "in_reply_to_user_id": "1605",
    "created_at": "2025-01-20T08:43:37.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881258443669172470" }
    ],
    "edit_history_tweet_ids": ["1881261288296489440"]
  },
  {
    "id": "1881259729953161714",
    "text": "Here's a thread which doesn't hit that fence. I don't agree with everything Ken says (e.g. I think he's mostly wrong about why sex is more vulnerable for women than men) but he stares at the hard parts in a way that'll be necessary to fix sexual morality. https://t.co/hRjmnQ1GP3",
    "author_id": "85225861",
    "in_reply_to_user_id": "85225861",
    "created_at": "2025-01-20T08:37:26.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1881157743274598479" },
      { "type": "replied_to", "id": "1881258130128187507" }
    ],
    "edit_history_tweet_ids": ["1881259729953161714"]
  },
  {
    "id": "1881259044981399734",
    "text": "It's your men who are spreading the hype anon https://t.co/LEUIOUzsn3 https://t.co/kp1vTzT7VS",
    "author_id": "1513853205125681162",
    "attachments": { "media_keys": ["3_1881259037112832001"] },
    "created_at": "2025-01-20T08:34:43.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881258443669172470" }],
    "edit_history_tweet_ids": ["1881259044981399734"]
  },
  {
    "id": "1881258856166339051",
    "text": "@sama but‚Ä¶\n\nyou hyped it üòÇ\n\nhttps://t.co/sAPihhUWPC",
    "author_id": "800854096219471872",
    "in_reply_to_user_id": "1605",
    "created_at": "2025-01-20T08:33:58.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1875603249472139576" },
      { "type": "replied_to", "id": "1881258443669172470" }
    ],
    "edit_history_tweet_ids": ["1881258856166339051"]
  },
  {
    "id": "1881258629007126762",
    "text": "Paper: https://t.co/QwBoeTvXcJ",
    "author_id": "1141052916570214400",
    "in_reply_to_user_id": "1141052916570214400",
    "created_at": "2025-01-20T08:33:03.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881258625999786422" }
    ],
    "edit_history_tweet_ids": ["1881258629007126762"]
  },
  {
    "id": "1881258625999786422",
    "text": "New inference-time computing method from @GoogleDeepMind! Evolutionary search strategy focuses on improving planning by generating multiple solutions in parallel, evaluating and recombining them.\n\nImplementation\n0Ô∏è‚É£ planning problems and a programmatic way to evaluate the quality‚Ä¶ https://t.co/9Nnmg7h2cf https://t.co/17ecEsoZE5",
    "note_tweet": {
      "text": "New inference-time computing method from @GoogleDeepMind! Evolutionary search strategy focuses on improving planning by generating multiple solutions in parallel, evaluating and recombining them.\n\nImplementation\n0Ô∏è‚É£ planning problems and a programmatic way to evaluate the quality of solutions. \n1Ô∏è‚É£ Use an LLM (e.g. Gemini) to generate an initial set of diverse candidate solutions. \n2Ô∏è‚É£ Evaluate each solution using the evaluator and select the best-performing ones \n3Ô∏è‚É£ Use the LLM to create new solutions by combining elements from the best solutions \n4Ô∏è‚É£ Have the LLM refine these new solutions based on evaluator feedback \n5Ô∏è‚É£ Repeat steps 3-5 for multiple generations until you find a satisfactory solution\n\nCan be used in a two-stage approach: start with a faster model (Gemini Flash) and use a more powerful model (like Gemini Pro) for difficult cases\n\nInsights\nüöÄ 98% success rate on TravelPlanner and Natural Plan benchmarks using Gemini 1.5 Pro.\nüí™ Outperforms Best-of-N and Sequential Revision strategies significantly.\nüí∞ Mind Evolution more cost-effective than sequential revision ($0.65 vs $3.20 per problem)\nüîÑ Deeper search (more generations) performed better than generating more candidates\nüéØ Works well for problems that are hard to formalize but easy to evaluate\nü•á¬†Achieved 46.5% success rate in the StegPoet compared to 1% for Best-of-N\nüìù Prompts are part of the paper and include general instructions, problem definition, few-shot examples\n‚ùå Requires a programmatic evaluator that can score solutions and provide feedback",
      "entities": {
        "mentions": [
          {
            "start": 41,
            "end": 56,
            "username": "GoogleDeepMind",
            "id": "4783690002"
          }
        ]
      }
    },
    "author_id": "1141052916570214400",
    "attachments": { "media_keys": ["3_1881258572144672768"] },
    "created_at": "2025-01-20T08:33:03.000Z",
    "edit_history_tweet_ids": ["1881258625999786422"]
  },
  {
    "id": "1881258443669172470",
    "text": "twitter hype is out of control again. \n\nwe are not gonna deploy AGI next month, nor have we built it.\n\nwe have some very cool stuff for you but pls chill and cut your expectations 100x!",
    "author_id": "1605",
    "created_at": "2025-01-20T08:32:19.000Z",
    "edit_history_tweet_ids": ["1881258443669172470"]
  },
  {
    "id": "1881258130128187507",
    "text": "Alas, I think Kat can't analyze this deeply enough to find a lasting solution, because she seeems committed to making sure her conclusions can't be weaponized.\n\nUnfortunately, fenced-off areas on your map often block paths to the most valuable solutions. https://t.co/TZFQ1els7x",
    "author_id": "85225861",
    "in_reply_to_user_id": "85225861",
    "created_at": "2025-01-20T08:31:04.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1879535272960163998" },
      { "type": "replied_to", "id": "1881061408487723177" }
    ],
    "edit_history_tweet_ids": ["1881258130128187507"]
  },
  {
    "id": "1881256536296861892",
    "text": "all eyes on https://t.co/hIofOqvHek üëÄ",
    "author_id": "874987512850128897",
    "created_at": "2025-01-20T08:24:44.000Z",
    "edit_history_tweet_ids": ["1881256536296861892"]
  },
  {
    "id": "1881253349443748043",
    "text": "I just assume this is sarcasm at this point. https://t.co/3ZOqdlX789",
    "author_id": "192201556",
    "created_at": "2025-01-20T08:12:05.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881251386265903328" }],
    "edit_history_tweet_ids": ["1881253349443748043"]
  },
  {
    "id": "1881252048584524133",
    "text": "Now that we know R1 uses v3 as a base, worth remembering that v3 was released less than a month ago\n\nEspecially important if you believe the rumor that v3 only finished training just before the release",
    "author_id": "1718879852827484160",
    "created_at": "2025-01-20T08:06:55.000Z",
    "edit_history_tweet_ids": ["1881252048584524133"]
  },
  {
    "id": "1881251730220073235",
    "text": "Are you trembling in your frontier glass house yet, Sam? https://t.co/TX9RnaG7QT",
    "author_id": "192201556",
    "created_at": "2025-01-20T08:05:39.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1813717300257931588" }],
    "edit_history_tweet_ids": ["1881251730220073235"]
  },
  {
    "id": "1881251521402384750",
    "text": "topical reminder https://t.co/khuQf8hQ9G",
    "author_id": "192201556",
    "created_at": "2025-01-20T08:04:49.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1867790537178460248" }],
    "edit_history_tweet_ids": ["1881251521402384750"]
  },
  {
    "id": "1881250340386882040",
    "text": "@crewAIInc @LukawskiKacper @tonykipkemboi https://t.co/ihDwYud1Rl",
    "author_id": "1338631899422617600",
    "in_reply_to_user_id": "1338631899422617600",
    "created_at": "2025-01-20T08:00:07.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881250338893668464" }
    ],
    "edit_history_tweet_ids": ["1881250340386882040"]
  },
  {
    "id": "1881250338893668464",
    "text": "üö® Last Chance to RSVP! üö®\n\nDon‚Äôt miss the Building Intelligent Agentic RAG live stream with @crewAIInc &amp; Qdrant!\n\nTomorrow, @LukawskiKacper and @tonykipkemboi will demonstrate how to create advanced AI agents that work with your emails and knowledge base to generate‚Ä¶ https://t.co/mMksGsnnJm https://t.co/2cThiISnIk",
    "note_tweet": {
      "text": "üö® Last Chance to RSVP! üö®\n\nDon‚Äôt miss the Building Intelligent Agentic RAG live stream with @crewAIInc & Qdrant!\n\nTomorrow, @LukawskiKacper and @tonykipkemboi will demonstrate how to create advanced AI agents that work with your emails and knowledge base to generate context-driven responses and automate personal tasks. \n\nüëâ Register now: https://t.co/MKud2hMTfv",
      "entities": {
        "mentions": [
          {
            "start": 91,
            "end": 101,
            "username": "crewAIInc",
            "id": "1770815821310230528"
          },
          {
            "start": 123,
            "end": 138,
            "username": "LukawskiKacper",
            "id": "4782705362"
          },
          {
            "start": 143,
            "end": 157,
            "username": "tonykipkemboi",
            "id": "850175781468819456"
          }
        ],
        "urls": [
          {
            "start": 338,
            "end": 361,
            "url": "https://t.co/MKud2hMTfv",
            "expanded_url": "https://buff.ly/4fQknd6",
            "display_url": "buff.ly/4fQknd6"
          }
        ]
      }
    },
    "author_id": "1338631899422617600",
    "attachments": { "media_keys": ["3_1881250336486170624"] },
    "created_at": "2025-01-20T08:00:07.000Z",
    "edit_history_tweet_ids": ["1881250338893668464"]
  },
  {
    "id": "1881250036803359214",
    "text": "DeepSeek R1 Zero is here. It looks to be from DeepSeek v3 which means that R1-Lite/Preview that we saw previously is a completely separate training run https://t.co/2ldP8uTUjA",
    "author_id": "1718879852827484160",
    "attachments": { "media_keys": ["3_1881249772322832384"] },
    "created_at": "2025-01-20T07:58:55.000Z",
    "edit_history_tweet_ids": ["1881250036803359214"]
  },
  {
    "id": "1881249739389436210",
    "text": "I refuse to believe that whales wrote a whole ass manual on pretraining infrastructure for V3 and now will say \"sike! we actually did that for R1, nvm\"\n\notoh, not their first time loop. DeepSeek-Coder paper came after DS-LLM, and cites it, but the Coder model was released first.",
    "author_id": "192201556",
    "created_at": "2025-01-20T07:57:44.000Z",
    "edit_history_tweet_ids": ["1881249739389436210"]
  },
  {
    "id": "1881248177288061082",
    "text": "just keep doing the bit https://t.co/z2qgnSFBkG",
    "author_id": "192201556",
    "created_at": "2025-01-20T07:51:32.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1878718780974760226" }],
    "edit_history_tweet_ids": ["1881248177288061082"]
  },
  {
    "id": "1881248120023216474",
    "text": "o1 pro for fixing super hard bugs in your codebase: https://t.co/YctpMIg19V",
    "author_id": "162124540",
    "created_at": "2025-01-20T07:51:18.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881121086752100428" }],
    "edit_history_tweet_ids": ["1881248120023216474"]
  },
  {
    "id": "1881244304771084657",
    "text": "&gt; Now, if R1@10 *is* cheaper than o1-High@1‚Ä¶\nlol it's pretty much guaranteed I guess. R1 has the same inference costs as V3. how much [thinking] does o3-High do? https://t.co/Ryt0etvf7Z https://t.co/t7XgKV593a",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881244004894851072"] },
    "created_at": "2025-01-20T07:36:08.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1880768996225769738" }],
    "edit_history_tweet_ids": ["1881244304771084657"]
  },
  {
    "id": "1881243748463739191",
    "text": "This is one of those general features that will scale nicely as we create new tools and as models become more personal. Because it enables modular compositions that, when combined, yield surprisingly creative and powerful use cases, from personalized recommendations to‚Ä¶ https://t.co/FgndYmsXay https://t.co/0w1GKGvuID",
    "note_tweet": {
      "text": "This is one of those general features that will scale nicely as we create new tools and as models become more personal. Because it enables modular compositions that, when combined, yield surprisingly creative and powerful use cases, from personalized recommendations to never-ending evolving stories and app creations!"
    },
    "author_id": "1094268079540920321",
    "created_at": "2025-01-20T07:33:56.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881079458465239507" }],
    "edit_history_tweet_ids": ["1881243748463739191"]
  },
  {
    "id": "1881242867064254603",
    "text": "I guess even whalebros can have a \"don't fit what's not broken\" attitude to envs\n@zheanxu comment? Or not your department?",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T07:30:25.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881241867335176475" }
    ],
    "edit_history_tweet_ids": ["1881242867064254603"]
  },
  {
    "id": "1881241966639509983",
    "text": "@Teknium1 it's zero afaict",
    "author_id": "192201556",
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T07:26:51.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881241886951940314" }
    ],
    "edit_history_tweet_ids": ["1881241966639509983"]
  },
  {
    "id": "1881241886951940314",
    "text": "@teortaxesTex Whats the diff from zero and r1",
    "author_id": "1365020011123773442",
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T07:26:32.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881231937265946957" }
    ],
    "edit_history_tweet_ids": ["1881241886951940314"]
  },
  {
    "id": "1881241867335176475",
    "text": "Curious detail: transformers_version in configs of both R1s is 4.46.3, which was released Nov 18, 2024. R1-Lite-Preview was debuted Nov 20, 2024.\n(V3's transformers_version is ancient, Sep 2023 4.33.1. Likewise for V2-Lite. V2-coders are 4.39.3 ‚Äì from April 2024) https://t.co/GFY8aysA8r",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881239818295779328"] },
    "created_at": "2025-01-20T07:26:27.000Z",
    "edit_history_tweet_ids": ["1881241867335176475"]
  },
  {
    "id": "1881241250789265855",
    "text": "let‚Äôs goo, 685 billion parameters of pure AGI! https://t.co/9ECPUYpMd3",
    "author_id": "874987512850128897",
    "attachments": { "media_keys": ["3_1881241246099738624"] },
    "created_at": "2025-01-20T07:24:00.000Z",
    "edit_history_tweet_ids": ["1881241250789265855"]
  },
  {
    "id": "1881241207831138788",
    "text": "No longer empty, they did the reasoning work on 680b param moe lol https://t.co/P3EU9ba4P4",
    "author_id": "1365020011123773442",
    "created_at": "2025-01-20T07:23:50.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881226980278129102" }],
    "edit_history_tweet_ids": ["1881241207831138788"]
  },
  {
    "id": "1881241099857174742",
    "text": "RT @RisingSayak: What up Bangalore? \n\nHF &amp; Google Cloud are organizing an in-person meetup on 25th Jan on multimodal models, featuring Pali‚Ä¶",
    "author_id": "593407733",
    "created_at": "2025-01-20T07:23:24.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879870116802048292" }],
    "edit_history_tweet_ids": ["1881241099857174742"]
  },
  {
    "id": "1881241076679532590",
    "text": "RT @RisingSayak: Nice work from GDM on going beyond steps to scale test-time compute for diffusion models. \n\nI know this is not the first w‚Ä¶",
    "author_id": "593407733",
    "created_at": "2025-01-20T07:23:19.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880095232706113726" }],
    "edit_history_tweet_ids": ["1881241076679532590"]
  },
  {
    "id": "1881240958400086347",
    "text": "Its not empty ahh",
    "author_id": "1365020011123773442",
    "in_reply_to_user_id": "1365020011123773442",
    "created_at": "2025-01-20T07:22:50.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881226980278129102" }
    ],
    "edit_history_tweet_ids": ["1881240958400086347"]
  },
  {
    "id": "1881239211946459488",
    "text": "Current vibe: \"Did it crash yet?\"",
    "author_id": "99581347",
    "created_at": "2025-01-20T07:15:54.000Z",
    "edit_history_tweet_ids": ["1881239211946459488"]
  },
  {
    "id": "1881238789995254028",
    "text": "RT @SonglinYang4: I've created slides for those curious about the recent rapid progress in linear attention: from linear attention to Light‚Ä¶",
    "author_id": "568879807",
    "created_at": "2025-01-20T07:14:13.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880536012432265349" }],
    "edit_history_tweet_ids": ["1881238789995254028"]
  },
  {
    "id": "1881238295180648892",
    "text": "RT @tokenbender: exhibit A - how the crowd welcomes the messiah\n&gt; Asi singularity\n&gt; Godsend\n&gt; Killer\n\ni am loving the vibes\nahahahaha https‚Ä¶",
    "author_id": "1513853205125681162",
    "created_at": "2025-01-20T07:12:15.000Z",
    "referenced_tweets": [{ "type": "retweeted", "id": "1881236886787956802" }],
    "edit_history_tweet_ids": ["1881238295180648892"]
  },
  {
    "id": "1881237899494166671",
    "text": "I used to think that technical founder CEOs would vastly outperform politicians in running states well\nmaybe we need technical quant hedge fund founder CEOs to really get the best possible operation https://t.co/H7ZcsvoUjz",
    "author_id": "192201556",
    "created_at": "2025-01-20T07:10:41.000Z",
    "referenced_tweets": [{ "type": "quoted", "id": "1881236236087734490" }],
    "edit_history_tweet_ids": ["1881237899494166671"]
  },
  {
    "id": "1881237853537206723",
    "text": "TFW you wrote a script eons ago that confirms everything worked fine with \"All good captain\" and you have been reading this message 100 times a day since then.",
    "author_id": "99581347",
    "created_at": "2025-01-20T07:10:30.000Z",
    "edit_history_tweet_ids": ["1881237853537206723"]
  },
  {
    "id": "1881237302745424051",
    "text": "whalebros I don't mind that its score is merely 1450 on CodeForces, what matters is not the size but the effort\npls share, what would it matter to you if you're already handing out these monstrosities https://t.co/KZ4nuPRuZ8",
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["3_1881236806093426689", "3_1881237021861019648"]
    },
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T07:08:19.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881235706489847915" }
    ],
    "edit_history_tweet_ids": ["1881237302745424051"]
  },
  {
    "id": "1881235706489847915",
    "text": "On one hand this is disappointing because we aren't getting any model we can run locally it seems. (they did upload V2-lite some time after V2 to facilitate community experiments, though, but hope is faint).\n\nOn the other. What's the deal with (-Preview) on LCB? https://t.co/pLnX0tVoiv",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881235633273806848"] },
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T07:01:58.000Z",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1881235108054868377" }
    ],
    "edit_history_tweet_ids": ["1881235706489847915"]
  },
  {
    "id": "1881235108054868377",
    "text": "nope I'm wrong\nR1 also is V3-based, or perhaps V3 and R1 are split from the same base, or whatever. In this case I notice I am very confused. https://t.co/HxkLi3vhOV",
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1881234890269536256"] },
    "created_at": "2025-01-20T06:59:36.000Z",
    "edit_history_tweet_ids": ["1881235108054868377"]
  },
  {
    "id": "1881234288533991510",
    "text": "it's disorienting seeing perfectly sane people, just doing one sensible step after another, doing everything I expect them to do if they want to win. People are supposed to be goofy, confused and sometimes lowkey retarded. This is anime territory. https://t.co/GcanBgHsWb",
    "author_id": "192201556",
    "in_reply_to_user_id": "192201556",
    "created_at": "2025-01-20T06:56:20.000Z",
    "referenced_tweets": [
      { "type": "quoted", "id": "1754709268966629582" },
      { "type": "replied_to", "id": "1881233018725249149" }
    ],
    "edit_history_tweet_ids": ["1881234288533991510"]
  }
]
